[{"content":"Close to 2 years ago, I had an idea for a mobile application that allowed users to store, submit, and manage tax reimbursements in foreign countries. For 2 years ago, I on and off worked on this idea and had a functioning version on my phone - and for nearly all that time, I never felt like the application was ready to release to potential users - and it doesn\u0026rsquo;t look like I\u0026rsquo;ll ever get it there.\nWhat follows are my work logs for the past few years from building this application, and what I learned.\nMay 2023 Choosing a framework Since I know users use iPhones for their work, and I have an Android device, I wanted a cross-platform framework so I only had to manage one codebase and learn a single new language. I considered building just a web app, but wanted the experience of downloading the app from the app store, and learning how to do it myself.\nI had some experience with React, so I first looked up React Native and started trying to install that. Exploring on the web led me to Flutter and I liked the fact it almost included a framework for the UI. Less work for me, and it was nice that it would align with usability needs and look professional and familiar to users.\nThe deciding factor was that I managed to get Flutter installed and working first before I got React Native working on my machine.\nJune 2023 I didn\u0026rsquo;t start documenting my work process immediately when building the app. In June, and May before it, I worked on the UI of the app, specifically:\nBuilt a mock home page\nBuilt a mock cedula card page (user information)\nEnabled the taking of pictures\nEnabled a list page of receipts\nCreated a mock data model and allowed for local storage\nIt was at this point when I needed to go further and implement a database that I started writing. Local storage didn\u0026rsquo;t seem like a necessarily secure or long lasting model. Families would want to share receipts across purchases, and access them on different devices to download and print. I would need to upload the receipts anyway to APIs to OCR the submission instructions, receipt IDs, and other purchase information.\nFlutterfire \u0026amp; Firebase Incorporating authentication, analytics, and a database into the application.\nI decided with Firebase for a few reasons:\nI didn\u0026rsquo;t want to worry about platform-specific APIs that much\nWanted something pre-built that I could outsource authentication, security, etc to\nSaw it had online and offline capabilities, which I thought was nice.\nSeemed to have good support with Flutter, and a decent amount of code-labs and instructions at first glance. I looked at AWS (Amplify?) and Azure as well, but since I was already using a Google framework, I decided the path of least resistance was likely a Google back end as well.\nOrganization Name I had built my app in the sample directory Flutter created as part of a code lab, which mean the Organization ID was com.example.something, which is disallowed by the App Store or something else. So at this point I created a new Flutter project, then copied my code over.\nI also refactored here to split up all the code in main.dart to specific files for the camera, profile, and receipt section.\nHere, Flutter notified me that Flutter had updated and I needed to run flutter update.\nOn trying to build my app after this, I had to restart VSCode because the Future type was not being recognized by Dart. Restarting fixed that error.\nNow, Flutter told me to run dart fix to fix common issues in my files (apparently which happens after a Flutter update). I did, and it returned help text. I needed to run dart fix --apply to have the fixes implemented.\nHere, I tried again to run flutterfire configure --project=PROJECTNAME. That returned a pubspec.yml not found in flutterfire/cache/something error. I re-logged into Firebase, then re-ran dart pub global activate flutterfire_cli. This activated flutterfire again, after which running the flutterfire configure command worked.\nI had to re-run flutter pub add firebase_core.\nI keep getting a\nBuilding with plugins requires symlink support. Please enable Developer Mode in your system settings. Run start ms-settings:developers to open settings.\nerror. No idea what symlink is at all.\nAt this point, the imports fore firebase_core and firebase_options are no longer marked as errors, but FirebaseDatabase class still is tagged as undefined. I thought it was an error and restarted VSCode, then I realized I didn\u0026rsquo;t actually bring over the import for the Firebase RealTime database because I decided to implement the basic authentication module first. My bad.\nI ran dart fix again. I don\u0026rsquo;t know why. I thought I just ran it. But it asked me too, so that\u0026rsquo;s that.\nAuthentication I followed this article, and the this codelab. Something I like about Flutter so far is the simplicity of installing and adding packages.\nI ran into an issue in Step 5, Sign-In screen, when trying to add in the headerBuilder option. VSCode (or me) had set const SignInScreen to return, rather than just SignInScreen. When I got the the headerBuilder arg, I kept getting an Invalid const error, which I kept thinking was the headerBuilder since that is what was being highlighted. But I had set the whole widget to a const, and the headerBuilder couldn\u0026rsquo;t be calculated as a const.\nI had to set the assets: - images/ folder in the pubspec.yaml folder for the SignInScreen widget to display the icon correctly. I also updated the size and background and added a second, different sized version to show on this page, versus the launcher icon.\nIcon I designed a simple icon in Figma (free plan) in about 15 minutes and saved as a .png. It took a bit to find the actual developer guidelines on how to build the application launcher app. I was also confused that I had to install flutter_launcher_icons to update the application icon, and I didn\u0026rsquo;t find the documentation very helpful. I copy-pasted the configuration example from the docs page. I ran pub run flutter_launcher_icons, which, I don\u0026rsquo;t exactly know what it does.\nThe icon successfully updated, but when the app loads, the icon is magnified, and the image I uploaded isn\u0026rsquo;t (so it looks small in comparison).\nI don\u0026rsquo;t know if it worked for iPhone, or if I need to upload multiple sizes. I got a \u0026ldquo;Overwriting default iOS launcher icon with new icon - No platform provided\u0026rdquo; note when I ran pub run flutter_launcher_icons.\nJuly 2023 Profile Page Restarting the project\nI had been away on vacation for 2 weeks. I hadn\u0026rsquo;t worked on this app for probably 1 to 2 weeks before that, as well, due to wrapping everything else up before the vacation. This is rough, because it is hard to keep track of a) what I did last, b) if I left it in a state where I need to do something crucial next that I don\u0026rsquo;t remember, and c) what I planned to do next. So, my steps to restarting a project now:\nTry to run the project. See what happens.\nRun anything that the IDE asks you to run. E.g., dart fix. I swear I get this message every time I open VSCode.\nFocus on the part you think you remember doing last and spend more time understanding that section than anything else.\nMake a minor, completely unrelated change that is almost worthless, e.g., adjust the padding on something, just to see if you remember how to commit a change. This will also feel like quick progress.\nI previously think I was working on the Google Firebase integration, so restarting work there first. I also set a goal. By the end of July, have a publishable app that allows users to log in and store their organization tax information. This is the information that the store will ask you for when you try to generate a reimbursment. I already have the major parts of this, but I want to polish it and ensure it works, and publish it (at least informally).\nI read about logging options due to a warning that tells me I shouldn\u0026rsquo;t use print in production code. That said, all the examples I found online about Dart logging literally just printed warnings from the logging package to the standard output, and ended there, or just used print statements themselves. So not worth it at this point for me to fix.\nFirebase (Realtime Database) I started with the Firebase documentation and quickly felt overwhelmed. I had not worked with a JSON tree type data structure before. I read the Firebase Flutter articles on Realtime Database. I can\u0026rsquo;t say I deeply understood the Choose a Database article either, but I assumed that for this minimal app, either would work. So, I went for the simplest.\nI ran flutter pub add firebase_database and flutter run, and added the Realtime Database package to my main.dart file. I was looking for a simple example on a) how to set up the data structure and b) how to write and read data, which incidentally are two of the five help articles they had (at least at the time of writing). Neither, however, were in-depth enough to get me started.\nI switched to a Google Codelab which covered how to add Firestore, rather than the RealTime database, but close enough.\nI ran into this error:\n: Error: Too many positional arguments: 1 allowed, but 2 found firebase_auth_web.dart:94 Try removing the extra positional arguments. FirebaseCoreWeb.registerService('auth', (firebaseApp) async { ^ : Context: Found this candidate, but the arguments don't match firebase_core_web.dart:43static void registerService( ^^^^^^^^^^^^^^^ Failed to compile application.\nFortunately apparently this was a very recent issue for many people and resolved it with this StackOverflow post.\nI followed this tutorial for a bit, implementing the UI for it. Then got distracted with how the screen looks. I implemented some UI changes, considered how I wanted the profile to function, and explored some example applications. I decided that editing the information would be done on a separate screen, to allow for users to click on each piece of information and immediately copy it to their clipboard. I then implemented the copy to clipboard functionality, which happily, was a trivial task.\nHere, a couple things to do (to keep track for myself):\nrefactor the label and profile text to be a container, so you can click anywhere on the text or label to copy.\nImplement a copy all functionality.\nImplement a edit page (imagining a pencil icon leading to a new page)\nActually stop procrastinating on the difficult problem and implement the database.\n7/18/2023 I watched this Firecast video that helped me ensure I had the packages installed correctly. The last step failed for me when trying to compile to Chrome Web, as I am using VSCode and didn\u0026rsquo;t have the logcat window. I couldn\u0026rsquo;t find an equivalent debug console, and thought that perhaps I didn\u0026rsquo;t properly connect the Web version to the Realtime Database. So I turned on an emulater (Pixel 2 API). From this, while compiling, I received a ...FlutterFirebaseFirestoreMessageCodec.java uses unchecked or unsafe operations. Note: Recompile with -Xlint:unchecked for details. error. Found this StackOverflow post.\nBefore updating the SDK version, I tried the simple database call laid out in the video. Finally, a Caused by: com.google.firebase.database.DatabaseException: Firebase Database error: Permission denied, which was good news. At least it was doing something.\nLooking in the console, my Rules prevented access.\n{\u0026quot;rules\u0026quot;: {\u0026quot;.read\u0026quot;: false,\u0026quot;.write\u0026quot;: false}\nBased on reading the Firebase security rules documentation, and a quick query to Github Copilot, I adjusted these to:\n{\u0026quot;rules\u0026quot;: {\u0026quot;users\u0026quot;: {\u0026quot;$user_id\u0026quot;: {\u0026quot;.read\u0026quot;: false,\u0026quot;.write\u0026quot;: \u0026quot;$user_id === auth.uid\u0026quot;}}}}\nOf course, for some reason I can\u0026rsquo;t tell, hot restart isn\u0026rsquo;t working. I have to manually click the hot restart button for the app to reload.\nBut now it works! I had the update the code in my onPressed call as well to get the unique ID of a user I had previously created. It now looks like this:\nonPressed: () { FirebaseAuth _auth = FirebaseAuth.instance; User? user = _auth.currentUser; String? uid = user!.uid; DatabaseReference _testRef = FirebaseDatabase.instance.ref().child(\u0026#39;users/\u0026#39; + uid); _testRef.set(\u0026#39;Hello World\u0026#39;); } Which was a slight adjustment from the installation video linked above. I also manually change the JSON data path of the Realtime Database under the Data tab in the Firebase Console. Where it previously stated https://project_name.firebaseio.com/, I added a key users and another object below with the user ID of the user I had previously created. I looked this up in the Authentication Console and copy-pasted. The data model now looked like:\nhttps://project_name.firebaseio.com/ - users - user_id:\u0026#34;\u0026#34; After restarting my project and clicking the button with the function above, it added \u0026ldquo;Hello World\u0026rdquo; as the value for the user_id key. This was a big accomplishment! I now have a database.\nHere, I manually entered sample data for the profile page for this user. One thing that confuses me at this point is how to create the data model; if that is manually done from the console? How do I add a new user_id branch in the users branch, for example? So I pushed passed this, and for the rest of today, just wanted to get a working example of reading data from the database for the current user. I updated the read rules on the users and new profile branches to all be \u0026quot;$user_id === auth.uid\u0026quot;.\nHere, I returned to the in-depth video of incorporating RealTime Database into Flutter. And with a bit of refactoring, including adjusting my `ProfilePage` widget to a Stateful Widget from a Stateless widget, and copying the code from the video, I had a working event listener set up that was reading data from the database.\nThe video was excellent, detailed, and got it working. However, it did that thing that teaches do where they teach you the less good method first, get you to do it, then tell you about a different method that is much better in every way. So now I apparently need to delete a bunch of that code and forget about that event listening process and use a StreamBuilder instead.\n7/28/2023 It has been 10 days since I\u0026rsquo;ve last looked at this. I quickly need to remind myself how to open Visual Studio Code and what all this multi-colored text on my screen is. I see a triangle with an exclamation mark inside, and a bright blue bubble with \u0026ldquo;33\u0026rdquo; inside of it. I literally have to scroll to read all of the warnings. I either make actual progress on my app, or add a const keyword in 30 different places for the next 20 minutes.\nI remember that at the end of the last day, everything broke and I spent a couple hours getting progressively angrier and angrier due to a Map\u0026lt;object, object\u0026gt; can't be assigned to the parameter type 'Map\u0026lt;String, dynamic\u0026gt;' or some similar error. Turns out the answer was in the Youtube comments section, and I needed to cast the returned value to a Map\u0026lt;dynamic, dynamic\u0026gt;, rather than a Map\u0026lt;String, dynamic\u0026gt;, which I am unsure why still. But it works.\nAnother error I ran into here was a LateError (LateInitializationError: Field '_myStream' has not been initialized.). If I tried to leave the Profile page, the app would freeze and throw this error. Looking at the call stack (which I am only now learning how to use this properly), I see it pauses on the deactivate method of the Profile page I am setting up. I rewatched the video (around 23 minutes) discussing the set up and take down of the StreamSubscription. For some reason, I had final _myStream assigned to the event listener. Removing final solved the problem. Again, I don\u0026rsquo;t understand why at all. late tells the compiler (I thought) that later, I would assign the StreamSubscription to a value, which I did to the event listener.\nThe final keyword tells the compiler that the value of the variable won\u0026rsquo;t be changed later, so perhaps this is incompatible with the event listener, which could change in the future? Or perhaps it can\u0026rsquo;t be cancelled if the value can\u0026rsquo;t be deleted? That is my guess, at least.\nI also spent a half hour (trying) finishing setting up Google Analytics in the application, based on a tutorial here from Firebase. I don\u0026rsquo;t care much for these tutorials where the tutorial is the installation, then a code file that you are supposed to add to your project. That isn\u0026rsquo;t a tutorial - it\u0026rsquo;s a code file. But I faithfully copy-pasted the code from the example main.dart into my existing project. The Google Analytics get started tutorial ends at FirebaseAnalytics analytics = FirebaseAnalytics.instance;. And there is no more, even though apparently that is not enough to get it working. Or perhaps it is. It isn\u0026rsquo;t clear how quickly the events will start being logged to Google Analytics, so maybe I just need to be less impatient.\nI tried to enable Debug mode by running adb shell setprop debug.firebase.analytics.app PACKAGE_NAME in my terminal, as suggested here in the DebugView tutorial. I am using a Pixel emulator right now, as my phone USB-C connection is not working right now for some reason and refusing to connect to my laptop. That, unsurprisingly, did absolutely nothing that I could tell.\nHere, I also connected the rest of the Profile fields to the event listener approach (saving the update to StreamBuilder for another day). I also added a persistentFooterButton to the Profile page, allowing a user to copy all the fields to insert into a text message or email (common action for the purpose of the application).\nNext Steps:\nEdit profile fields\nReorganize so MVP of app is just the profile card and nothing else\nUnderstand log-in flow (how to add new users?)\nadd profile fields\n8/5/2023 It is midway through projects that the scale of really releasing a production application starts to intimidate me. It is not difficult to start a project like this; the app developers and learning resources all aim to get you started. The novelty of getting something on the screen wears off. The screen is suddenly superficial as I realize the depth of what yet needs to be implemented, a majority of which is totally invisible to the user. Looking at the application now, it doesn\u0026rsquo;t even feel like I am building anything. There is nothing I can touch or hold on to. Nothing feels like I\u0026rsquo;ve created it. Instead, it is word after word, click after click, all dependent on machinery I don\u0026rsquo;t understand. I don\u0026rsquo;t feel like I have made anything new - I\u0026rsquo;m only implementing something that exists, already, that is doable by anyone.\n8/20/2023 Pain in my wrists, so I haven\u0026rsquo;t been working on this project at all. So I am simplifying - version one, only display card information, and that\u0026rsquo;s it. See if people even use it, and if they do, then I\u0026rsquo;ll keep working on it.\n8/22/2023 Checking to see how to create a new user and create that sign-up flow. But it appears Firebase Auth has that built in! Amazing. Successfully created a new user, but didn\u0026rsquo;t handle getting returned null data from the Realtime Database for a new user for the new home page, so had to resolve that. First had a Unhandled Exception: type 'Null' is not a subtype of type 'Map\u0026lt;dynamic, dynamic\u0026gt;' error, which I resolved by adding an if-then statement to check if the data is null prior to creating my object from the data.\nI leveraged GitHub Copilot here. Did a great job explaining to me the difference between event.snapshot.exists and just a if-then checking if event.snapshot.value is null. The .exists method checks if the reference exists or not, regardless of whether it is null. One aspect I find valuable is Copilot\u0026rsquo;s attempts to provide an example based in the code I am currently working on. This is usually where it goes wrong, sometimes getting the logical flow of the code incorrect, but good enough that I can see it and adjust. It also reminded me how to properly write an if-then statement in Dart and how to resolve the local variable not used error that came up.\n9/18/2023 Another long break away from the application. Severe forearm pain and nerve issues in my leg are making me wary of being on a computer for too long. Family emergencies, weddings, and dinners with friends fill up the time.\nBut I\u0026rsquo;m close. I start today with the aim of getting a About page in the application, and fixing the App Bar. I move the copy button to a floating action button, fix the color on the log out button. I add an App Drawer as an expanding side menu. I\u0026rsquo;m increasingly turning to Copilot to answer my questions and help write boilerplate code rather than StackOverflow.\nI update the user information in the drawer. Null checks continue to be difficult to get used too. What if the user doesn\u0026rsquo;t have a name? I need to use the email instead. I spend a half hour trying to get the first two characters of either, but my substring call keeps telling me RangeError... :Invalid value, which confuses me, since one of the strings is longer than 2 characters and I have a a ?? b null check.\nFinally I solve it with a ternary condition. a wasn\u0026rsquo;t null, but an empty string. Now to the actual problem of where each page takes the person. I\u0026rsquo;d like to include details about the the filing process for my users. Right now, it\u0026rsquo;s just a card on the phone that a user could substitute a picture of the card of for most cases. Sure, the copy functionality might save someone a few minutes, but not enough. If I can provide answers to some commonly asked questions, to serve as a sort of reference document, then that could be another low-hanging fruit to attract users to log in occasionally. I\u0026rsquo;m not sure where to get the information though, or how to keep it updated -\u0026gt; I don\u0026rsquo;t want to give wrong information, also. One wrong answer and I imagine people will be wary of future information, especially early on.\nI create an About page that includes an overview of the app, upcoming potential features, contact information, and a simple privacy statement.\n10/29/2023 Another long break in development. I\u0026rsquo;m not even sure what I need to do. I started with adjusting the copy area in the profile section, so clicking on the section name or the value copies the text to the clipboard, rather than just the value, making it a bit easier to get the values.\nBut I really need to work on the Edit profile page.\nI started off with replacing the separate Edit page with a callback function in the App Bar that flips a _isEditState toggle, switching the widget from a text display with a copy function to a Form based off of this tutorial.\n10/29/2024 The last time I worked on this app was 1 year ago exactly. I only realized this as I opened the project again. I didn\u0026rsquo;t realize it had been this long of a break, and I am disappointed in myself for not getting to this sooner. However, I have a clear goal - to take screenshots of the app to share with people to see if they would be interested in using the application.\nThat said, I have been using the app consistently during the year, and at checkouts, restaurants, and at home the test version of the application has been consistently helpful. I have mentioned it to other people who all expressed interest in something like this, and I am still motivated to finish this with a release.\nI started by trying to run the application in an emulator. The debugger would start, run assembleGradle, then fail. I found the flutter daemon logs after pressing the run and debug button with multiple configurations, which stated a few errors:\n\u0026gt; [ERR] Command exited with code 128: git fetch --tags \u0026gt; Standard error: fatal: unable to access \u0026#39;https://github.com/flutter/flutter.git/\u0026#39;: Could not resolve host: github.com \u0026gt; WARNING: your installation of Flutter is 531 days old. \u0026gt; To update to the latest version, run \u0026#34;flutter upgrade\u0026#34;. \u0026gt; Starting device daemon...\u0026gt; [ERR] Error 1 retrieving device properties for sdk gphone... x86 64: \u0026gt; [ERR] adb.exe: device \u0026#39;emulator...\u0026#39; not found Some of these I could handle, and I ran flutter upgrade to get this out of the way. This of course also returned an error.\n\u0026gt; Your flutter checkout has local changes that \u0026gt; would be erased by upgrading. If you want to keep \u0026gt; these changes, it is recommended that you stash \u0026gt; them via \u0026#34;git stash\u0026#34; or else commit the changes \u0026gt; to a local branch. If it is okay to remove local \u0026gt; changes, then re-run this command with \u0026#34;--force\u0026#34;. I committed and pushed all files I had updated locally, not realizing this wasn\u0026rsquo;t exactly what the error was pointing me to - that apparently I had changed Flutter itself? I confirmed this with a web search, finding a StackOverflow answer and - after looking for the directory that I installed Flutter to - I ran the suggested command: git diff HEAD, which returned nothing. I had tried to run the flutter upgrade in my local project directory; apparently this was wrong and I should run it in the installation directory, and doing this returned the same local changes error. Running flutter doctor showed no issues in my installation.\nIt was running git status in the installation directory that showed me the following message:\n\u0026gt; On branch stable \u0026gt; Your branch and \u0026#39;origin/stable\u0026#39; have diverged, \u0026gt; and have 20 and 7227 different commits each, respectively. \u0026gt; (use \u0026#34;git pull\u0026#34; if you want to integrate the remote branch with yours)Untracked files:(use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) .pub-cache/ I ran git pull, which resulted in many merge conflicts. I tried running git status once more, which returned now a massive list of updates and modifications. Trying to cut my losses, I ran flutter upgrade --force, which came back with a \u0026lt;\u0026lt; was unexpected at this time, which was also surprising to me. Another web search got me to just resetting the HEAD, to remove perhaps the changes that got included in the git pull command I tried? I then ran flutter upgrate, a typo, but it did start running flutter upgrade anyway. Still, I cancelled, ran flutter upgrade, and this started the process working normally, then errors with the same local changes error above. I am unsure what changed exactly in my .pub-cache/ file, but a year after last touching the project, I don\u0026rsquo;t imagine it will be relevant. I simply ran the upgrade with the --force command. During this, VSCode prompted me to reload Dart, after the installation was complete, and since my terminal is on the right hand side of my screen, the VSCode message hides any text at the bottom of the terminal - and so I thought the process was complete, clicked reload, and potentially interupted the flutter upgrade process. But it still reloaded the Flutter SDK, and then VSCode again prompted me to run flutter pub upgrade, so sure, great, I ran that too.\nAnother message at the end:\n\u0026gt; Building with plugins requires symlink support. Please enable Developer Mode in your system settings. Run \u0026gt; start ms-settings:developers \u0026gt; to open settings. \u0026gt; exit code 1 So I enabled Developer Mode, and tried to run flutter pub upgrade again, but still in the Flutter installation directory, which gave a expected to find project root in current working directory error, so I guess I need to run this in the actual app directory. Couple of cd ../s later and it tells me \u0026ldquo;no dependencies changed,\u0026rdquo;, so that doesn\u0026rsquo;t make sense given it provided a list to update, and a few packages have apparently been discontinued, like firebase_dynamic_links. The terminal suggests flutter pub upgrade --major-versions, and what the terminal suggests, the terminal gets.\nI moved on, and just ran Run and Debug from main.dart, laughed at the \u0026ldquo;Errors exist in your project\u0026rdquo; message, and clicked run.\nClose, but still failure.\nFirst I get this error:\n\u0026gt; You are applying Flutter\u0026#39;s main Gradle plugin imperatively using the apply script method, which is deprecated and will be removed in a future release. Migrate to applying Gradle plugins with the declarative plugins block: https://flutter.dev/to/flutter-gradle-plugin-apply Deprecation means it still works, so can ignore that one. The key error (hopefully) here:\n\u0026gt; - Where: \u0026gt; Script \u0026#39;C:\\Flutter\\flutter\\packages\\flutter_tools\\gradle\\src\\main\\kotlin\\dependency_version_checker.gradle.kts\u0026#39; line: 375 - What went wrong: Failed to apply plugin class \u0026#39;Dependency_version_checker_gradle$FlutterDependencyCheckerPlugin\u0026#39;. \u0026gt; Error: Your project\u0026#39;s Kotlin version (1.6.10) is lower than Flutter\u0026#39;s minimum supported version of 1.7.0. Please upgrade your Kotlin version. \u0026gt; Alternatively, use the flag \u0026#34;--android-skip-build-dependency-validation\u0026#34; to bypass this check. Great! Just upgrade a whole different library. But this error was informative enough and even as Android Studio booted up, I just changed my build.gradle file to point to version 1.7.0.\nAside from an error in my incomplete edit profile widget, which I commented out for now, I encountered multiple errors with TextTheme colors not being defined. Perhaps this was the .pub_cache error from earlier, and I found another StackOverflow question discussing the upgrade error, and the Flutter documentation. I ran flutter pub cache clean, given that the colors error were coming from material.dart in the cache folder, referencing the flutterfire-ui package, and followed up with flutter pub get, as the terminal told me to do.\nAdditionally, flutterfire-ui apparently was deprecated and broken out to a different repository, so I had to update auth.dart and main.dart. It isn\u0026rsquo;t clear from the new example in the changelog to update EmailProvider() to EmailAuthProvider. Additionally, this is the first time I\u0026rsquo;ve seen the hide option in an import used, such as:\nimport \u0026#39;package:firebase_auth/firebase_auth.dart\u0026#39; hide EmailAuthProvider; import \u0026#39;package:firebase_ui_auth/firebase_ui_auth.dart\u0026#39;; I finally came across the exact issue in the repository. One comment suggests updating the SDK environment versions, but I don\u0026rsquo;t know how to find what the current versions should be. I simply updated the upper boundary to the version I saw listed on the repository, but didn\u0026rsquo;t know what to switch the lower boundary to. I tried manually updating some of the firebase_auth_ui packages, which simply resulted in dependency conflicts and the automatic version solving erroring.\nI ran flutter pub upgrade --major-versions. Trying a build here gave me The plugin firebase_auth requires a higher Android SDK version., so I needed to update to minSdkVersion 23 in the build.gradle file. It notes that \u0026ldquo;Following this change, your app will not be available to users running Android SDKs below 23,\u0026rdquo; so tough luck to those folks. I had to do this twice, admittedly, since I added the whole suggested block to the build.gradle file in the /android directory, when I needed to update the build.gradle file in the /android/app/ directory.\nAnd this did it! The emulator started up with the latest version of the application. Only took multiple hours, and it was a bit of a frustrating experience. All this for a few static screenshots for promotion.\nFinally to actual coding. Estimated time spent today on this is probably 4 hours already. I re-add in screens I had previously taken out to add screenshots.\nMy initial outreach to potential users will just be a WhatsApp message to the target user group, asking for test users, accompanied by a brief overview of key functionality and a screenshots.\nI also made a Google Play Developer account, alongside a new email address for the app, paid the $25 developer fee, and completed the identity verification. I had not realized that to launch, you needed at least 20 test users for a 2-week period.\n11/6/2024 Have been thinking about this project daily. Wrote up a sample feature set for a version 1, 2, and 3 in my Notes application at about 3 AM one night in the past week. I have been considering an initial switch for the test launch to store data on the user\u0026rsquo;s phone locally, to reduce initial latency when logging in, plus to allow offline usage. Offline usage is probably the key feature, especially usage overseas or within buildings with poor cell reception.\nI tried some YouTube videos about this on SQFlite, Hive, Shared Preferences, and Secure Storage. All of these primarily to me seemed like additional work - Shared Preferences wasn\u0026rsquo;t suitable, and SQFlite and Hive seemed like overkill for just initial storing of simple key values. Secure Storage seems like the best option. Prior to taking any action, I just reviewed Firebase to see what I could learn about existing latency and caching options, and started to install the performance monitoring tools available - but it\u0026rsquo;s late, so I\u0026rsquo;ll continue tomorrow.\n11/7/2024 Continuing to try to install the performance library for Firebase. Had to reinstall the flutterfire_cli; no idea why, but I did. Running flutterfire configure after installing the library fails.\n\u0026gt; FirebaseCommandException: An error occured on the Firebase CLI when attempting to run a command. \u0026gt; COMMAND: firebase projects:list --json \u0026gt; ERROR: Failed to list Firebase projects. See firebase-debug.log for more info. In the log file:\n\u0026gt; [debug] [2024-11-08T01:44:31.164Z] FirebaseError: HTTP Error: 401, Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project. Running firebase login in the console tells me I am properly logged in. Clicking on the link in the log redirects to https://developers.google.com/identity/sign-in/web/sign-in, which seems to be an entirely different topic under a \u0026ldquo;Deprecated\u0026rdquo; section, so that\u0026rsquo;s great. After trying to restart this application development after a year, I think that stability is an aspect of any next framework that I would look for before starting.\nDuckDuckGo and StackOverflow solved this in website result 1; it was Copilot\u0026rsquo;s 3rd suggestion, so logging in and out of Firebase solved it. Curiously logging out gave a Invalid refresh token for \u0026lt;email\u0026gt;, did not need to deauthorize message, but not sure what that means, and I don\u0026rsquo;t care enough to explore. But configure finally ran.\n11/8/2024 First morning session. An hour a day is my goal, and the key last improvements I want to make is improving the receipt details page to make it look better. I was thinking that at this point, I should try to stay as close to the default formatting and constructions as possible to make it as easy as possible. I want to reach presentable and no more, so while I can look at a page and make endless small improvements on it, it looks good enough when I stop that a person could see how they use it.\nI did add some small additional information and indicators that would help users see what actions they could take from a screen shot. For example, a button and a disabled button, indicating that actions vary on what can be done, and colored indicators based on data. In my mind, I want people to be able to reach the conclusion that the app automatically reacts to the data stored, and customizes their interactions with each object based on its attributes. On green and red checkboxes, I added \u0026ldquo;(eligible)\u0026rdquo; or \u0026ldquo;(not eligible)\u0026rdquo; to make it clear what the colors indicated, for example, even if this wouldn\u0026rsquo;t be necessary for a daily user in the future.\n11/12/2024 Anxiety is high before launch, and I am struggling to decide between approaches. A casual text message with screenshots asking people to reach out with their information for a test group, or build a professional landing page to obtain emails?\n11/24/2024 A few weeks break again due to family events. And this time, I am deciding not to release the application.\nAs of now, I would no longer consider myself a \u0026ldquo;user\u0026rdquo; of the application, which, to me, is the primary driver of enjoyment when building the application. If I am no longer building it for myself, then, suddenly the application is now a burden. Maintenance, updates, security - not to mention the costs of any database, developer accounts, or APIs I would rely on. Right now, adding another 10 hours a week where I need to sit in front of my computer and code isn\u0026rsquo;t something that I am looking for. I think I was naive to think that \u0026ldquo;finishing\u0026rdquo; a project like this is releasing it - releasing it is starting the project.\nI don\u0026rsquo;t think this is a permanent decision - mid next year, I may need this application again, and if that is the case, I wouldn\u0026rsquo;t doubt that I would enjoy diving back in and building it - but to the extent that I would find value in it.\nThis said, I am quite proud of what I have learned, implemented, and and designed. I learned a new programming language and framework and produced a working mobile app that solved a real-life pain point for myself. I have a much greater appreciation for the individuals who do build and maintain mobile apps and open-source programs by themselves now, surely. I don\u0026rsquo;t feel like this is a failure - I didn\u0026rsquo;t approach this from the viewpoint of making money, or a dream of users - but of identifying a problem and fixing it, and that I did.\n","permalink":"http://localhost:1313/posts/2-years-of-notes-from-building-an-app-i-didnt-release/","summary":"\u003cp\u003eClose to 2 years ago, I had an idea for a mobile application that allowed users to store, submit, and manage tax reimbursements in foreign countries. For 2 years ago, I on and off worked on this idea and had a functioning version on my phone - and for nearly all that time, I never felt like the application was ready to release to potential users - and it doesn\u0026rsquo;t look like I\u0026rsquo;ll ever get it there.\u003c/p\u003e","title":"2 years of notes from building an app I didn't release"},{"content":"The National Review in July published a short opinion piece in July ‘24 entitled How Congress Can Fix Food Stamps. Sam Adolphsen, the author, argues that the cost of SNAP benefits is too high. He comments that \u0026ldquo;about 17.6 million food-stamp recipients are able-bodied adults, and about two-thirds don\u0026rsquo;t work,\u0026rdquo; which leads him to list a series of Republican-led, state-level policies that require SNAP recipients to participate in job training or employment programs. These policy decisions, Adolphsen argues throughout the article, are \u0026ldquo;common-sense\u0026rdquo;, \u0026ldquo;wildly popular among voters\u0026rdquo;, \u0026ldquo;turning a handout into the hand up that [SNAP benefits were] always supposed to be,\u0026rdquo; and are \u0026ldquo;protecting taxpayers while promoting work over welfare\u0026rdquo;.\nHowever, Adolphsen fails to demonstrate key assumptions in his ideologically-driven thesis: do work requirements actually give Americans an opportunity to no longer live in poverty? Is \u0026ldquo;moving [people] from welfare to work\u0026rdquo; an effective way to lower poverty?\nTo be clear, the essay doesn\u0026rsquo;t spend any time focusing on policies that achieve an outcome where families are highly food secure. In his own words, \u0026ldquo;Republican\u0026rsquo;s top priority should be reining in this out-of-control welfare program,\u0026rdquo; referring to the high cost and enrollment. He uses the word “crisis” to describe the $110 billion plus cost per year forecasted for 2024 to 2034 (since revised, see footnote), the fact that an average of 42 million people monthly participated in SNAP in FY 2023, and that two-thirds of able-bodied adults without dependents (ABAWDs) are not working.1\nA generous interpretation is that he believes that getting participants eligible to work into training or employment programs means they won’t live in poverty any longer. But having a job does not mean making enough to live. Cynically, however, I feel that the opinion piece is dismissive of this, discussing reforms born from a desire to cut costs, rather than proposing changes that would assist the Americans who rely on SNAP benefits. And while I do believe there is a place in critical discourse for both approaches, Adolphsen’s essay could have done a bit more to highlight root causes, rather than just the costs, of high SNAP participation.\nSo I\u0026rsquo;ll confine this to these two questions: 1) why SNAP participation and program costs continue to be high, and 2) what are the effects of work requirements as part of the SNAP benefits?\nHow (and why) have SNAP participation and costs changed since 2019? Adolphsen gives a dramatic and imprecise one-sentence explanation:\nPresident Biden has dramatically expanded the food-stamp program, exemplifying his penchant for spending binges, government handouts, and economic ineptitude.\nIn the aftermath of the COVID-19 pandemic, we undoubtedly are spending more on SNAP benefits, especially as participation gradually returns to pre-COVID levels. And Adolphsen is right to split out costs from participation throughout his essay; here, we’ll start with participation in the program.\nSNAP participation spikes during crises, as expected. In 2019, the average monthly SNAP participation was about 35 million people; in 2023, that number was up to just over 42 million driven by the global crisis that saw unemployment and food costs soar. By design, the costs of SNAP will decrease or increase when the U.S. economy is doing better or worse, respectively. In December 2020, roughly 30 million adults reported they did not have enough to eat over the last 7 days; a recent USDA report found that food insecurity has continued to rise since 2021. As of 2024, grocery prices have not fallen to pre-2020 levels (and they aren\u0026rsquo;t expected to), and the unemployment rate (after falling from its spike during government shutdowns in 2020 by mid-2022) is creeping back up. As the USDA Economic Research Service’s Key Statistics page points out,\nHistorically, SNAP spending and the participation rate tend to track the unemployment rate and poverty rate…\nA 1-percentage point increase in the unemployment rate is associated with an additional 2 million–3 million additional SNAP participants. Changes in program policy and administrative practices tend to augment the rise in SNAP participation during economic downturns and contribute to the continued rise in participation during the early stages of economic recovery.\nNotably, the source study only uses data from 1976-2010, so I would be curious to see an updated version of this. Additionally, an overview article from the Pew Research Center indicates that increased food stamp never returned to pre-2008 levels after the Great Recession.2 I would like to see a study about recovery, e.g., how long would it take to return to pre- crisis levels of SNAP enrollment. However, I don\u0026rsquo;t see any clear evidence that continued high levels on SNAP participation are abnormal. I think the article could do a better job of addressing this and provide better insight on how SNAP participation adjusts after social crises.\nBenefits spending also increased to match prices The Thrifty Food Plan (TFP) is the lowest-cost of food plans designed to estimate grocery spending for a family of four, which is guidance used to set the maximum benefit distribution for SNAP benefits.3 It is updated in line with inflation, but received a more comprehensive update in 2021.\nThe Congress-passed 2018 Farm Bill (signed by former President Trump) mandated that the USDA to reevaluate the TFP every 5 years, with the first report due before 2022. Only 13 Republican Senators and 44 Republican House members (19% of Republican house votes made) voted against this bill.\nAs a result of the reevaluation process, the TFP was increased in FY 2022, which was a separate increase from any COVID-19 relief funds, and based on data collected on the costs of items recommended within the plan. From the above linked memo, it found that the cost of the recommended diet was 21% higher than the cost allotted for within the benefits plan at the time. This is a permanent increase, unless a new law is passed that entirely removes it.\nA key point to note is that this TFP reevaluation, unlike previous times, was not required to be cost neutral (page vii of the Thrifty Food Plan, 2021, accessible from the USDA). This is a pivotal point not discussed in Adolphsen’s essay, but does provide context to his complaints about rising costs, and raises questions about whether Biden is truly responsible for this change.\nIn a Fact Sheet released by the Biden Administration, it notes:\nTherefore, as directed by the 2018 Farm Bill, the President will ask USDA to consider beginning the process of revising the Thrifty Food Plan to better reflect the modern cost of a healthy basic diet. This memo was released January 22, 2021. Yet the TFP 2021 report states that “the process to update the Thrifty Food Plan began several years ago…”4 The TFP 2021 report only notes President Biden’s contributions in two places (in a 125 page report):\nPresident Joseph R. Biden committed via Executive Order 14002 to prioritize the review.5\nPresident Joseph R. Biden emphasized the commitment to the reevaluation in Executive Order 14002 on January 22, 2021.6\nThe cited Executive Order 14002 is incredibly vague, and the TFP reevaluation had to be completed by 2022 anyway. Here is a New York Times article framing the TFP update positively for the Democrats, Biden Administration Prompts Largest Permanent Increase In Food Stamps, yet goes on to note that Biden’s only contribution was to “[urge] the department to speed up the process,” which happened about 10 months until the report was due anyway. Plus, the Secretary of Agriculture at the time, Tom Vilsack, is quoted goading Republicans: “‘A majority of Republicans in the Senate and House voted for this,’ Mr. Vilsack said. ‘They deserve credit.’”\nApparently Republicans did not realize that what they were voting for allowed the USDA to drop the cost-neutral requirement. The same New York Times article states:\nIn allowing the plan’s value to rise, officials argued they were following the 2018 law, which required new standards but did not specify whether costs should stay the same\u0026hellip;\nBut as hints of the benefit increase spread last week, Republicans pushed back. Former Representative Mike Conaway, a Republican and chief author of the 2018 law, said it was written “assuming the precedent of cost-neutrality would be followed” and warned the administration against “unilateral overreach.”\nSo this may have just been a poorly-written law. It is also hard to know to what extent this was debated internally, e.g., was this a ‘loophole’ that the evaluators took advantage of, or was this the widely accepted interpretation of the law at the time of writing in the USDA? I would be very interested in learning more about who identified this and the process internally to come to these conclusions.\nA February 2023 hearing saw Republicans denouncing and blaming FNS (Food \u0026amp; Nutrition Security) leadership for this change. Testimony from the Deputy Undersecretary indicates a “fundamental difference of perspective regarding what the 2018 Farm Bill directed for the re-evaluation” between the USDA and a Government Accountability Office report released in 2022.7\nIt is this GAO report that we get the closest to practical answers. In response to Biden\u0026rsquo;s Executive Order and Fact Sheet, \u0026ldquo;FNS officials said they hired additional staff, stopped work on other projects, and worked overtime.\u0026quot;8 As to the cost-neutral claim, a footnote in the GAO report notes that \u0026ldquo;USDA OGC officials told [GAO] that holding costs constant during prior TFP reevaluations was an administrative decision made by the Secretary of Agriculture, not a legal requirement,\u0026rdquo; which seems at odd with the claims made in the TFP 2021 report.9 There is not further substantive discussion of this interpretation, but I did find a Senate Fact sheet reiterating that this complied with the law.\nPutting the history and any assignation of responsibility aside, how did this change affect costs? From a 2022 CBO report, the change in the TFP is said to be \u0026ldquo;main source\u0026rdquo; of a $266 billion increase in estimated outlays from 2022 to 2031.10\nWhat happens when work requirements are enforced for eligible SNAP participants? A 2023 report from the Center on Budget and Policy Priorities states that: \u0026ldquo;strong research evidence on SNAP’s existing work-reporting requirement shows that it does not increase employment or earnings but does cause many people to lose food assistance.\u0026rdquo; Despite this, the 2023 Fiscal Responsibility Act doubled down on work requirements, limiting the waivers that states took advantage of during the COVID-19 pandemic. The maximum age for work requirements also was increased for ABAWDs, from 52 to 54.\nAdolphsen claims that \u0026ldquo;in Kansas, the Republican-controlled legislature passed veto-proof bills in 2023, expanding the age range of able-bodied adults required to participate in job training,\u0026rdquo; and goes on to claim that \u0026ldquo;participation in such programs has more than tripled.\u0026rdquo;\nWhile he did not provide a source or context, I found reports from the Kansas Department for Children and Families. I think the bills he is referring to should have went into effect in July 2023. So my best guess is that the FY 2024 Participation Report should show this change; page 17 shows the \u0026ldquo;Food Assistance Employment \u0026amp; Training Program Caseload and Expenditures\u0026rdquo; and indicates July 2023 had 798 adults, with June 2024 having 1,266 participants, which is not triple. The FY23 monthly average was 580 adults; the FY24 average was 1,307. I also thought perhaps he combined training programs, but the \u0026ldquo;SNAP WORK PROGRAMS (GOALS)\u0026rdquo; (page 22) shows a large drop in participants from 557 in FY23 to 273 in FY24.\nThere is a PDF from the Kansas that reports on FY 2023 food assistance participation (which ends in July 2023); he may be referring to page 12, a table titled \u0026ldquo;Food Assistance Employment \u0026amp; Training Program Caseload and Expenditures\u0026rdquo;, which shows the number of adults enrolled each month increasing from 281 in July 2022 to 843 in June 2023 - which is exactly tripled, amusingly - but the following chart, \u0026ldquo;Food Assistance Employment \u0026amp; Training Program - Historical Caseload and Expenditures Detail\u0026rdquo; shows that the average number of adults enrolled monthly increased only from 424 in FY22 to 580 in FY23 (page 13).\nPage 15, Kansas FY23 current participation report\nOn page 15, there is a SNAP Work Programs (GOALS) table, which is confusing, as it shows \u0026ldquo;Avg Monthly Adults Receiving Assistance\u0026rdquo; increase from 39 in FY22 to 557 in FY23! Yet the \u0026ldquo;Avg Monthly Adults Enrolled,\u0026rdquo; (the next column over) shows a decrease from 495 in FY22 to zero in FY23.\nPage 22, Kansas FY23 current participation report\nThis may be a reporting error, as page 22 of this document has a chart \u0026ldquo;SNAP WORK PROGRAMS (GOALS) Monthly Average Number of Adults Receiving Assistance\u0026rdquo; that shows 495 in FY22 and 557 in FY23. So the numbers may be simply mixed up in the table. It doesn\u0026rsquo;t seem to be corrected in the FY24 report either.\nSo, I\u0026rsquo;m not quite able to pinpoint what exactly Adolphsen is measuring. The number of ABAWDs enrolled, however, did decrease from 13,504 in July 2023 to 9,964 by June 2024 (page 8), but to what extent that can be attributed to enforced work requirements, I\u0026rsquo;m not sure. I found one supporting news article that discusses wider decreases in program participation in FY 2023 after previous requirements. Another article from the Kansas Reflector notes how a paid lobbyist supporting work requirements up to age 60 could not provide any evidence it would work or that previous reforms were effective.11 I did see discussion that food pantry usage was increasing in 2021, but the USDA 2023 food insecurity report does not show a statistically significant change between 2018-2020 (11.3%) to 2021-2023 (10.6%).12\nSimilarly, I found next to nothing on the impact of Idaho\u0026rsquo;s changes. This is despite the Governor \u0026ldquo;urging caution\u0026rdquo; and recommending that legislators \u0026ldquo;closely monitor the impacts.\u0026rdquo; I see some news articles on Louisiana\u0026rsquo;s enforcement; here, 15,000 recipients lost benefits in the summer of \u0026lsquo;24. Again, the article mentions the department \u0026ldquo;has no information about the 15,000 people who were disenrolled since the fall and whether they have found employment, or what sort of wages they are earning if they did, a spokesperson said.\u0026rdquo; This is surprising to me that the state did not take the chance to follow up to identify outcomes, but again, the critic in me feels that this demonstrates that legislators thought whether people were successful in finding quality jobs was secondary to the true purpose of the legislation: to just decrease participation in SNAP. Again, data (collected and pushed by the FGA) doesn\u0026rsquo;t actually show any clear successes.13\nIn the second to last paragraph, the author claims that work requirements for SNAP benefits are “wildly popular,” noting that “80 percent of swing-state Wisconsin voters cast a ballot in favor of welfare work requirements,” without linking to any background on the measure.14 Checking Ballotpedia shows that “casting a ballot\u0026hellip;” really meant less than 2 million people answered a vague advisory question that was not legally binding. The question in full: “shall able-bodied, childless adults be required to look for work in order to receive taxpayer-funded welfare benefits?” The Wisconsin State Journal, which advised voting yes, also recognized the lack of merit in the question, stating: \u0026ldquo;the question is too cute by half in seeking to manufacture outrage.\u0026rdquo; I don\u0026rsquo;t think saying it was a question designed to be manipulated as a marketing tool is out of line.\nAgain, studies that have looked at this find very little evidence that work requirements lead to stable, well-paying jobs. An NBC News report compiled 12 studies, and all reviewed found decreased SNAP enrollment while 50% found no impact on employment, 25% found mixed to mostly none, and 25% found positive effects.\nLastly, the piece aside, it is frustrating to read the some of the outwardly hateful comments posted along with the article. Very few are well-reasoned, and most rely on gross generalizations and are very unkind. After some time, the comments appear closed to non-subscribers.\nAs something to follow up with, we can see the author’s opinions in his testimony to Congress from 2020.\n","permalink":"http://localhost:1313/posts/questions-on-how-congress-can-fix-food-stamps/","summary":"\u003cp\u003eThe \u003ca href=\"https://www.nationalreview.com/\"\u003eNational Review\u003c/a\u003e in July published a short opinion piece in July ‘24 entitled \u003ca href=\"https://archive.ph/RcWdh\"\u003eHow Congress Can Fix Food Stamps\u003c/a\u003e. Sam Adolphsen, the author, argues that the cost of SNAP benefits is too high. He comments that \u0026ldquo;about 17.6 million food-stamp recipients are able-bodied adults, and about two-thirds don\u0026rsquo;t work,\u0026rdquo; which leads him to list a series of Republican-led, state-level policies that require SNAP recipients to participate in job training or employment programs. These policy decisions, Adolphsen argues throughout the article, are \u0026ldquo;common-sense\u0026rdquo;, \u0026ldquo;wildly popular among voters\u0026rdquo;, \u0026ldquo;turning a handout into the hand up that [SNAP benefits were] always supposed to be,\u0026rdquo; and are \u0026ldquo;protecting taxpayers while promoting work over welfare\u0026rdquo;.\u003c/p\u003e","title":"Questions on “How Congress Can Fix Food Stamps”"},{"content":"I re-deployed 8 Red Squares, a site that allows you to play through the 8 Queens Puzzle on different sized boards.\nFuture enhancements I\u0026rsquo;d like to add are\nTimer (for each segment), and total running time until the users solves n=8.\nBetter mobile support (board size 9 and 10 don\u0026rsquo;t handle small screens well).\nFoundational solutions checklist, e.g., if a user wants to find all possible arrangements (excluding symmetries and rotations).\nAssistant, e.g., allow a user to turn on CSS highlights that show conflicting squares, or hints.\nOptionally pause switching board sizes, allowing the player to examine their solution, e.g., a \u0026ldquo;Jump to next puzzle\u0026rdquo; option, or retain the solution when they navigate to a previously solved board size.\nPlay it at https://leppekja.github.io/8redsquares/. The site uses React; I originally built it to learn React and how to deploy a site to a cloud-based provider (AWS Amplify), but now uses the gh-pages package and is deployed on GitHub Pages.\n","permalink":"http://localhost:1313/posts/play-8-red-squares/","summary":"\u003cp\u003eI re-deployed \u003ca href=\"https://leppekja.github.io/8redsquares/\"\u003e8 Red Squares\u003c/a\u003e, a site that allows you to play through the \u003ca href=\"https://en.wikipedia.org/wiki/Eight_queens_puzzle\"\u003e8 Queens Puzzle\u003c/a\u003e on different sized boards.\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://laggingindicators.blog/wp-content/uploads/2024/09/image-5.png?w=644\"\u003e\u003c/p\u003e\n\u003cp\u003eFuture enhancements I\u0026rsquo;d like to add are\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eTimer (for each segment), and total running time until the users solves n=8.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBetter mobile support (board size 9 and 10 don\u0026rsquo;t handle small screens well).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eFoundational solutions checklist, e.g., if a user wants to find all possible arrangements (excluding symmetries and rotations).\u003c/p\u003e","title":"Play 8 Red Squares"},{"content":"I recently bought the Kensington Slimblade Trackball to replace the Logitech MX Master mouse that I have been using for the last year. This is the first time that I\u0026rsquo;ve used a trackball. A couple of thoughts worth noting that are either omitted from or in conflict with other reviews:\nThe device is too large for me. It takes up almost an entire mousepad, and it is wide enough to force frequent movement between the trackball and the keyboard (I use a Glove80). I blame this partially on the desk, as it requires a roll-out keyboard holder that was not made to accommodate the split keyboard and the trackball. But for a trackball with \u0026ldquo;Slim\u0026rdquo; in the name, I expected it to be smaller.\nThe “keys” are irritating to press. They require too much of an actuation force, if that is the right term. I would like if a touchpad-like-tap was possible. This is especially true because the design is wide enough that one key is comfortable for my thumb, but the other really only for my pinkie finger, as my index and middle fingers are being used to control the trackball itself. Plus, the top two keys above the trackball are uncomfortable to press, so much so that I never use them.\nI would like if tilting was somehow available for the trackball, to decrease the wrist rotation that is require to use the trackball and click the surrounding keys. It is too flat to use and requires a similar wrist position to a trackpad.\nThe much-maligned scrolling noise does not bother me, although it is odd that it can not be disabled, especially as it is office equipment. It is hard to scroll without accidentally messing up and just moving the mouse as well; for example, scrolling sideways to highlight part of a line.\nThe trackball is a dust and cat hair magnet, and all of the dust and cat hair will find itself stuck to the trackball support bumps, or into the indent where the sensors are. This either slows down the trackball’s movement once enough dust has accumulated, or entirely interferes with the movement sensors. I need to clean this at least once a week.\nKensington Works isn’t particularly great. On my computer, it doesn’t save the altered mouse settings between shut down and start up. I need to manually start up the Kensington Works software for the changes to take effect. There are also no easy-switch settings profiles, e.g., if I want to switch using the trackball between my left- and right-hands, re-mapping the keys manually is required.\nI have almost completely stopped using the writing pad and pen in favor of the trackball. Wrist pain has definitely subsided by using the trackball over the previous mouse (Logitech Master MX).\n","permalink":"http://localhost:1313/posts/from-a-mouse-to-a-trackball/","summary":"\u003cp\u003eI recently bought the Kensington Slimblade Trackball to replace the Logitech MX Master mouse that I have been using for the last year. This is the first time that I\u0026rsquo;ve used a trackball. A couple of thoughts worth noting that are either omitted from or in conflict with other reviews:\u003c/p\u003e\n\u003cp\u003eThe device is too large for me. It takes up almost an entire mousepad, and it is wide enough to force frequent movement between the trackball and the keyboard (I use a Glove80). I blame this partially on the desk, as it requires a roll-out keyboard holder that was not made to accommodate the split keyboard and the trackball. But for a trackball with \u0026ldquo;Slim\u0026rdquo; in the name, I expected it to be smaller.\u003c/p\u003e","title":"From a Mouse to a Trackball"},{"content":"What follows are a few takeaways from a recent app launch, where I had some successes and some things I had to fix. I also maintain dashboards for a wide set of clients on a different project that will be overhauled soon, and would like to apply these learnings during the redesign.\nThe three guiding business questions for initial design are: How are we getting users?\nWhat our users are finding value in when using the application?\nWhat problems are users are encountering when using the application?\nPerhaps this verges on trivial, but it was helpful to think about these three questions when working with little input from stakeholders. This also shapes how the dashboard is organized, providing a storyline to follow, or natural groupings in which to place metrics and charts within. Users may not look at dashboards until the application has launched, and they may not have feedback until after they see something they dislike or don’t understand.\nOf course, these will become more specific over time, so it is essential to stay close the business needs and monitor the questions being asked and results being shared, then to build these into the dashboards. At the top level, consumer questions might be very vague, e.g., how is the product doing, or has anything changed in April that I should know about? But that’s okay - start with general indicators, and over time, incorporate questions that are commonly raised. At the same time, you need to be able to defend and recommend: for the former, to justify the decisions behind what to show on the dashboards, and for the latter, demonstrate why certain variations are better proxies than others.\nThe audience for your dashboards will obviously influence the granularity of the sub-questions address. Executive leadership may care less about device types past whether web or mobile users are driving adoption, while specific device versions may serve as a key data point for product design teams.\nLastly, when having initial conversations, dashboards should be discussed as cohesive reports. Many people, when deciding they want a dashboard, quickly start listing out metric definitions rather than focusing on the questions they value. Oftentimes, people will need guidance on what metrics exactly should even be used to measure something, so starting with ‘what to track and what to show’ is backwards. Instead of giving people the implicit definition of charts on a page (and people will happily tell you if they want a bar chart or pie chart rather than focus on whether the metric is meaningful), frame the conversation around answers to questions, like a research report was being done. The stakeholders should not design the dashboard!\nCharts should explain themselves. I wrote what I thought was a nice user-friendly explanation of what a chart meant right next to it. I then received many questions about what the chart meant and how to use it.\nUnfortunately, data visualizations are often not as easy to understand from the consumer point of view as I think they are. I fall into this trap frequently, trying to design a beautiful and engaging chart that fails in its key goal: deliver information effectively. This is the core of every chart in a dashboard, and more often than not, a large number with a title, subtitle, and basic trend indicator is going to be easier and quicker for a user to understand.\nThere is an art to writing good helper text. I like to have the title of the chart be a question directly addressing a business need, e.g., how many users are active today?, and have the subtitle should answer the question.1 The subtitle of the chart should embed the metric into plain text, e.g., 37 users logged-in and viewed a post today.2 The title guides the user to what they are looking for, and the subtitle tells the viewer how to use the answer in a sentence.3\nTechnical definitions and sources should be embedded, but not intrusive. Standard footnotes should suffice, and fuller documentation should be linked to for complex calculations. As a simple example, take the chart “how many users viewed profiles?”: a subtitle may state “32% of users viewed more information from the search results for at least one restaurant”, and the footnote can state “measures the count of unique logged-in users this month divided by total active users this month with at least one click on a More Information button in at least 1 session.” However, if there are projections about the percent of users that will click it next month, I would just include a link to a document that explains the assumptions behind those.\nA number is almost never a simple division like on the product analytics websites claiming it is. The application or site will go through many UI and UX changes.4 Bugs in tracking happen, or the product changes, or things are deleted or inactivated, or testing and bot data need to be cleaned and removed… Some instances will require you to share this in the published dashboard, while others won’t, but these adjustments are context specific. A helpful rule for me is if they affect the visual appearance of the chart, then I need to either change the chart or add a note.5\nLastly, well-formed titles, subtitles, and footers should point consumers in the right direction about limitations when using the numbers. Measurable numbers are usually proxies for what we want to know. Once a number is put on a dashboard, you have no control over how it is shared out or with what context. The distinctions between users, sessions, visitors, page views are technical, more technical then most consumers will care to distinguish between.\nSo be mindful of what terms you use, and explain limitations succinctly. For example, for a chart titled “Which products are potential users looking at?,” I would rephrase the subtitle “Product A’s landing page was the most popular in May” to “Product A’s landing page had the most online views in May, based on total anonymous page visits across web and mobile.” This does not explicitly state the limitations, e.g., a user could have loaded the same page over and over on different unlinked devices to game the metric, but it at least acknowledges the calculation method and gives the consumer a starting point to discuss or ask about. And as always, you can include a technical definition in a footer or additional usage documentation for users who are interested.\nCurate charts aggressively to key needs only. Too many variations of a chart with similar business outcomes will lead to user confusion, and users will gravitate toward the best looking number. Obviously, complementary numbers are needed, like including rolling averages of active users that make long-term trends clearer.\nDemonstrate events in relation to the relevant or entire user base, depending on which is appropriate. Other segments of interest could be different time periods, sub-populations, or similar actions, but these should be curated such that any comparison from one segment to another is always easily interpretable, statistically valid, and relevant to business questions.\nThe discovery, sign-up, and onboarding flow will be the primary focus. It might be assumed within the group that the app provides value to the user, and that the discovery and onboarding is the hump to go over. This means defining the funnel for acquisition and activation and clearly communicating this. At the same time, avoid steps that lead to over-optimization early on, e.g., click-through rates on intermediate pages that will be targeted as ‘inefficiencies’ and gamed to increase rates. Focus on the actions that should be providing value.6\nI think the only exception to this is showing vanity metrics, e.g., those that will only go up, those that have little practical use for decision making, etc. as these will be requested for marketing use. Again, you will need dashboards that show the success of the application, and I should not disregard this. An example of this would be something like the all time number of page views, which might be helpful for a LinkedIn post, but nothing else. Metrics that are only useful for marketing are valuable for the business, which is something that I have not appropriately recognized in the past at times. In these cases, pair marketing metrics with value actions, e.g., conversion rates or returning rates, to emphasis their importance, or create a separate section entirely, depending on the audience.\nChart design should accommodate growth. Gracefully handle extreme values and lopsided outcomes in visualizations. When choosing a chart type, ask how will this look in a situation where all values are zero, or when only one data point is very high, or the distribution is heavily skewed?\nPrepare for situations where values are zero. Handle null values, divisions by zero, and appropriate wordings of titles and subtitles. For me at least, bugs inevitably will surface on the dashboards - how can the chart fail without degrading the user experience entirely? For example, consider a chart stacked bar chart that shows the percent of users that are new versus returning today. The subtitle could read “{X}% of users today are returning users;” in this case, if zero users were active today, then the subtitle should update its wording to say “No users were active yet today” rather than “NaN% of users today…”\nPrepare for situations with heavy clustering when using charts that display individual features, e.g., scatter plots, dot plots. What if growth occurs very quickly? In faceted or stacked charts, what if one segment increases very quickly (and causes outlier or scale issues?) The chart design should consider the hypothetical distribution of possible values to the best possible extent. A representative example: consider a single stacked bar (like this) with a segment label overlaid directly on each section of the bar. If one segment accounts suddenly for a large majority, the labels of other sections will be squished together and overlap into an unreadable mess.\nTrust is lost quickly, and don’t assume it exists at the outset. Consistency is key, and the difficulty of managing this is multiplied by how many reporting systems exist. Small differences will be quickly identified and questioned; as a trivial example, an internally surfaced activity log may not have test users filtered out, but dashboards do filter out testing traffic. Another BI user may calculate things differently then you. A key example I have dealt with is reconciling and explaining internal logging versus Google Analytics tags, where ad blockers may contribute to sizable differences in reported numbers. Deliberate coordination is required in these instances, but very clear documentation about calculations can prevent some of these issues.\nI’ve found myself in the situation on a different project where, because of data quality issues arising from tracking bugs in the past, users may check the dashboard, then send a note to confirm that the number is accurate to use for many months after. Additionally, some users may not care to even log a report and instead simply disregard the dashboard entirely. When people are first looking at the dashboards, they may come in with doubt as well, unsure about what the numbers mean and how to use them. It is an open question for me as to how to ameliorate this issue apart from accessible design.\nThe dashboards need to be fast and visually appealing. It may seem odd to bring this up under the topic of trust, but I think for many people, this is a signal of competence. People will not wait 15 seconds for a large set of metrics to load. Start with small amounts of pre-aggregated data, then load more where needed at the user’s request. I work with a system where the dashboard refreshes after the user has loaded the page with cached data, so they may be on the dashboard, then suddenly see the numbers change, which is poor design, especially when it takes a minute to update.\nOn the visual side, creating charts in Excel might work, but people don’t find them engaging. In many cases, dashboards are just reflections of progress, and progress doesn’t feel as good when it doesn’t look pretty. Professionalism goes a long way, and a modern design is a part of this.\nIt is inevitable that users will have questions that aren’t answered in the dashboard. I personally don’t think this is a failure, but you need a process for it. Questions become reports. Reports which need to be repeated should become dashboards. Do not try to answer a question with a dashboard, but with a report. The dashboard is a live summary of the underlying validated research.7\nThe minimum ‘user journey’ for a dashboard consumer is to have a question, identify what the answer to the question is on the dashboard, then be able to form a good ‘why’ question based on this that they can follow up on if needed. So a user having a question on a dashboard and wanting to dive deep is okay\nAn approach for a metric in a dashboard I have heard is overview number, drill down to a pre-defined segment, then row view of the data. To me, this is the best version of the ‘self-serve analytics’ trend in which products promise that dashboard consumers would be able to answer questions for themselves.\nSelf-serve analytics doesn’t account well for early stage launches in which it is more common for bugs and tracking issues to find their way downstream. Investigative questions, or why something occurs, need to be explored fully, which may require looking over data quality, third-party data, custom queries, etc., for small teams. It also assumes a high level of statistical knowledge and data architecture for anything past basic applications and questions.9 It requires consumers to properly translate their questions into a calculation, which is an acquired skill. Alternatively, it takes a large amount of work for the dashboard designer to constrain users to only certain comparisons that are valid.\nThe proper workflow should be a dashboard that a user has a ‘why’ question on, which is then referred to a analyst, who then creates a specific report based on expert knowledge of the way the data is collected and aggregated. This is the subject of many complaints, that these questions can’t self-answered within the dashboard, but personally, I think this is the exactly right workflow. Dashboards should allow people to form good questions that can then be handed over to a subject-matter expert.\nLastly, people will want to export the data to review it themselves in Excel or Google Sheets, and they will need a CSV download. If you do include this, expect many questions from them about their self-aggregated findings. If you do not, expect requests for exports. My best advice is make exports available in the context of getting data, e.g., I need the names of contacts of this segment to reach out to them, but not for external data analysis.\nPrioritize flexibility when choosing an initial framework. Having used dashboard software that prioritize UI builders, e.g., Power BI, Tableau, I would recommend lower-level dashboard frameworks. I agree with the current marketing campaign for Observable Framework: “the best dashboards are built with code.”\nRecently, I deployed Observable Framework through an Azure Static App from a GitHub repository, leveraging GitHub Actions to update data regularly and the Azure Entra ID for authentication (but they do just have a easy password protection also). Certainly, learning this took more work than it would have to pay a larger sum of money to just leverage an existing platform. Yet it keeps costs low, is extensible, offers professional visualizations, allows for clear metric definitions in code or templates that are not locked into a vendor’s platform, makes extending existing visualizations into longer one-off reports easy (with Observable notebooks), and leverages common languages (vanilla JS, Python, YAML) rather than vendor-specific terminologies or languages. Note that learning Plot (and D3 where needed) is still a big lift, but the declarative nature of Plot is very similar to other visualization libraries that future analysts should be familiar with.\nNote that for many applications, a plug and play solution (Google Analytics, PostHog, etc.) might be the simplest to start with. Note that this won’t work for applications that work with regulated data, (HIPAA, for example), and still requires a significant amount of management, experience, and maintenance.10 With teams I’ve worked with, Google Analytics is the standard that users will make comparisons to if you do decide to build something outside of this. Additionally, as a solo developer working on projects - if I only need a dashboard for myself - I leverage open source projects that avoid third-party tracking, but do provide pre-built dashboards.\nAuthentication and data security is frustrating to deal with. Ensure that your dashboard tooling can access your database prior to trying to build anything on it, that users will be limited to their permissions, that managing users and permissions can scale, etc. But that is outside the scope of this post.\n","permalink":"http://localhost:1313/posts/lessons-learned-on-dashboard-design-for-early-stage-apps/","summary":"\u003cp\u003eWhat follows are a few takeaways from a recent app launch, where I had some successes and some things I had to fix. I also maintain dashboards for a wide set of clients on a different project that will be overhauled soon, and would like to apply these learnings during the redesign.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eThe three guiding business questions for initial design are:\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eHow are we getting users?\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eWhat our users are finding value in when using the application?\u003c/p\u003e","title":"Lessons learned on dashboard design for early-stage apps"},{"content":"Site is accessible here, and the accompanying GitHub repository can be accessed through that site as well. It is based on a Google Alerts RSS feed, built every ~6 hours with Jekyll and GitHub Actions.\nMonthly commentary will be included on that site in the future. Immediate next steps are to add in more news aggregators as sources, to try and get articles that are missed. I would like to integrate Google Scholar as well, but it does not appear they offer an RSS feed or any simple method. Article display filtering is currently done on a keyword basis, which has been working fine, but would like to move to a classifier model.\nIn the next few months, ideally will introduce automated tagging and some basic client-side filtering, as well as moving older daily updates to a separate page. May add in a food access and food banks/pantries daily updates page on there as well, which would be helpful for me to stay up-to-date.\nRead about SNAP benefits at: https://leppekja.github.io/snap_news/.\n","permalink":"http://localhost:1313/posts/daily-snap-news-aggregator-launched/","summary":"\u003cp\u003eSite is \u003ca href=\"https://leppekja.github.io/snap_news/\"\u003eaccessible here\u003c/a\u003e, and the accompanying GitHub repository can be accessed through that site as well. It is based on a Google Alerts RSS feed, built every ~6 hours with Jekyll and GitHub Actions.\u003c/p\u003e\n\u003cp\u003eMonthly commentary will be included on that site in the future. Immediate next steps are to add in more news aggregators as sources, to try and get articles that are missed. I would like to integrate Google Scholar as well, but it does not appear they offer an RSS feed or any simple method. Article display filtering is currently done on a keyword basis, which has been working fine, but would like to move to a classifier model.\u003c/p\u003e","title":"Daily SNAP News Aggregator launched"},{"content":"Note a slightly different format to topic, rather than state-based.\nSnap Interview Waivers in some places expiring Expiration of Waiver of Interview Requirements for SNAP Benefits in Mississippi\nBeltrami County SNAP interview waiver ends April 30\nI would be very curious to see any study performed exploring differences in program administration and case outcomes between while the waiver was in effect, and the before / after where the waiver is not in place. How has the speed of applications changed? Overpayment or underpayment rates? What do the caseworkers think about this change? I also came across this Reddit thread on the impact of interview waivers, but would like to see a structured case study.\nWhat does better integration between SNAP and higher education look like? Guaranteed college financial aid coming to WA students on food assistance, and the bill is here. Students in 10th, 11th, or 12th grade need to demonstrate family participation at some point in these years. \u0026ldquo;WCG award covers tuition, and services and activities fees, for 15 quarter credits or the equivalent at the state\u0026rsquo;s public institutions. A student is eligible to receive the WCG for five years or up to 125 percent of the published length of the student\u0026rsquo;s program.\u0026rdquo;\nThe adjustment from COVID-19 period policies that sped up SNAP renewals to are expiring, causing delays. From an article in the Santa Fe Reporter, \u0026ldquo;Human Services Department Director of Communications Marina Piña tells SFR the increase in individuals experiencing issues and delays with SNAP benefit renewals can be explained by the April 2023 end of COVID-related federal policies that allowed for automatic renewals and led to \u0026lsquo;a higher volume of applications and renewals than usual.\u0026rsquo;\u0026rdquo;\nMA students urge lawmakers to fund campus anti-hunger efforts, just as SUNY Cobleskill opens food pantry with additional funding. Before reading these, I did not consider the role that state legislators would have in disbursing funds to schools to combat food insecurity; I think I assumed funding came from private endowments, college administrators, or NGOs. For example, the EKU campus is one of first in Kentucky to accept “SNAP’ benefits. But clearly lawmakers have a role in deciding eligibility for SNAP funds for college enrollees, as raised in Forbes recently in their article: 1 In 5 College Students Have Kids, How Are States Supporting Them?\nSurvey finds 67% of UNM students face food insecurity, but the linked news report does not share the survey, so I can\u0026rsquo;t give any more information, but this is a very high estimate that demands attention and review; it is nearly double a 2019 meta-review by Nikolaus et. al. I saw a similarly high estimate from a 2021 report (Food Insecurity at Urban Universities), but this is from one university and it does not appear to be a representative sample, nor do the indicate that the team used the USDA-recommended food insecurity screener? Here is a 2022 literature review (which focuses on student athletes), but finds a similar average of slightly above 30% for the general student population. This report from 2018 (Rethinking SNAP Benefits for College Students) mentions a few surveys that indicate results around 50% of those surveyed experienced food insecurity.\nThis smaller (n=33) unreplicated (as far as I know) 2019 study focused on whether the USDA screener was valid for college students and left unsure of its validity. But honestly, I don\u0026rsquo;t know about how reliable research like this is; other studies discussed in the above noted there are differences in responses by gender.\nShedding light on Food Insecurity at MSU (Montana) gave a perspective from a student that increasing awareness, more application guidance, and decreasing the stigma involved with SNAP are good steps moving forward.\nCollege students eligible for food assistance deterred by confusing requirements is a news article based off of the following research paper (n=14): SNAP Student Rules Are Not So Snappy: Lessons Learned From a Qualitative Study of California County Agency Workers. Some nice lessons there, even if it is a smaller study. Do note that it claims \u0026ldquo;CalFresh participation remains low, with approximately 78% of those eligible not receiving benefits,\u0026rdquo; based on the Rethinking SNAP Benefits for College Students and Senate Bill 77 CalFresh Student Data Report. I think both linked reports are very up-front about the serious limitations of these estimates, so I would be wary of just reporting out that number.\nD-SNAP alert and plans to clean data Replacement benefits available for SNAP recipients impacted by storms\nI did find where D-SNAP historical records are on the USDA website, so will work on cataloging those and formatting the data. Somehow failed to identify that I needed to click the map to see older years.\nPuerto Rico doesn\u0026rsquo;t have SNAP, but NAP ‘The right thing to do’: Puerto Ricans in Central Florida fight for SNAP benefits I was not aware that Puerto Rico\u0026rsquo;s food assistance program was more limited, and here is a nice introduction to the NAP program from the Center on Budget and Policy Priorities. There is actually a feasibility study for Congress from 2022, and an updated report from 2023 is accessible from the USDA website. Here is the original report in Spanish.\nHow should we think about nutritional incentives for SNAP? An op-ed supporting nutrition restrictions on purchasing groceries with SNAP benefits. As brought up before, an incentives-based approach would likely be a more feasible approach (like doubling benefits at farmers markets) - cataloguing what is and is not healthy, political pressure from grocery stores fearing decreased spending from SNAP, etc. But I am curious about alternative mechanisms to encourage the purchase of healthier foods. In most states, ultra-processed foods taxed more, I thought; Yet sales tax is not charged when using SNAP. Oddly, when using a mixture of cash and benefits to pay, it appears that first the SNAP benefits are applied to items that can be taxed, and the cash is used to purchase exempt items. This workaround does seem a bit odd to me.\nAn almost nice write up on the subject is here - but in one part, it points out that since this is the case, SNAP benefits likely over count the amount of taxed food (and the taxed food in question may be more often unhealthy food) - but the summary of the original study points out that it uses the entire transaction in question, not just the portion paid for by SNAP benefits.\nPBS did a nice write up and filmed segment on the state laws limiting access to SNAP.\nMost of the stuff that you get at the food banks are like very high-carbureted or starchy items. And my son\u0026rsquo;s a diabetic, but we have to use it. We have no choice.\nBetsy Cruz\nSlightly unrelated point, but it shows the importance of meeting dietary requirements of food pantries for individuals. That aside, the article notes that Kansas is one of five states where you have to apply for child support when participating in SNAP.\nPreventing SNAP fraud is always in the news WebXtra: Texas HHS warns of scam targeting SNAP benefit recipients A convenience store went to court in Massachusetts after being accused of trafficking SNAP benefits, and lost. It is worth reading the opinion to learn more about how the USDA identifies potential fraud through statistical analysis of transaction data, and how the burden of proof is placed on the store, rather than the USDA, to demonstrate that there is no wrongdoing. Components of the statistical analysis included how a small number of households made many transactions in a short time period, how similar stores (selected apparently by their close proximity and similar inventories) did not have any of these transactions, how large the transactions were (“72% higher than an average transaction conducted at a convenience store in Essex County”, p.12).\nAnd to combat this, the FY 2024 SNAP Fraud Framework Implementation Grant opened for state submissions this month.\nMore and more mobile applications are making EBT payments accessible. DoorDash and Walgreens Launch Unprecedented Access for SNAP Customers,\nGiant Eagle, Flashfood app now taking SNAP benefits\nAmazon debuts grocery delivery program for Prime members, SNAP recipients\nUber Eats to accept federal benefits payments in late 2024\nRedner’s Markets’ e-commerce sales climb nearly 7% after accepting SNAP online\nSNAP clickbait articles are everywhere, especially around payment distribution times. The worst offenders include Marca.com, La Grada, AS, and Tododisca. These articles clog up any serious news stories, and I am curious as to whether they are truly helpful to individuals. I will occasionally see local news outlets report on this but not close to the frequency of the websites listed above.\nTo combat this, and to automate this process a bit more, I am putting together a ML classifier that categorizes articles picked up by a Google Alerts RSS feed by whether they are high quality SNAP benefits related news articles or analysis or not, then feeding them to a links website. The Google Alerts RSS feed also brings in many non-SNAP related articles that just use the word “snap”, so parsing those out would help a lot.\nOther articles to read One Mistake Led to a Lifetime Ban of SNAP Benefits. This Reform Rollback Can End It.\nNew state benefit program ensures students have healthy food in summer\nComputer glitch blamed for early May payments for 300k SNAP recipients in TN\n","permalink":"http://localhost:1313/posts/april-snap-updates/","summary":"\u003cp\u003eNote a slightly different format to topic, rather than state-based.\u003c/p\u003e\n\u003ch3 id=\"snap-interview-waivers-in-some-places-expiring\"\u003eSnap Interview Waivers in some places expiring\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.mdhs.ms.gov/post/expiration-of-waiver-of-interview-requirements-for-snap-benefits-in-mississippi/\"\u003eExpiration of Waiver of Interview Requirements for SNAP Benefits in Mississippi\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://news.yahoo.com/beltrami-county-snap-interview-waiver-023600199.html\"\u003eBeltrami County SNAP interview waiver ends April 30\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eI would be very curious to see any study performed exploring differences in program administration and case outcomes between while the waiver was in effect, and the before / after where the waiver is not in place. How has the speed of applications changed? Overpayment or underpayment rates? What do the caseworkers think about this change? I also came across \u003ca href=\"https://www.reddit.com/r/foodstamps/comments/198kzdi/petitioning_for_the_end_of_snap_interview/?rdt=33738\"\u003ethis Reddit thread on the impact of interview waivers\u003c/a\u003e, but would like to see a structured case study.\u003c/p\u003e","title":"April SNAP Updates"},{"content":"pd.crosstab is one of those built-in functions in the Pandas API that I forget about routinely. I instinctively reached for df.groupby('x')['y'].count().unstack(), but when I wanted to normalize the values, it takes more and more steps to get where I wanted.\nThis was a nice straightforward overview of the pd.crosstab function. To document for myself, below, create a sample correlated DataFrame with integer columns ActiveUsers and CompletedProfile.\nimport pandas as pd import numpy as np # following code from Github Copilot np.random.seed(0) n = 1000 # Number of samples p = 0.7 # Probability of True in the first column rho = 0.8 # Correlation col1 = np.random.choice([True, False], size=n, p=[p, 1-p]) col2 = np.where(col1, np.random.choice([True, False], size=n, p=[rho, 1-rho]), np.random.choice([True, False], size=n, p=[1-rho, rho])) df = pd.DataFrame({\u0026#39;ActiveUsers\u0026#39;: col1, \u0026#39;CompletedProfile\u0026#39;: col2}) Sample of the constructed DataFrame\nRunning pd.crosstab(df['ActiveUsers'], df['CompletedProfile']) gets a frequency distribution. Passing normalize=True adjusts the numbers of each group relative to the sum of the groups.\nWith normalize='index', we can find conditional probabilities given the row values. Given the value in the index, we can see the relative frequencies in the columns; numbers are normalized according to total values of each row. This gives us P(CompletedProfile=Y|ActiveUser=X).\nResult of pd.crosstab(df[\u0026lsquo;ActiveUsers\u0026rsquo;], df[\u0026lsquo;CompletedProfile\u0026rsquo;], normalize=\u0026lsquo;index\u0026rsquo;). Given a ActiveUser value of True, ~78% of instances are CompletedProfile=True.\nWith normalize='columns', the conditional probabilities are based on the columns, so we find P(ActiveUser=Y|CompletedProfile=X). Given a value in a column, what is the relative frequency of each row value.\nResult of pd.crosstab(df[\u0026lsquo;ActiveUsers\u0026rsquo;], df[\u0026lsquo;CompletedProfile\u0026rsquo;], normalize=\u0026lsquo;columns\u0026rsquo;). Given a CompletedProfile value of True, ~90% of instances are ActiveUsers=True.\nJust so I don\u0026rsquo;t forget this:\nResulting conditional probabilities by normalize arg.\nCuriously, passing margins=True when normalizing by index or columns gives totals (normalized) for the columns or rows, respectively. The Pandas documentation doesn\u0026rsquo;t cover this, but it is strange that the margins=True doesn\u0026rsquo;t result in a totals relative to the values being normalized against.\nResult of pd.crosstab(df[\u0026lsquo;ActiveUsers\u0026rsquo;], df[\u0026lsquo;CompletedProfile\u0026rsquo;], margins=True, normalize=\u0026lsquo;columns\u0026rsquo;). Values in the All column just reflect the normalized totals relative to the entire table, as if you ran pd.crosstab(df[\u0026lsquo;ActiveUsers\u0026rsquo;], df[\u0026lsquo;CompletedProfile\u0026rsquo;], normalize=True, margins=True).\n","permalink":"http://localhost:1313/posts/joint-conditional-probabilities-with-pd-crosstab/","summary":"\u003cp\u003e\u003ccode\u003epd.crosstab\u003c/code\u003e is one of those built-in functions in the Pandas API that I forget about routinely. I instinctively reached for \u003ccode\u003edf.groupby('x')['y'].count().unstack()\u003c/code\u003e, but when I wanted to normalize the values, it takes \u003ca href=\"https://stackoverflow.com/questions/37818063/how-to-calculate-conditional-probability-of-values-in-dataframe-pandas-python\"\u003emore and more steps\u003c/a\u003e to get where I wanted.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://lisds.github.io/textbook/useful-pandas/crosstab.html\"\u003eThis was a nice straightforward overview\u003c/a\u003e of the \u003ccode\u003epd.crosstab\u003c/code\u003e function. To document for myself, below, create a sample correlated \u003ccode\u003eDataFrame\u003c/code\u003e with integer columns \u003ccode\u003eActiveUsers\u003c/code\u003e and \u003ccode\u003eCompletedProfile\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e pandas \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e pd\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e numpy \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e np\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# following code from Github Copilot\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003enp\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003erandom\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eseed(\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003en \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1000\u003c/span\u003e  \u003cspan style=\"color:#75715e\"\u003e# Number of samples\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ep \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0.7\u003c/span\u003e  \u003cspan style=\"color:#75715e\"\u003e# Probability of True in the first column\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003erho \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0.8\u003c/span\u003e  \u003cspan style=\"color:#75715e\"\u003e# Correlation\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ecol1 \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e np\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003erandom\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003echoice([\u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e, \u003cspan style=\"color:#66d9ef\"\u003eFalse\u003c/span\u003e], size\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003en, p\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e[p, \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003ep])\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ecol2 \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e np\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ewhere(col1, np\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003erandom\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003echoice([\u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e, \u003cspan style=\"color:#66d9ef\"\u003eFalse\u003c/span\u003e], size\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003en, p\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e[rho, \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003erho]), \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e         np\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003erandom\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003echoice([\u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e, \u003cspan style=\"color:#66d9ef\"\u003eFalse\u003c/span\u003e], size\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003en, p\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e[\u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e-\u003c/span\u003erho, rho]))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003edf \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pd\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eDataFrame({\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;ActiveUsers\u0026#39;\u003c/span\u003e: col1, \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;CompletedProfile\u0026#39;\u003c/span\u003e: col2})\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c!-- raw HTML omitted --\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eSample of the constructed DataFrame\u003c/p\u003e","title":"Joint \u0026amp; conditional probabilities with pd.crosstab"},{"content":"Here is Microsoft\u0026rsquo;s documentation page on the topic. The only reason I am documenting this is because the Azure Resource Explorer failed to load consistently across devices for me. Some tutorials I found, like this one, seem to be outdated and the outbound IP addresses weren\u0026rsquo;t listed in any Properties menu in the Function App in the Azure Portal. The Azure CLI method was what worked for me:\naz functionapp show --resource-group \u0026lt;GROUP_NAME\u0026gt; --name \u0026lt;APP_NAME\u0026gt; --query outboundIpAddresses --output tsv az functionapp show --resource-group \u0026lt;GROUP_NAME\u0026gt; --name \u0026lt;APP_NAME\u0026gt; --query possibleOutboundIpAddresses --output tsv I wanted this as I was hoping to whitelist the IP addresses in the database firewall to allow for scheduling some SQL scripts to run daily. The issue with this is the following, copied from the above linked Microsoft documentation: \u0026ldquo;because of autoscaling behaviors, the outbound IP can change at any time when running on a Consumption plan or in a Premium plan.\u0026rdquo; While at least a few people say whitelist these IPs anyway, the recommended course of action is to set up a virtual network within Azure.\nGitHub Actions also does not support static IP addresses through the general free hosted option it looks like - while I can get the IP addresses they use, it is against best practices to whitelist these, and they are updated weekly.\nHow permissions work for a hosted tool is a consistent aspect I need to consider when evaluating new solutions:\nHow does the hosted tool get permission to access a private database?\nWhat adapters does it support (either officially or community driven)?\nWould it rely on direct queries to the database or through a REST API?\nWhere do I store the environment secrets in the tool? How is that secured? Is this a paid feature? What does the process look like to update or rotate these secrets?\nHow do I test the tool locally using the correct credentials? For example, with an Azure Function, I can use a local.settings.json file to include environment variables that will be accessible from the App Settings in the Function App.\nIs there a set of outbound IP addresses that the tool will try to access our data from that we can whitelist, or do we need a more sophisticated approach?\nHow does any regulation around data sharing work here, e.g., if there is PII or PHI data, are there issues with which tools pull data and how they connect?\n","permalink":"http://localhost:1313/posts/identifying-outbound-ip-addresses-of-a-azure-function/","summary":"\u003cp\u003eHere is \u003ca href=\"https://learn.microsoft.com/en-us/azure/azure-functions/ip-addresses?tabs=portal\"\u003eMicrosoft\u0026rsquo;s documentation page on the topic\u003c/a\u003e. The only reason I am documenting this is because the Azure Resource Explorer failed to load consistently across devices for me. Some tutorials I found, like \u003ca href=\"https://rubberduckdev.com/app-outbound-ip/\"\u003ethis one\u003c/a\u003e, seem to be outdated and the outbound IP addresses weren\u0026rsquo;t listed in any Properties menu in the Function App in the Azure Portal. The Azure CLI method was what worked for me:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eaz functionapp show --resource-group \u0026lt;GROUP_NAME\u0026gt; --name \u0026lt;APP_NAME\u0026gt; --query outboundIpAddresses --output tsv\naz functionapp show --resource-group \u0026lt;GROUP_NAME\u0026gt; --name \u0026lt;APP_NAME\u0026gt; --query possibleOutboundIpAddresses --output tsv\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eI wanted this as I was hoping to whitelist the IP addresses in the database firewall to allow for scheduling some SQL scripts to run daily. The issue with this is the following, copied from the above linked Microsoft documentation: \u0026ldquo;because of autoscaling behaviors, the outbound IP can change at any time when running on a \u003ca href=\"https://learn.microsoft.com/en-us/azure/azure-functions/consumption-plan\"\u003eConsumption plan\u003c/a\u003e or in a \u003ca href=\"https://learn.microsoft.com/en-us/azure/azure-functions/functions-premium-plan\"\u003ePremium plan\u003c/a\u003e.\u0026rdquo; While at least a few people say \u003ca href=\"https://stackoverflow.com/questions/49109310/how-to-allow-azure-function-to-access-database-hosted-on-azure-vm\"\u003ewhitelist these IPs anyway\u003c/a\u003e, the recommended course of action is to set up a virtual network within Azure.\u003c/p\u003e","title":"Identifying outbound IP addresses of a Azure Function"},{"content":"a) improve communication skills by forcing myself to formalize an opinion. Feedback from anonymous readers may either point out an error I made while translating what I think to a written document or a flaw in the argument itself. Of course, I need to be willing to be wrong, and reminding myself that I am excited about learning is an powerful way to cope with finding errors in my work. Writing online is a low-barrier opportunity to become comfortable with this.\nb) Document and share a learning process. I benefit from in-depth tutorials, quick write-ups on unfamiliar topics, StackOverflow answers, summaries of lessons learned from experiences I don\u0026rsquo;t have, etc. Why not contribute back to that community if I am able?\nc) Complement traditional forms of outreach. I would not make a decision to join a team on a 30 minute interview. Having more information on how someone approaches a problem, their interests, and a regular commitment to a project is evidence that normally wouldn\u0026rsquo;t be available about whether we would work well together. This hopefully translates to a better fit for future jobs, and at the very least demonstrates my knowledge and capabilities better than a resume does.\na response to\na) Writing online might be accessible, but it is not low-risk. A double blind article keeps the reviewer and the author anonymous; this blog is not. Others may form a reputation of me that is negative if I am consistently wrong or blind to a recurring category of errors. If this group does not provide explicit feedback, then writing online to improve communication skills may only be a placebo, with possible negative effects on my personal reputation.\nb) This is reasonable, but I need to impose reasonable limits on contributions on time spent on topics like these. Seeing how companies profit from the work of unpaid, open-source maintainers, and in recent years the increasing push back against this model (and a more honest acknowledgement of its limitations), shouldn\u0026rsquo;t the focus of my time be spent on meeting my primary obligations? Can I honestly assess the potential value of online writing here against the known value of producing additional output for nonprofit organizations?\nc) A potential employer may be just as likely to use this additional information against me. Even assuming I don’t post or link to objectionable topics, they may disagree with a position I take in opinionated pieces. Mixing professional-facing articles with personal pieces may not be what a company wants, and they may not want to work with individuals who maintain an online presence at all. And while I agree that public-facing work is evidence for what you say you can do, isn’t it almost a given that traditional hiring pipelines will still force their own tests for a applicant’s knowledge?\na follow-up to\na) Does improvement not happen through self-revision as I write? With more writing practice, it seems likely that I will improve regardless of viewership. Additionally, external feedback is a complementary benefit, but it is not essential. Lastly, the act of posting publicly creates pressure for myself to think through ideas more deeply in an attempt to avoid missing obvious errors.\nb) Online content is dominated by low-effort material. Continuing a tradition of meaningful contributions that are freely accessible has value in itself. And I don’t feel that I can dedicate all of my time to a single project, even if it may be less valuable. Also, perhaps writing on different topics prevents burnout in the long term. But any technical writing should be aligned with practical problems I deal with, rather than just general, shallow tutorials that can be answered from reading the documentation, I agree. A write-up on a particular issue should serve to reaffirm my understanding of how I solved the problem.\nc) Separating professional and personal commentary isn’t a bad idea, and it is fair to clarify that my writing isn’t on behalf of any organization on professional articles. But am guessing that the networking value of maintaining a up-to-date online presence is greater than then potential opportunities lost by it. If an organization is that controlling that I couldn’t express my thoughts online, then I likely wouldn’t want to work for them, unless there are extenuating circumstances, e.g., government roles or something similar. To the last point about still passing specific knowledge checks - that’s true, early on at least, but as a person’s reputation as an expert is demonstrated, these might not be needed.\na response to\na) If improvement through self-revision is possible, why write online at all, rather than publishing to private documents that I consistently review? I am still formalizing an opinion by writing it down. Waiting a few days and then reading back what I\u0026rsquo;ve written will allow me to detach myself from the argument and evaluate it more objectively. With a small blog like this that is not advertised anywhere, it feels like either there is no difference, or the motivation is that I want people to read it - and to agree with what is said.\nb) Settled, then.\nc) Tagging content by category, perhaps, or separate pages for work and personal topics. But I should take note to avoid over sharing, or limit personal posts to only those which have value outside of the sharing in itself. For example, a criterion such as: what are personal experiences or lessons that hold instructive value?\na follow-up to\na) For me, at least, I think there is 1) accountability created, and 2) opinions on external topics deserve with public posts. Of course, I privately journal daily, and for this, my motivation is long-term records of my personal development alongside short-term organization of my thoughts and emotions. There is a sort of future self-accountability: over time, I want to become a kinder, more thoughtful person that learns from my mistakes.\nOn professional development related topics or social issues, however, I feel like these are intrinsically public opinions and are by nature reflected socially. So why does it make sense for me to suppress why I believe in something, even as the actions I take on the basis of these beliefs is public-facing? For example, you might say that political beliefs should be kept to one’s self - but these beliefs will result in a vote for a candidate, which will have an impact on the lives of others. So shouldn’t ideas that may affect others be held accountable by the affected people themselves? By arguing that why I believe something is private to me, it feels like I am only insulating myself from public criticism.\nb) And a last note for myself - I do frequently benefit from advice that people write explicitly with the purpose of helping others - but I am not at that point yet, I don’t feel, where I have any meaningful advice of this sort to give.\nc) This is reasonable. I should ask myself each time I post: why should a piece of content be shared? What about a piece of writing deserves attention from others? This post even, an argument with myself, perhaps should be meant only for myself. And yet, seeing the state of online discourse, I think more people should consider how what they share affects other people. What motivates other people to post online?\na response to\na) That is a position I am satisfied with. From here, the risk comes less from faithfully describing my reasoning for a decision, and more from claiming that the decision is the right one for others. I could say this more plainly: my arguments should be available, but not imposing. I should try to justify as best I can what I believe and avoid any attempt to influence others to my position.\n","permalink":"http://localhost:1313/posts/why-not-write-online/","summary":"\u003cp\u003ea) improve communication skills by forcing myself to formalize an opinion. Feedback from anonymous readers may either point out an error I made while translating what I think to a written document or a flaw in the argument itself. Of course, I need to be willing to be wrong, and reminding myself that I am excited about learning is an powerful way to cope with finding errors in my work. Writing online is a low-barrier opportunity to become comfortable with this.\u003c/p\u003e","title":"Why (not) write online?"},{"content":"These are some thoughts about using a Wacom Intuos Wireless Pen and Tablet to complement a mouse and keyboard over the past few weeks. I made this purchase in an effort to decrease forearm and finger pain from overuse working at a desk. Previously, I\u0026rsquo;ve been using the Logitech MX Master 3 For Business mouse, and I was hoping that switching to a pen and tablet would limit some of the forearm rotation that was causing me pain. While I put the mouse to the side, I am still using a Glove80 keyboard, as well as Windows Voice Access.\nOverall I wouldn\u0026rsquo;t recommend it unless you need it. Odd compatibility issues, not easy to switch between input devices, and difficult to accomplish some tasks with a less accurate input device. Tablet itself is good enough if you want to test it out. Handwriting recognition was excellent.\nSet-up Unpacking and setting up the tablet was easy, but appropriately configuring Windows and all of the applications took some time.\nThe tablet and pen configuration is done inside Wacom\u0026rsquo;s software, and overrode the Windows settings. It is not the most intuitive software and figuring out what I should do - or what I should do - was kind of tricky. My initial settings change was just using a portion of the tablet to reflect the entire monitor, so I didn\u0026rsquo;t have to move my wrist so much. I also updated a pen button to open the on screen handwriting panel.\nChoosing Mouse mode should be done on an application basis. I found Mouse mode less intuitive when working across applications. It made it much more difficult to actually write as well, so I stayed in Pen mode, which maps the edges of the tablet to the edges of your screen.\nThere are definitely tradeoffs between Pen mode and Mouse mode when using a tablet. With Pen mode, I was forced to only use a portion of the tablet because I simply couldn\u0026rsquo;t reach to cover all of the screen. It can also be kind of tricky when you move the pen away and then put it back. The mouse will jump to wherever your pen is on the screen. Plus, to reach the entire screen, sometimes I have to contort my wrist to really reach the lower left corner, for example, even when only using part of the tablet.\nNot that you can add application specific settings. but I don\u0026rsquo;t particularly want to add custom settings for every app that I use.\nI tried a different couple places on the tablet to portion my screen too. At first I tried a corner, then I tried the middle bottom, and then I ended up just switching to the middle of the tablet. My actual writing area was quite small, and I only used very little of the tablet. It\u0026rsquo;s also a bit odd to get used to because in general, when you\u0026rsquo;re writing by hand, you\u0026rsquo;re either moving the paper or your forearm as you write across the page. Here you don\u0026rsquo;t need to do that.\nThe default onscreen writing pad is too small on the screen; I had to adjust it to be larger in the Personalization Settings menu. It\u0026rsquo;s also tricky to just stay in the space of the onscreen writing pad, especially if you are using a smaller area of the Wacom tablet.\nExperience Using It I use Windows 11. Some applications will require overrides; for example, Excel kept drawing in the spreadsheet, but also would refuse to show the Draw Ribbon where it is possible to enter \u0026ldquo;mouse mode\u0026rdquo;, even with the Draw tab enabled in the Ribbon menu. I had to update the Default pen Settings in the advanced menu to always use the pen to interact with the cells like a mouse.\nFor some reason, working in VSCode was awful, especially in an Jupyter notebook. The mouse would disappear entirely, and I wasn\u0026rsquo;t able to scroll in file using the scroll bar for more than a cell or two. Text and handwriting did work in regular .py files, but not in Jupyter notebooks.\nFields marked as password entry don\u0026rsquo;t let me use handwriting as an input. The onscreen keyboard will pop up, but without an option to switch to Ink.\nWindows Ink Even though Windows Ink isn\u0026rsquo;t part of this tablet, without it, the tablet would be useless, so it is important to consider what built-in option exists on your OS for handwriting recognition. I haven\u0026rsquo;t done any research on custom solutions or tablets that come with their own replacement software.\nWindows Ink advertises writing directly into fields; outside of the Start menu and Settings applications, this rarely works for most apps. Instead, I had to always enable the onscreen keyboard, then select the handwriting option.\nSo this introduces a bit of friction because I have to select the text input field, then click a button to open up the writing pad, then properly place my pen into the writing pad. Not a big deal, but it is something to get used to. I would like it better if it was like Windows Snip, for screenshots, where upon selecting a text box the screen \u0026ldquo;greyed out\u0026rdquo; and I could write anywhere on the tablet as input. But this is not the case, and you have to write within a onscreen writing pad.\nI tried to turn on \u0026ldquo;tip-up sensitivity\u0026rdquo; to solve this, but upon exiting the Wacom menu, the selection would always revert back to disabled. So whatever that check box should do, it does not do.\nAlso, I did find that the recognized words scroll too slowly as I write. I sort of find myself running out of room to type and have to wait for the screen to catch up. That said, I thought the handwriting recognition was phenomenal. Very often what I would write appeared illegible on the screen, but Windows perfectly translated it.\nThe editing tools are okay. For example, deleting a word is just a scribble. But using the pad as a complement to a keyboard, where my primary usage of the pen would be to replace a mouse, e.g., selecting and highlighting a word, means the pen editing tools are ineffective.\nTablet Sometimes, if I didn\u0026rsquo;t lift the pen up from the tablet enough, even though it definitely wasn\u0026rsquo;t touching, a line would still appear on the screen in between letters. I don\u0026rsquo;t see an option to control the \u0026ldquo;lift distance\u0026rdquo;.\nPrecision mode creates a box on your screen roughly around the current position of your pen and slows down the movement of your cursor. But to enable and disable precision mode, you have to touch a button. So you essentially need to enable precision mode as a button on your pen, otherwise you can\u0026rsquo;t leave it without very, very slowly moving your pen to whatever button you have on your computer.\nSo this leads to a point where you sort of run out of buttons on the pen. Precision mode, left click and open the handwriting input onscreen, I think, is the ideal combo for the pen - but I only have 2 buttons to spare.\nI mapped the \u0026ldquo;Express keys\u0026rdquo;, buttons at the top of the writing pad, pretty quickly. One to control+find, and two to control+copy, +paste, with the last on Enter. With the buttons at the top of the pad, it can be sort of difficult to reach up, so I\u0026rsquo;m glad I went with the smallest version of the tablet. Adding precision mode to one of these buttons isn\u0026rsquo;t helpful, because to click the button, my pen moves, so precision mode is created in the wrong place on the screen.\nI\u0026rsquo;m not sure if this is a setting, but the pen does sort of stick to the edge of the screen, sort of like snapping to a grid line. It\u0026rsquo;s not awful, but it is noticeable.\nOccasionally scrolling, and the click by pressing the pen tip to the tablet, would just randomly not work. I can\u0026rsquo;t quite consistently reproduce it. Switching apps or even just moving the pen away for a few seconds would often seem to help it figure itself out.\nBuild Quality The pen definitely feels like the cheapest part of the tablet. I don\u0026rsquo;t like that the nib of the pen is loose, and I think the pen is too light overall. I definitely prefer the iPad pen, which feels much more solid. The button keys on the pen are also a bit loose, and they can almost sort of get stuck sometimes, or catch on the edge. I also don\u0026rsquo;t care for how the pen feels against the tablet, slightly scratchy against a hard surface.\nIt can take a bit of time to get used to the sensitivity. Because the pen is so light, even though I feel like I\u0026rsquo;m not moving my hand, I\u0026rsquo;m still making tiny movements. The normal mouse wouldn\u0026rsquo;t necessarily respond to this, because it\u0026rsquo;s just heavier. So it\u0026rsquo;s harder to move a very tiny area quickly, and oftentimes, where I hover the pen is different from where I actually push down.\nTrying to hit a specific mark while pressing an on-pen button (e.g., a click and drag action) also changes where you\u0026rsquo;re holding the pen tip to as well by just a little bit, and sometimes that makes the difference between missing or making your target.\nI couldn\u0026rsquo;t really notice to any input lag difference between wired and Bluetooth.\nI ended up using a mouse pad to lean my wrist on, and putting the tablet on top of the main part of the mouse pad. The tablet is very thin, but the mouse pad helps with comfort as the arms of my chair are a bit higher.\nOther Notes I do think that text-to-voice quicker than using the pen. I started writing this article with the pen, and then quickly switched to voice. Either way, the real slowdown is always editing. Typing is much more precise and easier to edit in real-time.\nI did keep a mouse right by me. I wouldn\u0026rsquo;t say I found myself reaching for it too much unless I was in Excel or VSCode. But it did become slightly more annoying if I needed to type something out, because then I\u0026rsquo;d have to put down the pen and move my hands to the keyboard. I wasn\u0026rsquo;t really aware of how much I drag and drop as an action, which also becomes trickier with the pen.\nSpace on the desk becomes an issue too as well - I\u0026rsquo;m very happy that I got the smallest writing pad. If you\u0026rsquo;re only using this pad in the context of daily admin work, the small version is great - if I did upgrade, I don\u0026rsquo;t think it would be to get a bigger size. Also, I use a keyboard drawer in the desk, and I found that I had to pull out the drawer quite a lot, because my pen would hit the top of the desk when I was trying to write. I had the writing pad in the middle of each side of the Glove80.\nI did get the cheapest tablet just cause I wanted to test it out. Having used it, I would appreciate multi-touch capabilities alongside the pen. Zoom in and out would be great, plus just replacing clicks and double clicks with a tap.\nUpdates May 2024\nI think that the Bluetooth disconnects too quickly if not using the tablet.\nI ran into this issue with the jittering mouse; restarting the driver solved it. This happened after when I returned home from using a dual screen set up while traveling.\n","permalink":"http://localhost:1313/posts/replacing-a-mouse-with-a-pen-and-tablet/","summary":"\u003cp\u003eThese are some thoughts about using a \u003ca href=\"https://estore.wacom.com/en-us/wacom-intuos-s-bluetooth-black-us-ctl4100wlk0.html\"\u003eWacom Intuos Wireless Pen and Tablet\u003c/a\u003e to complement a mouse and keyboard over the past few weeks. I made this purchase in an effort to decrease forearm and finger pain from overuse working at a desk. Previously, I\u0026rsquo;ve been using the Logitech MX Master 3 For Business mouse, and I was hoping that switching to a pen and tablet would limit some of the forearm rotation that was causing me pain. While I put the mouse to the side, I am still using a Glove80 keyboard, as well as Windows Voice Access.\u003c/p\u003e","title":"Replacing a mouse with a pen and tablet?"},{"content":"These were my answers to the application essay questions for UChicago\u0026rsquo;s MSCAPP program back from the 2018 round. Only piece of advice - make sure you know what skills or knowledge you want to get out of any MS program - which means work for a bit prior to attending.\nWhy is a combined program between policy and computer science a good match for your career goals? (max 300 words)\nWith a M.S. in Computational Analysis and Public Policy, I can support the shift from Michigan nonprofits solely serving constituents to leading communities. My primary career goal is to increase volunteerism through developing the technical expertise of the nonprofit sector. By applying data science techniques, I will provide organizations with evidence of successful interventions and expand their capacity to deliver services. To accomplish this, I need intensive direction to develop my quantitative analysis skills through computer science and statistics courses.\nA combined program in computer science and policy is the perfect opportunity to better understand how nonprofits should capitalize on recent advances in computer science. In my eight years of working, interning, and volunteering with small and large organizations, I repeatedly find that nonprofit staff do not have the technical expertise needed to lead communities. Each has trouble implementing new technologies, as tools need to be grounded within a framework of social impact and equity. Yet this perspective is largely absent from software design. Unlike other programs, the MS-CAPP provides the computer science methods oriented toward the nonprofit and social impact industries. This degree will teach me to build tools with nonprofits rather than for them.\nRather than attend a master’s program that simply reinforces my strengths, the MS-CAPP is an intellectual challenge that provides me with tools to expand my limited experience with computer science and statistical analysis. Building on my economics experience and online courses on Python, linear algebra, and data science, I am ready for instruction on more advanced techniques and their applications. Overall, while my background will necessitate a disciplined approach to higher-level courses, my unique perspective will teach me to effectively communicate complex concepts to nonprofit professionals and mitigate the severe technical skills gap of the nonprofit sector.\nDescribe briefly the biggest challenge you have ever faced. How did you tackle it and what did you learn? (max 300 words)\nI learned what self-reliance is when I didn’t have enough money to continue my undergraduate education. It was winter break of my sophomore year. My FAFSA had been filed and I was staring at thousands of dollars of loans and an expected family contribution that I couldn’t afford.\nThe next semester, I spent my spare time completing scholarship applications. With each essay I wrestled with self-doubt, probing at why I thought I deserved their money. I still have fourteen drafts of personal statements, each boasting small accomplishments, each saying the same thing: please, I need this. Each day I looked at my resume, detailing the major – well, minor – accomplishments of my life: milestones reached, tasks completed, hours volunteered, and awards won. I saw the gaps when I compared it to others. I wondered why anyone would invest in me. Yet I kept working, turning in applications late at night after I had finished studying.\nBeing challenged to pay for my undergraduate education taught me two lessons: one, self-reliance doesn’t exist. Over the following two years, I received enough support avoid any other loans. It’s a debt that I am repaying with my career by affording opportunities for others. Two, no one is investing in me. They are investing through me, into our community.\nAs nonprofit professionals, our role is to minimize ourselves and work for others. To silence the voices in the back of our heads that doubt our strengths and indulge our weaknesses. The voice that wraps itself in layers of pride and power until it reifies itself as me. Part of me still wants to believe that my hard work earned what I have. Yet this experience reminds me that whatever I am, if anything, isn’t worth as much as what’s around me.\nWhere do you see yourself getting involved in the community during your time at Harris\u0026ndash;either at the University of Chicago or in the city of Chicago? [Optional, max 300 words]\nAs a community discussion group organizer, frequent volunteer, and former AmeriCorps VISTA member, I know the significance of community engagement. While studying at the University of Chicago, I will supplement my education by forming practical connections with community members through volunteerism, discussion, and supporting national service.\nAs I have not lived in Chicago, my community involvement must be carefully considered. There is an essential distinction between volunteering at a community, rather than with them. In my first year of studies, I will focus on learning more about community issues, contributing through existing student volunteering organizations, and by joining the Community Action Bureau. Additionally, volunteering with the Center for Data Science and Public Policy will complement my studies while also contributing to the wider community.\nAs a founder of a community philosophy discussion group, I will continue promoting philosophy as a tool for everyone through joining discussion groups, supporting public deliberation opportunities, and sharing resources from my Grassroots Philosophy initiative. Working with UC3P is also an excellent opportunity to further conversation on important issues. While not directly related to my studies, I will support AmeriCorps members within the city of Chicago. I know the difficulties of serving a community with low pay and minimal support. Providing any type of aid, either through events, networks, discussion, or resources is a valuable use of my time.\nLastly, I will join student organizations such as the Behavioral Economics and Public Policy group, Harris Consulting Club, Harris Talks, and the Harris Policy Analysis and Debate group to strengthen my grasp of related concepts and my communication skills. Through volunteering, discussion, and service support, I will contribute to the social fabric of the city and promote social learning activities.\n","permalink":"http://localhost:1313/posts/my-uchicago-mscapp-application-essay-answers-2018/","summary":"\u003cp\u003eThese were my answers to the application essay questions for \u003ca href=\"https://capp.uchicago.edu/\"\u003eUChicago\u0026rsquo;s MSCAPP program\u003c/a\u003e back from the 2018 round. Only piece of advice - make sure you know what skills or knowledge you want to get out of any MS program - which means work for a bit prior to attending.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cem\u003eWhy is a combined program between policy and computer science a good match for your career goals? (max 300 words)\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eWith a M.S. in Computational Analysis and Public Policy, I can support the shift from Michigan nonprofits solely serving constituents to leading communities. My primary career goal is to increase volunteerism through developing the technical expertise of the nonprofit sector. By applying data science techniques, I will provide organizations with evidence of successful interventions and expand their capacity to deliver services. To accomplish this, I need intensive direction to develop my quantitative analysis skills through computer science and statistics courses.\u003c/p\u003e","title":"My UChicago MSCAPP Application Essay Answers (2018)"},{"content":" Context\nStudent and supporting organizations wrote a letter to the USDA recommending that the SNAP application interview requirement be removed, with the accompanying press release here. A news article that summarizes the entire P.R. push for this is accessible here through Fortune magazine.\nWhy We Should Rethink the SNAP Interview Requirement: A Former Caseworker’s Perspective is an op-ed from The Center for Law and Social Policy (CLASP) which argues SNAP interviews should be made optional. Based on the author\u0026rsquo;s experience as a caseworker, the mandatory interviews are largely a pretense for detecting fraud, and the time could be better spent providing holistic assistance to SNAP participants. These \u0026ldquo;unnecessary interviews that are ineffective at finding what infinitesimal fraud exists\u0026rdquo; only serve to increase the stigma associated with accessing food stamps by treating applicants as if they \u0026ldquo;are thieves that must be watched\u0026rdquo;.1\nUnfortunately, the lack of any evidence for or against the effectiveness of SNAP interviews (whatever their purpose may be), the confusing use of statistics, and the wider focus on stigmas associated with SNAP participation resulted in an unconvincing argument. While I agree with the author\u0026rsquo;s wider points that we should take steps to minimize stigmas of government benefits and that a primary purpose of mandatory SNAP interviews is to verify information, further study of the consequences is warranted before SNAP interviews are made optional.\nFirst, the author confuses low fraud rates as evidence for removing fraud prevention efforts. A key quote from the blog post is: “despite the low incidence of fraud, caseworkers are required to dedicate significant time and resources to fraud prevention\u0026quot;.2 The author does not consider that the dedication of time and resources to fraud protection is exactly the reason for the low incidence of fraud.\nA better argument would use data to demonstrate that SNAP interviews rarely, if ever, detect potential fraud, or explain why interviews are not an effective mechanism for catching fraud. This point is notably excluded from the post. Another point is that the author does not consider that the interviews are also meant to prevent household and agency errors. For example, the applicant may have poor English language skills and misunderstood a question, or a staff member mistyped a value. Validating this in an interview may cut down on these types of errors. But instead the author only considers fraud, as it fits the overall narrative of the essay.\nWhat we can use is the SNAP quality control data to demonstrate that even with the interview, many mistakes still happen. For example, in FY19, 68,228 fair hearings (process to challenge decisions by a State agency which deny, reduce, suspend, or cancel benefits) were held with the State\u0026rsquo;s decision only upheld 58% of times.3 29,436 eligibility fraud investigations were referred to hearing officials by State agency investigators.4 Unfortunately, I\u0026rsquo;m not able to tell how many of these resulted in any disqualification, as the data is not broken out by type of fraud. If we just look at administrative disqualification hearings, out of 34,930 hearings, only 1,865 did not find an Intentional Program Violation. However, the ADH data includes both eligibility and trafficking fraud, and it\u0026rsquo;s very possible that whether or not a violation is found is an inequitable process.\nSo without direct data, I do think that we need to explore more about how interviews are not ineffective in catching reporting errors (whether or not it is intentional fraud), and identify ways in which we can adjust interviews to be more effective.\nSecond, the author minimizes the monetary impact of fraud, . From the article:\nIn fiscal year 2019, only 0.1 percent of SNAP issuances were overpayments based on Intentional Program Violations—which worked out to just a dime for every $100 of SNAP benefits. Moreover, only 0.9 percent were overpayments of any sort, including household and agency errors. Paragraph 2, Why We Should Rethink the SNAP Interview Requirement: A Former Caseworker’s Perspective; numbers sourced from SNAP “Program Integrity:” How Racialized Fraud Provisions Criminalize Hunger\nI am a bit skeptical of percentages presented out of context of real numbers rather than monetary values. If I understand correctly, SNAP issuances reflects the total monetary values of SNAP benefits, e.g., if a household gets $100 of benefits from SNAP, the SNAP issuance is $100. So if we accept the author\u0026rsquo;s estimate of .1% (.001) in FY19, and we get from the FY19 USDA State Activity Report that total issuances were $55,622,284,536, then we can conclude that $55,622,284.536 (fifty-five million, six-hundred and twenty-two thousand, and two hundred eighty-four dollars and fifty-four cents (rounded-up)) was the amount of overpayments based on Intentional Program Violations. Using the .9% (.009) number, overpayments of any sort would come to just over 500 million dollars. That, to me, is quite a lot of money that was not disbursed correctly.\nBut I don\u0026rsquo;t totally understand how we get these estimates. The inline citation links to another report by the author, where the claim is repeated on page 4, and the footnote links references the Supplemental Nutrition Assistance Program State Activity Report: Fiscal Year 2019 (I believe I located the correct report). However, I can\u0026rsquo;t find any mention of overpayments in that report anywhere.\nMy best guess is that \u0026ldquo;overpayments\u0026rdquo; is synonymous with \u0026ldquo;fraud\u0026rdquo;, and as such, the .1% and .9% are arrived at by taking the Fraud Claims Established (in millions) ($59.8), and Total Claims Established (in millions) ($482.4) from Table 40: SNAP Newly Established Recipient Claims - FY 2013 - FY 2019 on page 51 with the denominator as the total issuances mentioned above. This results in .0010 and .00866, which are reasonably close to the author\u0026rsquo;s estimates.\nBut the report states that \u0026ldquo;sum of the fraud associated with disqualifications is a better measure of the ultimate amount of fraud claims than the newly established amount.\u0026quot;5 It is a bit hard to be sure, but I believe this is referring to table 41: SNAP Collected Recipient Claims; if this is the case, Fraud Claims Collected (in millions) is $96.6, and Total Claims Collected (in millions) is $376.6, which would suggest .0017 and .0067, respectively.\nIn the SNAP Quality Control 2019 report, Table 7: Issuance and Issuance In Error, the dollar amount over issued is reported by state. Once again, this is a bit confusing. A U.S. Average is reported that is the same as the sum of all the state-level numbers: $3, 424,700,104. Why don\u0026rsquo;t we use this number, which compared to total of issuances, would come to 6.16%?\nAdditionally, the USDA reports a national weighted (by state caseload) average overpayment rate, which for FY2019, was 6.18% (which is relative to the total dollars issue). Based on the SNAP Quality Control Annual Report FY 2019, the U.S. Average estimate for total proportion of active cases with a dollar error was 8.86%.6 This USDA Payment Integrity Scorecard shows that overpayment as a percentage of total outlays is $3,306M, or 5.59% in FY19.\nEven if I better understood the proper calculations, it is still clear to see that these statistics don\u0026rsquo;t really give us any evidence for or against the author\u0026rsquo;s main point that we should end required SNAP interviews. Despite the focus on Intentional Program Violations, at least one legislator questions if the distinction in how the error is made matters. Program integrity doesn\u0026rsquo;t only mean intentional fraud, but decreasing errors anywhere in the process. Additionally, we can see that in most cases, the agency is likely at fault for overpayments.7\nCan the interview serve as an opportunity to reduce these errors? Where in the process do these errors occur? Reporting here makes it difficult for me to tell: the only discovery options reported are discovered from case file, household, or collateral contacts.8 Most reports will only offer vague points, but don\u0026rsquo;t address if interviews cut these types of errors down.\nThird, the author fails to demonstrate that mandatory SNAP interviews meaningfully limit access or is a major administrative burden.\nIn this section:\nState agencies should implement better communication and interview processes with applicants, which will streamline the process without removing the interview entirely. The USDA and state agencies recognize this, and we are seeing examples of funding for process modernization projects.\nIf the point is to reduce administrative burden, adding holistic support and assistance in place of mandatory interviews will not achieve this.\nTo get it out of the way, the author incorrectly states that the SNAP program reaches less than a quarter (22%) of eligible people.9 The first bullet point of the linked summary that the author uses as a source contradicts the author\u0026rsquo;s quote; the SNAP program reaches 78% of eligible people (at least in the report year). We should certainly explore why some individuals remain not enrolled, but SNAP is reaching a majority of eligible applicants.\nThe anecdotes about how interviews may be difficult to attend, or incorrectly scheduled, are unpersuasive: both of these will still occur if the SNAP interview is optional, and these errors result from the states\u0026rsquo; implementations. If these scheduling issues are pervasive, then the state needs to investigate, fix, and modernize their own systems. For example, the original Code For America study (outside of the blog post) found that one in three applications in LA were denied for a missed interview. This type of research should be replicated across more states.\nWhile not cited in the blog post, the anecdotes are similar to the concerns raised in the CalFresh study that the original letter to the USDA relies on. Neither the blog post nor the original letter bother to discuss the actual intervention made by Code For America to implement flexible interviews. Here are just two of the intervention\u0026rsquo;s successes:\nApplicants who received information about flexible interviews and who called the flexible interview line received a benefit determination roughly seven days sooner than those in the control group and were 6% more likely to be enrolled in CalFresh (an 11% increase in the approval rate).\nThe positive effect on approval rates was largest for people whose county office approval rates were the lowest, which means that the flexible interview line makes outcomes more equitable across LA County zip codes.\nThink Big, Start Small: How Implementing Flexible Interviews Improves Benefit Delivery\nSo clearly, there are ways that state agencies can streamline their interview process. As Code For America summarizes:\nThe success of the flexible interview pilot shows that large county departments can successfully plan, implement, and evaluate major changes to their business processes. They can do this in a way that centers the client experience and optimizes client outcomes while actually improving efficiency for caseworkers and streamlining their business processes.\nThink Big, Start Small: How Implementing Flexible Interviews Improves Benefit Delivery\nA Center on Budget and Policy Prorities (CBPP) and the author\u0026rsquo;s own organization CLASP released some excellent recommendations in 2018 to improve flexibility of interviews and completion rates - maybe the USDA can work with states to implement these first.\nOutside of the author\u0026rsquo;s blog post, we can find comments that point blame on interviews as an administrative burden; the Director of Alaska\u0026rsquo;s Division of Public Assistance, is quoted here in Stateline in Feb. 2024 stating “[Interviews] were taking an extreme amount of time\u0026hellip; We were growing the backlog.”10 That said, the news article initially provides context, pointing out that a backlog was created by a Alaska DHSS policy misinterpretation, a cyberattack, outdated computer systems, budget cuts and low pay. It\u0026rsquo;s also mentioned that $60 million was approved in funding, \u0026ldquo;with the bulk of that dedicated to computer upgrades\u0026rdquo;, and that the department is actively hiring eligibility technicians, which to me suggests that interviews aren\u0026rsquo;t the only cause or blocker of this backlog.11\nThis example hints at a problem that the author doesn\u0026rsquo;t address in their blog post: how the COVID-19 pandemic affected states\u0026rsquo; ability to administer SNAP and the backlogs created by the expiration of these temporary benefits. Undoubtedly, proponents of making SNAP interviews at optional will point to all of these waivers and argue that they are proof that the program works without required interviews. But we can\u0026rsquo;t say that, as data for 2020 or 2021 doesn\u0026rsquo;t exist while reporting requirements were suspended. And based on 2022 data, 44 states were sent letters pointing out declines in key benchmarks (note that there is some potential that the measured error rates could be less accurate than most years due to emergency allotments, see the State Certification Flexibilities Prioritized SNAP Access section in this CBPP report).\nOther opportunities to learn are available. There still are waivers for streamlined interviews for select populations and states face-to-face waiver for quality control interviews; we could study how error rates change when these waivers are in place. Unfortunately, I\u0026rsquo;m not sure if these findings would be generally applicable to a wider population, but it could be an indicator. We also need to compare the decrease in administrative burden by removing SNAP interviews to the potential increase in resolving cases of fraud or agency and household errors. I don\u0026rsquo;t mean to assume that fraud will go up if we remove SNAP interviews; it could be that without SNAP interviews as a supplementary data point, the investigations take more work. To what extent are data from the interviews used, and what would change if that data was not verified in the interview? I am not sure, ultimately, but it is worth studying.\nAs a last note, the blog post claims that removing the interview requirement would “help minimize agency errors”.12 The author offers no follow-up evidence or explanation to demonstrate why this would be the case, so I won\u0026rsquo;t bother with it. Instead, I\u0026rsquo;ll point to some key actions by the USDA\u0026rsquo;s Food And Nutrition Service that could replace some of the verification done in the interview with automated practices, which is definitely part of a way forward.\nFNS is:\nAwarding $5 million in grants per year to select state agencies to develop and implement projects that use technology to improve the quality and efficiency of SNAP application and eligibility determination systems; and\nContracting with national payroll data providers to help states improve income verification for SNAP applicants and recipients, which is expected to reduce payment errors and improve the timely processing of applications and recertifications.\nAgriculture Secretary Calls on States to Take Action to Improve SNAP Administration for Families in Need\nThe $5 million in grants offer a competing vision of how the SNAP application process could be streamlined. Five out of the six grant winners of the FY 2023 Process and Technology Improvement Grant from the USDA FNS are funded to modernize and automate state application systems (project descriptions adjusted for brevity):\nThe District of Columbia Department of Human Services will launch OCR and a bot to process paper documents and add them to SNAP case files.\nThe North Carolina Department of Health and Human Services will develop Remote Identity Proofing (RIDP) to improve access to optional online SNAP services for clients by removing the need to go into offices.\nThe South Carolina Department of Social Services will create a system for real-time Social Security Number validation and will provide real-time electronic SNAP case notifications for clients to enhance customer service.\nThe Ohio Department of Job and Family Services will implement text messaging for reminders and secure case updates.\nKansas Department for Children and Families will automate manual SNAP administrative tasks using a bot including case registration, data entry, and creating workflow tasks for caseworkers.\nProjects like these should be pursued.\nI\u0026rsquo;m not convinced that SNAP interviews the best opportunity for holistic case management. I don’t have experience as a caseworker, so I only have questions here, which are:\nis the time provided for the interview not enough to confirm the application and help search for alternative resources?\nAre there automated verification methods outside the interview that we can incorporate into the process? if we “must include an optional interview for those who would benefit from it,” how do we identify the applicants that would benefit from it?\nIf those optional interviews occur, where is the harm in confirming an applicant’s information? What are NGO or other government opportunities (social service nonprofits, calling a 2-1-1 line) for case management, and why should an optional SNAP interview replicate their efforts?\nIf decreasing administrative burden is a goal, then limiting the interviews to only address SNAP benefits seems more effective than expanding the amount of assistance a caseworker is expected to provide. Collecting trusted data about SNAP fraud is exactly the evidence that we can use to disprove the stereotypes about public benefits recipients. When politicians try to cut SNAP benefits and create these myths about people not working or stealing from the government, they can easily be challenged with data from a robust and verified data collection process. How will state and national agencies defend this change when many politicians are already reinstating qualifications that preclude participation entirely in many states across the U.S.?\nLastly, I support the author\u0026rsquo;s intentions to remove stigmas around government benefits and to provide more holistic care to address the challenges of impoverished families. It is important to make sure that people feel respected when going through a process like this - that is the role of excellent case managers. I agree with the author that caseworker jobs should be \u0026ldquo;secure, well-paid and high quality\u0026rdquo;.13\nBut I am left unconvinced that streamlining the SNAP application process and ensuring dignity to participants means removing the mandatory SNAP interviews. We should instead first gather more data to determine the effects of the change and explore enhancements to state implementations.\nAdditional Resources\nHere is a fraud study from the Congressional Research Service last updated in 2018.\nHere is Code for America\u0026rsquo;s overview page on food assistance programs.\nNotes\nRelevant quotes and sources from the original blog post are listed below. Last accessed 4/8/2024. The entirety of the article as a PDF is embedded below from 4/8/2024.\nwhy-we-should-rethink-the-snap-interview-requirement-a-former-caseworkers-perspectiveDownload\n","permalink":"http://localhost:1313/posts/a-response-to-why-we-should-rethink-the-snap-interview-requirement-a-former-caseworkers-perspective/","summary":"\u003chr\u003e\n\u003cp\u003e\u003cstrong\u003eContext\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eStudent and supporting organizations wrote a \u003ca href=\"https://defendstudents.org/news/body/Student-Defense-Congressional-letter-on-SNAP-petition-FINAL.pdf\"\u003eletter to the USDA recommending that the SNAP application interview requirement be removed\u003c/a\u003e, with \u003ca href=\"https://defendstudents.org/news/student-advocacy-coalition-continues-push-for-u-s-department-of-agriculture-to-remove-barriers-to-snap-benefits\"\u003ethe accompanying press release here\u003c/a\u003e. A news article that summarizes the entire P.R. push for this is \u003ca href=\"https://fortune.com/2024/01/16/food-stamps-snap-interview-obstacle/\"\u003eaccessible here through Fortune magazine\u003c/a\u003e.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003ca href=\"https://www.clasp.org/blog/why-we-should-rethink-the-snap-interview-requirement-a-former-caseworkers-perspective/\"\u003eWhy We Should Rethink the SNAP Interview Requirement: A Former Caseworker’s Perspective\u003c/a\u003e is an op-ed from The Center for Law and Social Policy (CLASP) which argues SNAP interviews should be made optional. Based on the author\u0026rsquo;s experience as a caseworker, the mandatory interviews are largely a pretense for detecting fraud, and the time could be better spent providing holistic assistance to SNAP participants. These \u0026ldquo;unnecessary interviews that are ineffective at finding what infinitesimal fraud exists\u0026rdquo; only serve to increase the stigma associated with accessing food stamps by treating applicants as if they \u0026ldquo;are thieves that must be watched\u0026rdquo;.\u003ca href=\"#9e749f2e-5a57-454a-a61c-2fdc32647381\"\u003e1\u003c/a\u003e\u003c/p\u003e","title":"Questions on \"Why We Should Rethink the SNAP Interview Requirement: A Former Caseworker’s Perspective\""},{"content":"Summary:\nmany warnings about EBT payment scams and theft, alongside a proposal to improve security\nstate bills (and national) continue to propose work requirements and refuse additional SNAP funding for the summer\nupcoming Farm Bill renewal is stalled by SNAP discussions and funding\nNational Jobs and Opportunities for SNAP Act of 2023 proposed by Senator John Kennedy in the U.S. Senate. The companion U.S. House bill is here. The following is copied from the summary:\n“This bill expands applicability of the work requirements for Supplemental Nutrition Assistance Program (SNAP) recipients who are able-bodied adults without dependents (ABAWDs). (SNAP recipients who are ABAWDs have work-related requirements in addition to the general SNAP work registration and employment and training requirements.) Specifically, this bill applies the work requirements for ABAWDs to adults who are not over 65 years old, whereas these requirements currently apply to adults who are not over 50 years old. Further, the ABAWD exemption for a parent or household member with responsibility for a dependent child is restricted to a dependent child under the age of seven. Current law does not include an age for the child.\nThe bill repeals COVID-19 public health emergency waivers issued for ABAWD work requirements.\nThe bill also repeals an ABAWD waiver program that allows state exemptions based on an area (1) having an unemployment rate of over 10%, or (2) not having a sufficient number of jobs.\nUnder current law, a state agency may exempt up to 12% of SNAP recipients from the ABAWD work requirements for each fiscal year; unused exemptions may be carried over and used in a subsequent fiscal year. The bill reduces the percentage of exemptions a state agency may provide to up to 3% of SNAP recipients, and unused exemptions may not be carried over.”\nNew bill would require SNAP EBT cards to have microchips and other safeguards to combat \u0026lsquo;skimming\u0026rsquo;\nFull bill is accessible here. DoorDash Expands Food Access for SNAP Customers With New Grocery Partners\nDollar stores are hitting hard times, faced with shoplifting and inflation-weary shoppers\nDollar stores are listed as Combination Grocery/Other store type, according to the USDA, for purposes of the SNAP program. The retailer management year end summary for fiscal year 2023 shows that redemptions at this store type account for nearly five and a half per cent of total redemptions. The total monetary amount of these redemptions fell about 10% from FY 2022 - a decrease in around $700 million.\nInvestors are curious too.\nWe know how important nutrition is for health — it’s time to fortify the Farm Bill\n\u0026ldquo;GusNIP provides cash incentives in the form of electronic reward cards, coupons or tokens to SNAP participants to purchase more fruits and vegetables. The program also supports American farmers by prioritizing direct-to-consumer sales and locally grown produce.\u0026rdquo;\n\u0026ldquo;\u0026hellip;the program currently reaches less than 1 percent enrolled in SNAP.\u0026rdquo;\nHere\u0026rsquo;s the primary program pilot page from the USDA.\nThis is the primary article from December 2023 that the op-ed is based on (both are written by the same people).\nThis is an interesting contrast to proposals which would mandate that SNAP funds be used only on healthy foods.\nHere\u0026rsquo;s an example project funded for $500,000 for an 18 month period of time. Five corner stores served 250 pre-selected SNAP enrolled families; qualifying purchases on fresh fruits and vegetables resulted in awards put on a loyalty card.\n(More funded projects listed here)\nSNAP Benefits Receive a Lifeline\nSomewhat unsurprisingly, the pilot proposal fails. It is interesting to see the language used by the Senator copying a lot of the phrases used from the FoodBankNews website.\nGrassley: food stamps debate stalling farm bill development\nChildren face hunger across Deep South after states refuse summer food aid\nPersuasive essay on stories from individuals affected by states refusing funding for the Summer EBT Program, which \u0026ldquo;was launched in pilot versions in 2011, expanded nationally during the COVID-19 pandemic and was made permanent by Congress in a spending bill adopted in December 2022\u0026hellip;.In total, $2.5 billion has been allocated for the program this year to feed the estimated 21 million children nationwide whose families qualify for free or reduced-price meals at school.\u0026rdquo; - Esther Schrader Arizona Republican proposals would place more restrictions on SNAP benefits Much of the language, and commentary mirrors what we see in other states\u0026rsquo; proposals. California USDA Announces Approval of D-SNAP for California Disaster Areas\nHow often is D-SNAP approved? Are there any maps or timelines that show how often D-SNAP is available across the U.S.? ‘I have no idea what I’m going to do’: Woman says food stamps agency told her to pay back $2,095. Does she have to?\nOverpayment error? Florida Florida\u0026rsquo;s Expansion of SNAP Mandatory Work Requirements Will Hurt Program Participants and Local Economies\nIdaho Statehouse roundup, 3.28.24: Senate rejects summer lunch program funding\n“We’re sending the wrong message to parents and kids that we’re going to keep providing for everybody without needing something in return,” said Sen. Cindy Carlson, R-Riggins. “I believe that the message we need to be sending is we all need to work for what we get.”\nFrom Sen. Carlson’s Ballotpedia entry, asking about her favorite book: “The Bible is my most read book. It is a timeless book that helps keep me grounded. It has every day application that is never outdated“\nI’m sure, then, that she has memorized all of these quotes from the Bible about feeding the hungry.\nIllinois Illinois man steals $1.2 million in SNAP benefits fraud scheme Kentucky Ky. Senate committee rejects bill that would jeopardize some people’s SNAP benefits\nThis is the Senate-version of the bill, and it appears the bill sponsor updated the bill to only limit the state agency\u0026rsquo;s ability to apply for a statewide waiver to work requirements. Who should be on SNAP? An explainer on the discussion around HB 367\nA locally-reported recap of some of the conversations that have been happening in Kentucky, especially those among the state legislators.\nA quote from the bill\u0026rsquo;s sponsor (quoted from the article):\n“Other states have implemented these restrictions back to the federal level at no cost. We’ve actually seen some increased savings from that. Taxpayers in Arkansas saw $28 million in savings. Taxpayers in Mississippi saw $93 million in savings,” he reported. The representative added, “In addition to that, what some States saw in case studies is that people who got off to SNAP benefits actually doubled and tripled their income. That they were held back by restrictions on SNAP. So we actually saw more retail flow into the local economies from doing that.” I did my best to track these studies down. I believe the Mississippi report was published by the Foundation for Government Accountability in 2019. For the Arkansas number, the report - same organization, same authors - is accessible here.\nLegislature looks to cut SNAP benefits, raise requirements\nMassachusetts Massachusetts residents with SNAP benefits can now use them at food trucks\nIt appears the pilot program was initially proposed in 2022, and 27 restaurants and food trucks were accepted by June 2023. According to the Department of Transitional Assistance, only one food truck is currently open and accepting SNAP (with potentially 2 more coming soon). Including restaurants, 12 places (out of the original 27) are ready. If the first linked article is right, and Massachusetts is the first state to expand SNAP to food trucks, then congratulations to Sabrosa Venezuela, the first food truck in the country that accepts SNAP benefits.\nMichigan How surviving on food stamps helped me lead Michigan\u0026rsquo;s unemployment system | Opinion\nNew Hampshire NH is offering free job training to people receiving SNAP benefits\nNew York Mayor Adams Announces Cash Assistance and SNAP Application Backlogs Nearly Eliminated, Bolstering Access to Benefits for Low-Income New Yorkers\nGreat work by the NYC team to cut down on a backlog, plus a nice chart. I\u0026rsquo;m curious about how the decreasing backlog looks at other departments. Minimum SNAP benefit at $100 a month?\nFull article here. $23 as the minimum for 1 to 2 person households. Ohio \u0026lsquo;A failure of government\u0026rsquo;: As food-stamp theft soars in Lorain, experts say urgent help is needed Local story emphasizing the need for better cybersecurity for EBT payments.\nThe article notes that California is upgrading these cards to chip-based payments at its own cost.\nOhio refuses to, stating that improvements to a federal program should be paid for by the federal government, from the article.\nTennessee SNAP benefits backlog continues to impact families who depend on the help across Tennessee\nTexas SNAP Benefits Warning for Millions of Americans Common phone call scam. South Carolina Dillon Co. woman arrested for fraudulently claiming nearly $30K in SNAP benefits\nBerkeley Co. woman charged with food stamp fraud\nWisconsin USDA approves Wisconsin plan to provide summer food benefits for kids, families\nProbably the first of many for 2024, apart from the few states that decided not to apply. Missed from February! Expiration of the 2018 Farm Bill and Extension in 2024\nCongressional Research Service report on SNAP funding in the upcoming Farm Bill renewal. If the Farm Bill is delayed further, SNAP, TEFAP, and other programs can potentially continue through appropriations funding. Welch Introduces New Bills to Bolster SNAP Benefits for Social Security Recipients and Student Loan Borrowers\n\u0026ldquo;bills that would exempt annual cost-of-living adjustments (COLA) and student loan payments from impacting the benefits of the families and individuals who utilize the Supplemental Nutrition Assistance Program (SNAP) for food assistance.\u0026rdquo; ","permalink":"http://localhost:1313/posts/snap-benefits-news-march-2024/","summary":"\u003cp\u003eSummary:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003emany warnings about EBT payment scams and theft, alongside a proposal to improve security\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003estate bills (and national) continue to propose work requirements and refuse additional SNAP funding for the summer\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eupcoming Farm Bill renewal is stalled by SNAP discussions and funding\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"national\"\u003eNational\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.congress.gov/bill/118th-congress/senate-bill/1062?s=1\u0026amp;r=96\"\u003eJobs and Opportunities for SNAP Act of 2023\u003c/a\u003e proposed by Senator John Kennedy in the U.S. Senate. The companion U.S. \u003ca href=\"https://www.congress.gov/bill/118th-congress/house-bill/1550\"\u003eHouse bill is here\u003c/a\u003e. The following is copied from the summary:\u003c/p\u003e","title":"SNAP Benefits News - March 2024"},{"content":"Written by Larry Gonick \u0026amp; Woollcott Smith\nNote: This is based on the \u0026ldquo;Revised and Updated Edition\u0026rdquo;.\nCover page of The Cartoon Guide to Statistics\nDeriving, and learning when to apply, statistical formulas is always going to be difficult. It turns out that including cartoons does not make it any easier.\nI would put statistics writing into three general categories: teaching statistical literacy, e.g., How To Lie With Statistics; deriving the principles of statistical concepts, e.g., any college-level textbook; and applying statistical methods, e.g., an academic study. The Cartoon Guide To Statistics tries to do a bit of all three of these, and is worse off for it. The guide covers probability, random variables, sampling, confidence intervals, hypothesis testing, experimental design, and regression in just over 200 pages.\nI’m unsure who the guide is written for, but I imagine it would be appropriate for a high school statistics class. I don\u0026rsquo;t think it would be particularly valuable for someone learning statistics for the first time, with this as their only resource. Chapters too frequently end with the derivation of a formula, and not enough applications of the formula to demonstrate its usefulness. Personally, I would prefer a greater focus on reinforcement through a set of exercises - at least 2 to 3 worked-through applications per concept.\nThe examples range widely, from the usual coin flips and dice rolls to polling, quality control, and health studies. I don’t care at all for probability explained through gambling applications, or the height of students, even though they possess properties that make them easy to use for statistics examples. I thought that this guide spent far too long stuck in coin flips, for example, without connecting them to more interesting applications.\nAnd lastly, on the topic of examples, the goal of a statistics book should give you the ability to determine what type of problem you have, and whether it can be approached through statistical methods. A Cartoon Guide to Statistics is best as a quick, visually interesting survey of different types of methods, but I don’t recommend it if you have a specific problem that you are curious about solving. This is why I feel that statistics are best taught within the context of a certain domain, rather than as a general set of methods. Sure, the book hints at more complex statistical methods or how certain formulas might have to be adapted - but what I would have liked to see is a list of examples and exercises that you could actually do yourself, where what\u0026rsquo;s been presented in each chapter does apply.\nThe cartoons, at their best, help illustrate the examples; at worst, they distract me from the statistics. In some chapters, recurring characters create a thin narrative wrapper around solving a problem end-to-end, almost acting as checkpoints separating steps within each problem. I think this is a good use of the cartoons - this approach continually asserts that statistical analysis a method to answer a question, without losing sight of the question that gets people interested in statistics. And of course, sometimes explanations are easier to understand through visual drawings, like Venn diagrams or data visualizations.\nAn effective use of the illustrations is to explain the intuition behind confidence intervals, as shown below.\nA Cartoon Guide to Statistics, Gonick \u0026amp; Smith, p. 116\nTurning each page, my eyes immediately go to the drawings, and I read them out of order. Many of the cartoons are just little funny characters with short quips about the current topic that I felt almost detracted from the book; space could have been slightly better used to further explain mathematical formulas or definitions instead of a witty comment about how confusing the formula is (which happens very often in the book). The subject material is likely too advanced for most kids, but many of the jokes feel targeted toward young children.\nAs the math gets simpler, the book gets better. Cartoons don’t add much to derivations, but they work well in the context of how to visualize data. And notably, the text still does nearly all of the heavy lifting in the book. If you took out nearly all of the cartoons, you would not lose any key information that hindered your understanding. But the book doesn\u0026rsquo;t always present concepts in the context of real life scenarios that apply to the general population, instead using hypothetical questions that are not memorable or immediately useful. The statistics behind political polling and the racial bias in jury selection court case presented in later chapters were good examples that the authors worked through - I would just like even more, perhaps with guided exercises that get the reader involved in the calculations.\nOverall, if you are teaching statistics and want to use a visual aid, I think this book would be useful in a classroom. You can pull out a few specific chapters and work through them, or assign them as digestible readings. However, if you\u0026rsquo;re learning on your own, I think you would be better off with another book. Decide what you want to learn - how to interpret statistics or how to use and apply them yourself? If it\u0026rsquo;s the former, I\u0026rsquo;d recommend Naked Statistics; if the latter, take an online course. But no need for cartoons.\n","permalink":"http://localhost:1313/posts/the-cartoon-guide-to-statistics/","summary":"\u003cp\u003eWritten by \u003ca href=\"https://www.larrygonick.com/titles/science/the-cartoon-guide-to-statistics/\"\u003eLarry Gonick\u003c/a\u003e \u0026amp; Woollcott Smith\u003c/p\u003e\n\u003cp\u003eNote: This is based on the \u0026ldquo;Revised and Updated Edition\u0026rdquo;.\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://laggingindicators.blog/wp-content/uploads/2024/03/wp-17118311210711858430788391303633.jpg?w=768\"\u003e\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eCover page of The Cartoon Guide to Statistics\u003c/p\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003c!-- raw HTML omitted --\u003e\n\u003cp\u003eDeriving, and learning when to apply, statistical formulas is always going to be difficult. It turns out that including cartoons does not make it any easier.\u003c/p\u003e","title":"The Cartoon Guide to Statistics"},{"content":"Written by Darrell Huff and illustrated by Irving Geis. Originally published in 1954.\nIn a sentence: a quick, worthwhile general knowledge read that explains how people misuse statistics through familiar and useful examples (that could use an update).\nI’ll face up to the serious purpose that I like to think lurks just beneath the surface of this book: explaining how to look a phony statistic in the eye and face it down; and no less important, how to recognize sound and usable data in that wilderness of fraud…\nHow to Lie with Statistics, p. 124, Darrell Huff.\nMost of the examples revolve around a) consumer misinterpretation, b) deliberate misrepresentation, c) failures in random selection, d) confusing correlation with causation, or e) data collection and reporting issues. Each chapter is largely a long list of examples from society illustrating a common theme of how a statistic is misused, along with a summary. The book is highly readable and contains very little math. It tries to teach intuition; at first sight of a statistic, what are the questions you should ask about it to see if it is trustworthy?\nIllustrations are well-used. These are either custom designed or reproduced data visualizations that illustrate common errors of perception. The examples are usually drawn from newspapers or magazines of the time; if not, they are just humorous. At their core, the tricks used to create misleading visualizations still are relied on today: adjusting axes, misjudging the size of shapes, different sampling periods, etc. While visualizations may be more complex or visually appealing nowadays, I don’t think there are many new ways we’ve developed to purposefully confuse people. The old ways still work. I would say we’ve just gotten better about categorizing and identifying why and how people get confused when they see certain types of visualizations.\nObviously, some of the examples are outdated, but the issues that they demonstrate are lasting. For example:\nSome malaria figures mean as little. Where before 1940 there were hundreds of thousands of cases a year in the American South there are now only a handful, a salubrious and apparently important change that took place in just a few years. But all that has happened in actuality is that cases are now recorded only when proved to be malaria, where formerly the word was used in much of the South as a colloquialism for a cold or chill.\nHow to Lie with Statistics, p. 84-85, Darrell Huff.\nReading this book, two general questions come to mind.\nFirst, the book, obviously, is not teaching you how to lie with statistics. It is showing you how to be an “informed skeptic” of statistics. And from this, I start to think about what a general framework of skepticism looks like, that would apply to any new information, rather than just statistics. My underlying thought here is that a sort of blind, consistent skepticism, always equally doubting new information regardless of its attributes, content or context, is unrealistic and unhelpful. On the other end, we can be skeptical of new information based on an informed understanding of how that content could be feasibly manipulated.\nFrom the book, a proper skeptical approach to deciding whether a statistic is valid or not revolves around a) how data was gathered, b) what statistic was chosen to represent that data, c) how that statistic was calculated, d) in what context the statistic was reported, e) how the statistic is visualized, and f) how the statistic is used (e.g., what argument is the statistic being used to support?\nHuff himself, in the last chapter, summarizes these questions more generally under 1) Who says so? 2) How do they know? 3) Did somebody change the subject? 4) Does it make sense?\nI’ll walk through an adapted example that Huff uses to open Chapter 2: when you move to a new neighborhood, a neighbor eagerly reports that the average income is $190k - you’re in a rich neighborhood. A month later, at a community meeting that is discussing some sort of local tax increase (you arrived late), the same neighbor angrily points out that the average income is $80k - why are we raising taxes again? We’re going to all have to pay more, they exclaim! They brought out a fancy chart they made at home as well:\n(The illustrations in the book are much better)\nApplying the framework, we can ask the following questions:\nA) What families are being included in the income estimate? When did the neighbor get this number - have some families moved away or into the neighborhood recently that change this number? Did the neighbor talk to every household, or just survey themself and their neighbor? See Chapter 1, “The Sample with the Built-In Bias”, or Chapter 3, “The Little Figures that are not there”.\nB) Clearly, the first average is a mean, and the second average is likely a median. But we should still clarify which average is being used. See Chapter 2, “The Well-Chosen Average”.\nC) But even in calculating the average - did the neighbor remove any outliers? Can we trust they did the math correctly and understood what statistic to use when? Why use a percent feather than just the value of the increase itself? See Chapter 9, “How to Statisticulate”.\nD) Both of the numbers in the example are being used in a persuasive context. The first to persuade you to move to the neighborhood, the second to dissuade a tax increase. There is an implicit argument here at the community meeting: passing this tax increase means you will pay more, but you might want to question if this is the case, or how much you would pay, or what the community benefits might be. Perhaps the neighbor points out that the neighborhood next to you increased taxes, and crime went up. We need to be wary of misleading correlations used as evidence of causation. See Chapter 8, “Post Hoc Rides Again”.\nE) Looking at the visualization - no axis labels? How was the percent increase calculated? But yikes, that taxes line is going up quickly and sharply - unless the taxes are measures in pennies? See Chapter 5, “The Gee-Whiz Graph”, or Chapter 4, “Much Ado about Practically Nothing”, or Chapter 6 “The One-Dimensional Picture”.\nF) At the community meeting, the argument that the statistic is being used to support is that the neighborhood’s average income is too low for another tax increase. Yer perhaps this isn’t the most relevant statistic to use in this situation - maybe it is a property tax that only affects properties larger than X size. See Chapter 7, “The Semi-Attached Figure”.\nMy second question is how anyone would update this book for today. Are the ways that people misrepresent statistics the same as when the book was written? For the most part, I think yes. Perhaps the methods are more sophisticated, and it takes more background knowledge to be able to pick a statistic apart than asking what type of average was used. But most of the statistics reported in the media are still generally framed in ways that most people will understand: averages, percent changes, or correlations.\nI’d also argue that a better understand of these basic errors have also led to the sort of “barrage of statistics” arguments that are common today. No reasonably-informed person will give just one statistic anymore - they’ll give 4 or 5, each linked to a very long and technical academic paper, or no sources at all, just a vague “read it somewhere.” Huff points out the overall error here in the book - how does the statistic relate to the argument - but disproving the argument might require an in-depth discussion on each statistic.\nThis is the biggest limitation with the book: now you are skeptical, but unsure how to demonstrate anything yourself. A general sense that something may not be what it proclaims it is will not win an argument. It is unlikely that you will read the academic paper, that you will review the aggregated data, that you can replicate the study… where does the skeptic go from here?\nThe book is at its best when exposing misleading statistics that should have a reliable, straightforward, and meaningful interpretation. But with statistics increasingly being deployed through more complex modeling, what is the path forward?\n","permalink":"http://localhost:1313/posts/how-to-lie-with-statistics/","summary":"\u003cp\u003eWritten by Darrell Huff and illustrated by Irving Geis. Originally published in 1954.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eIn a sentence\u003c/strong\u003e: a quick, worthwhile general knowledge read that explains how people misuse statistics through familiar and useful examples (that could use an update).\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://laggingindicators.blog/wp-content/uploads/2024/03/20240303_185748.jpg?w=166\"\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eI’ll face up to the serious purpose that I like to think lurks just beneath the surface of this book: explaining how to look a phony statistic in the eye and face it down; and no less important, how to recognize sound and usable data in that wilderness of fraud…\u003c/p\u003e","title":"How To Lie With Statistics"},{"content":"The following is a curated list of news articles by U.S. state and nationally that discussed SNAP benefits in February 2024.\nNational Letter from Secretary Vilsack to Governors on SNAP Performance and Operations\nPoor performance on the SNAP efficiency measures meant 44 states got letters from the USDA expecting improvements. Congressional leaders agree on ag funding as Vilsack talks about SNAP pilot\nThe SNAP pilot they discuss is the SNAP-choice pilot, limiting purchasable foods to “nutrient-dense” foods. Unsurprising that a paternalistic policy with the name “SNAP-choice” is being pushed by a Republican. See the next article for the industry’s response.\n“GusNIP” must be one of the worse acronyms out there.\nNearly 2,500 Independent Grocery Stores Ask Congress to Oppose SNAP Restrictions\n2,500 signatories sounds better than one trade association. This accounts for slightly less than 1% of the nearly 260K retailers that accept SNAP benefits (number from their own letter).\nHere is the actual letter. Prior to starting to read these sorts of arguments, I didn\u0026rsquo;t realize how much money retailers make off SNAP. This association is simultaneously blocking efforts by Republicans to stop SNAP restrictions and a bi-partisan reporting requirement.\nHere is a considerate response against the Association’s response from the American Enterprise Institute, pointing out that restrictions already exist on what can be purchased, how the point of the pilot is to find out if health outcomes improve, and that SNAP is purposefully designed to increase nutrition among low-income households.\nPR alert - an online-only grocery store made the news for now accepting EBT payments. Many of the placed news articles somewhat ignore the USDA pilot has been ongoing, and online EBT payments are accepted by a retailers in all 50 states currently. But this is the first online only store, apparently. It still seems heavily promoted with sensationalist headlines.\nFetterman introduces legislation regulating SNAP retailers\nHere is the link to the bill (text not yet available at time of publishing). COLAs Don’t Count Act of 2024\nHere is the link to the bill. Meant to exclude cost of living increases from SNAP income assessments. Alaska Bill would relax food stamp income eligibility requirements for Alaskans\nFood assistance advocates seeking substantial fixes as record demand, food stamp problems persist\nMost of the articles I’ve seen, when discussing backlogs, refer to department statements that the agencies are successfully working through them and should be cleared soon. That isn’t a relief to families who needed assistance months ago, however, and I am curious about lessons learned from state agencies in handling unexpected influxes in applications. https://alaskapublic.org/2024/02/15/as-alaska-pays-millions-to-fix-food-stamp-backlog-lawmakers-suggest-systemic-fixes\nNew York https://gothamist.com/news/thieves-are-stealing-millions-of-dollars-of-new-yorkers-cash-benefits\nhttps://collive.com/multiple-reports-of-ebt-food-stamps-stolen-in-crown-heights/\nSNAP Benefits Could Be Quadrupled for Millions of Recipients\nNY State Senate has a bill in committee which proposes a increase in minimum payments by the difference between the monthly SNAP payment and $95 or $100, depending on if you read the bill sponsor memo or the proposed amendment text as of 2/20/24. Perhaps they copied New Jersey, which increased theirs to $95. This article confused the bill text with the sponsor memo it seems. New Proposal Would Automatically Apply Coupons For SNAP Recipients\nThe news article rightly raises some pointed, insightful questions about the proposal, like, how the f*** would this work? Bill linked here, but I\u0026rsquo;ll just copy and paste the text here because the entire proposal is three sentences. Section 1. Section 95 of the social services law is amended by adding a new subdivision 12 to read as follows: 12.(a)Any food distributor that accepts SNAP benefits shall establish a mechanism to apply any available coupons or discounts to purchases made by eligible recipients of SNAP benefits. (b Any such available coupons or discounts shall be automatically applied when a customer makes a purchase using SNAP. An eligible recipient of SNAP benefits shall not be required to provide a physical coupon in order to receive the discount from such coupon. § 2. This act shall take effect immediately. S08552 Text\nNew Mexico State seeing backlog of SNAP applications and renewals\nWith these types of articles, and the one below, I am curious to learn more about the technology used to process and approve applications and renewals. How many can one person do each day? Former HSD contract workers share their concerns on SNAP benefit processing\nWorkers means one worker. Not a very newsworthy criticism, but it is interesting to see reporters focus on the failures of the state government SNAP application workers. Nebraska Nebraska lawmaker wants mandatory work requirements for SNAP benefits Another very short bill proposal. It\u0026rsquo;s interesting because of the relevant fiscal analysis finds that the cost of making the current program mandatory \u0026ldquo;is $329,036 in FY25 and $460,651 in FY26,\u0026rdquo; while for expanding the program to new areas, \u0026ldquo;the estimated cost is $1,964,927 in FY25 and $2,750,897 in FY26.\u0026rdquo;\nSomehow the news article calculates the cost to be ~4.5 million, but summing those numbers gives me a estimated cost of $5,505,511 over 2 years.\nOn the program\u0026rsquo;s website, it states that \u0026ldquo;Participants must live in or around one of the services areas below. SNAP Next Step E\u0026amp;T is currently expanding and new areas are being added\u0026rdquo;.\nExpanding the SNAP program constitutes about 85% of the estimated 2-year cost.\nThe OpenSky Policy Institute quoted against this bill provides reasonable evidence that work mandates aren\u0026rsquo;t clearly effective, but also conveniently uses the larger number in their response.\nI am curious if the lawmaker will rewrite the bill to clarify that it will be mandatory in current service areas without expansion.\nAn additional interesting note in the fiscal analysis is the delay forced by updating regulations:\nHowever, the primary barrier to this time frame will be that the 475 NAC regulations will need to be updated as current regulations state that E\u0026amp;T is a voluntary program. The regulation process can take over 12 months to complete.\nLB 1381, FISCAL NOTE, PREPARED BY: Mikayla Findla\nOklahoma USDA sends letters to Oklahoma, 46 others over poor SNAP benefit efficiency No comment, one of many. Ohio Applying for SNAP benefits? In Cuyahoga County, expect to wait on hold for an hour \u0026hellip; if you’re lucky enough to get through I tried to locate this data on the county website, but was unsuccessful. I\u0026rsquo;m not even sure the website or phone number is correct. I don\u0026rsquo;t understand how news articles don\u0026rsquo;t link to the sources of what they are reporting on. From the Cuyahoga County website SNAP page. It is a bit unclear to me if you need to apply online, then call, then go to a local library, then go to a Family Service Center?\nAmazingly, the Apply Online link in Step 1 leads to a 404 error (https://benefits.ohio.gov/)\nMississippi, Kansas The feds tell Missouri and Kansas to fix SNAP application errors, as thousands lose food benefits\nMisleading headline, somewhat. Errors in their SNAP applications are not causing thousands to lose their benefits. This is reporting on the recent letters from the USDA on these states not meeting the minimum performance indicators. https://www.msn.com/en-us/health/nutrition/kansas-bill-would-ask-feds-for-permission-to-ban-candy-and-soda-purchases-with-food-stamps/ar-BB1ivELq\nTennessee Retired deputy loses SNAP benefits due to income changes\nFood stamp issues continuing to impact families in the Memphis area, backlog of cases not yet worked through\nThey mention bringing in an outside contractor - to solve the software issue? I am a bit confused on how outside contractors can be leveraged for SNAP applications. Kentucky GOP bills to cut SNAP benefits, loosen child labor laws advance in House First off, what a combination for a headline. The bill is available here.\nReading the changes, the proposal removes many of the waivers available while prohibiting any increases to benefits unless required by federal law. Waivers to the work requirements were previously available without approval from the General Assembly if a) a county with an unemployment rate of 10% or more, b) if the cabinet \u0026ldquo;determines economic conditions are severe enough in a county\u0026rdquo;, or c) if the state\u0026rsquo;s unemployment rate is 10% or more, a statewide waiver could be granted (p.4).\nFrom the FRED, the statewide unemployment rate is very rarely above 10%; county level maps (Dec. 2023, annual 2022) indicate that 10% unemployment is also rare; so I\u0026rsquo;m curious to see if option b) is ever applied, and in what circumstances. How often are these waivers granted?\nA local news report on this with some quotes is here, or here.\nSponsor Rep. Wade Williams, R-Earlington, called Kentucky’s economy “red hot” and cited the roughly 112,000 job openings in the state as of November, down from 118,000 in October. Sarah Ladd\nIt\u0026rsquo;s surprising, since a report that the author links to indicates available job openings decreasing steadily, and in November 2023, Kentucky had a rate of .8 unemployed people per job opening - so there are not enough people looking for work to even fill the available jobs - plus considering it is likely that individuals on SNAP may not be able to work.\nSecondly, the bill reinstates an asset test:\nThis would exclude households that have savings worth $2,750 as long as there are no disabled or elderly people in the household. This number increases to $4,250 for seniors and people with disabilities\u0026hellip;.\nSarah Ladd\nHow does the asset test work? These two reports do a nice job of explaining:\nA Quick Guide to SNAP Eligibility and Benefits (2023)\nEliminating Asset Limits: Creating Savings for Families and State Governments (2018)\nIowa https://www.radioiowa.com/2024/02/19/u-s-d-a-says-iowa-needs-to-speed-up-processing-of-snap-benefits\nCalifornia https://www.independent.com/2024/02/13/santa-barbara-county-sees-big-spike-in-food-stamp-cases\nWashington D.C. DC SNAP recipients begin receiving extra temporary benefits in their accounts Details here, lasting until September 2024. It appears to be based on a bill from FY 2022, but not funded last year. West Virginia https://mountainstatespotlight.org/2024/02/14/snap-food-stamp-benefit-senate-changes\n","permalink":"http://localhost:1313/posts/snap-benefits-news-feb-2024/","summary":"\u003cp\u003eThe following is a curated list of news articles by U.S. state and nationally that discussed SNAP benefits in February 2024.\u003c/p\u003e\n\u003ch3 id=\"national\"\u003eNational\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.fns.usda.gov/snap/governor-letter-performance-operations\"\u003eLetter from Secretary Vilsack to Governors on SNAP Performance and Operations\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePoor performance on the SNAP efficiency measures meant 44 states got letters from the USDA expecting improvements.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.thefencepost.com/news/congressional-leaders-agree-on-ag-funding-as-vilsack-talks-about-snap-pilot/\"\u003eCongressional leaders agree on ag funding as Vilsack talks about SNAP pilot\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eThe SNAP pilot they discuss is the \u003ca href=\"https://www.politico.com/live-updates/2024/02/16/congress/nearing-nutrition-funding-deal-spending-talks-00141962\"\u003eSNAP-choice pilot\u003c/a\u003e, limiting purchasable foods to “nutrient-dense” foods. Unsurprising that a paternalistic policy with the name “SNAP-choice” is being pushed by a Republican. See the next article for the industry’s response.\u003c/p\u003e","title":"SNAP Benefits News - Feb 2024"},{"content":"Microsoft Teams provides an integration with Microsoft Viva, which schedules daily check-ins to record your perception of your mental state. Once a day, at 4pm, I get a notification that asks me to select one of five emojis that reflects how I feel.\nClearly, the last few weeks have not been particularly excellent, but I\u0026rsquo;m not sure what the value of this type of check-in or chart provides. We can come up with reasonable estimates of our own satisfaction with our work. I frequently journal, and I believe that the self-reflection forced through written inquiries gives way to a better sense of being, rather than an even shorter point-in-time indicator with almost no ambiguity.\nOur days are composed of moments, and for most, are each filled with a wide range of emotions. This survey, given in the morning, likely would see different results as I start the day less stressed. Near the end of the day, I am likely thinking about all the tasks that remain undone.\nWhat is the natural evolution of work software that attempts to summarize work habits? What are the aspects that I would find valuable to improve my productivity? It is hard to beat the simplicity of a well-kept task list. I can\u0026rsquo;t say I look much beyond the satisfaction of checking off tasks each day.\nThat said, some analytics and productivity features I would like to see:\nI would be curious about intelligent time use measures during meetings. For example, what percent of time during meetings am I speaking, or not paying attention and doing another task? A small note on requested recurring meetings that states \u0026ldquo;you usually don\u0026rsquo;t speak during this meeting. Consider reading the meeting notes after,\u0026rdquo; or something similar.\nBetter email management and task linking would be extremely helpful - grouping emails, creating and resolving tasks, etc. A log of what I completed each day, stored and aggregated locally on my computer, that I could track over time would be great as well, e.g., if VSCode notes I edit a code file with name “file_x”, and push it to a remote repository, then my daily summary could note “Spent 1 hour editing file_x and pushed to remote”, along with “replied to 6 emails on new dashboard, notes on proposed analysis,” etc.\nThe new OCR integrated into the screen snip software is excellent, and I use it very frequently. More like this! Better copy and paste of tables would be great.\nImproved auto-complete, similar to GitHub Copilot.\nBetter voice support. The new Windows 11 Voice Access needs lots of work.\nOverall, I am less interested in my work software trying to identify and improve my emotional mindset, and more on streamlining how I work.\n","permalink":"http://localhost:1313/posts/viva-insights-how-are-you-feeling/","summary":"\u003cp\u003eMicrosoft Teams provides an integration with Microsoft Viva, which schedules daily check-ins to record your perception of your mental state. Once a day, at 4pm, I get a notification that asks me to select one of five emojis that reflects how I feel.\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://laggingindicators.blog/wp-content/uploads/2024/02/image-12.png?w=936\"\u003e\u003c/p\u003e\n\u003cp\u003eClearly, the last few weeks have not been particularly excellent, but I\u0026rsquo;m not sure what the value of this type of check-in or chart provides. We can come up with reasonable estimates of our own satisfaction with our work. I frequently journal, and I believe that the self-reflection forced through written inquiries gives way to a better sense of being, rather than an even shorter point-in-time indicator with almost no ambiguity.\u003c/p\u003e","title":"Viva Insights - How are you feeling?"},{"content":"I recently went on a weekend trip, where I counted each time that I interacted with a person who was a citizen of the country I was visiting. I did not include any interactions with individuals at the airport prior to landing at the destination, nor once I reached the airport to return. Non-verbal interactions were not considered, e.g., making room for someone on the sidewalk, or gesturing for a car to go first at an intersection.\nOut of 29 interactions, only 3 did not include a purchase. 2 of the 3 interactions which did not include a purchase, notably, were asking questions about making a purchase (what a type of food at a stand was, and if a person was leaving a table at a beach that we could sit at). The third was talking to the front desk attendees about entrance to a free cultural center and an art exhibit of Joan Miro. I only had to log our entry in a guest book.\nOf course, many of these exchanges could be classified as cultural learning or engagement - history and art museums, ruins of ancient civilizations, tour guides of haciendas - but others were for tequila , dinners, or marquesitas (get it with the cheese; it really is delicious). Sure, call eating locally made desserts cultural engagement, but it still is defined by a purchase.\nOn our last vacation, we did meet a local couple and had a few lunches, dinners, and drinks with them (over a two week period), but that is the only recent instance I can recall that was not defined by a commercial exchange.\nHow, if at all, are cultural exchanges affected by being offered as paid services to tourists?\nOther notes:\nWhat are those enormous paper guest books that log name, nationality, age, and number of guests used for? Does someone go through each day to aggregate the data for future funding?\nIt would be nice if countries had \u0026ldquo;contemporary history museums:\u0026rdquo; places where tourists could go to interactively learn more about very recent history that explains current political and social tensions, from locals rather than international news. Why are things they way they are? What are the social forces that are having practical effects on people\u0026rsquo;s lives in the country? What are people concerned about?\n","permalink":"http://localhost:1313/posts/all-my-cultural-tourism-is-commercial-exchanges/","summary":"\u003cp\u003eI recently went on a weekend trip, where I counted each time that I interacted with a person who was a citizen of the country I was visiting. I did not include any interactions with individuals at the airport prior to landing at the destination, nor once I reached the airport to return. Non-verbal interactions were not considered, e.g., making room for someone on the sidewalk, or gesturing for a car to go first at an intersection.\u003c/p\u003e","title":"All my cultural tourism is commercial exchanges"},{"content":"I started to post SNAP performance indicators from the USDA in machine-readable format, aggregating and cleaning the data from the many PDF tables. This repository includes quick-access to cleaned, FIPS-linked CSV long-format tables of yearly state reported indicators for Application Processing Timeliness, Program Error Rates, and Case and Procedural Error Rates (coming soon).\nUSDA Descriptions as follows:\nApplication Processing Timeliness \u0026ldquo;measures the timeliness of states’ processing of initial SNAP applications. The Food and Nutrition Act of 2008 entitles all eligible households to SNAP benefits within 30 days of application, or within 7 days, if they are eligible for expedited service.\u0026rdquo;\nPayment Error Rates (PER) \u0026ldquo;measures how accurately a state agency determined SNAP eligibility and benefit amounts for those who participate in SNAP. Errors include both overpayments \u0026ndash; when households receive more benefits than they are entitled to – and underpayments – when households receive less benefits than they are entitled to.\u0026rdquo;\nCase and Procedural Error Rates (CAPER) \u0026ldquo;assesses the accuracy of state agency actions in cases in which applicants were denied, terminated, or suspended and did not receive benefits. It also measures a state\u0026rsquo;s compliance with federal procedural requirements, including the timeliness and accuracy of notifications sent to affected households.\u0026rdquo;\nPlanning to use this as a simple dataset for exploratory data analysis and test visualizations. I added FIPS codes, and the data is in tidy format, so should be very easy to go straight to visualization.\nNote: this data is not synced regularly. Be careful when using the data and ensure it matches any posted documents. Data was accessed Feb. 2024, and extracted with OCR. Rates are published yearly. I don\u0026rsquo;t see a way to be notified if any corrections are made, so data will be refreshed with each USDA release.\nThe GitHub repository is available here. You can download the data or read it into dataframes easily with most popular libraries by accessing the raw content, e.g.,\ndf = pd.read_csv([https://raw.githubusercontent.com/](https://raw.githubusercontent.com/)...repository_file_path)\n","permalink":"http://localhost:1313/posts/snap-state-performance-indicators-datasets/","summary":"\u003cp\u003eI started to post \u003ca href=\"https://www.fns.usda.gov/snap/efficiency-effectiveness-measures\"\u003eSNAP performance indicators\u003c/a\u003e from the USDA in machine-readable format, aggregating and cleaning the data from the many PDF tables. \u003ca href=\"https://github.com/leppekja/SNAP-performance-indicators\"\u003eThis repository\u003c/a\u003e includes quick-access to cleaned, FIPS-linked CSV long-format tables of yearly state reported indicators for \u003ca href=\"https://www.fns.usda.gov/snap/qc/timeliness\"\u003eApplication Processing Timeliness\u003c/a\u003e, \u003ca href=\"https://www.fns.usda.gov/snap/qc/per\"\u003eProgram Error Rates\u003c/a\u003e, and \u003ca href=\"https://www.fns.usda.gov/snap/qc/caper\"\u003eCase and Procedural Error Rates\u003c/a\u003e (coming soon).\u003c/p\u003e\n\u003cp\u003eUSDA Descriptions as follows:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eApplication Processing Timeliness \u0026ldquo;measures the timeliness of states’ processing of initial SNAP applications. The Food and Nutrition Act of 2008 entitles all eligible households to SNAP benefits within 30 days of application, or within 7 days, if they are eligible for expedited service.\u0026rdquo;\u003c/p\u003e","title":"SNAP State Performance Indicators Datasets"},{"content":"I took about 70 classes over a one-year unlimited class subscription with Babbel Live for Spanish from mid-2022 to 2023. My level was beginner to low intermediate over the course of the year, and I only took classes in the A1, A2, and B1 range. Prior to the classes, I was working with Anki flashcards and Duolingo lessons. What follows are some thoughts I had wrote down while taking the courses. Some aspects of the course may have changed since I took them.\nFor those who haven’t looked into Babbel Live, the classes are online and slides-based, with up to 6 students and a single instructor. You can book up to a few minutes in advance. They run for about 55 minutes. Class Activities The classes were all structured the same, which I found helpful, but repetitive – after a few classes, I began to recognize certain phrases that made the classes go smoother, and I knew what to expect. You could also view the slides in advance of the class. Each would have generic stock photos, and simple phrases or lessons that you could expect in a middle school class. They don’t feel intimidating, and the slide design the same across all classes. Rarely, teachers will take out their own learning materials and use those in place of the slides.\nEach class is focused on a single subject – how to talk about vacations, or your family, or what you are doing. Depending on the class, they have a mix of new vocabulary, sentence matching to a photo, a simple conversation in a break-out room, a grammar exercise, or a list of question prompts.\nEach class starts with a short introduction from each student (where you are from, why you are learning Spanish, and maybe an additional question or two). While this was repetitive, it did help me in my visa interview, as I had practiced explaining that my partner was moving to Mexico for work so many times by that point.\nDepending on the teacher, the class may finish the slides early or not at all. Occasionally some teachers will ask the class to further describe what is in a picture or spend more time asking for vocabulary words on a topic. If the class finishes the slides early, the teacher might ask people what they are doing for the day after the class is over, or how everyone feels about what they learned.\nAt the Newcomer level, the classes were much more focused on vocabulary than grammar. It was difficult to tell frequently which class would be more focused on grammar. Even so, on the Newcomer level, the grammar exercises were never in-depth. For example, when learning to talk about vacations, we learned the past tense for the I, you, and we forms. The next exercise was to talk about each other’s vacations, which involved using the third person he and her tenses – which we didn’t go over in advance, which made it very confusing.\nThe classes could have done a better job incorporating cultural lessons on holidays, food, etc., that helped us learn about the countries we might travel to. And to some extent, the teachers will make up for this, telling us about their lives.\nThe courses are catalogued as Newcomer, Beginner, Intermediate, and Advanced. I struggled a bit with the jump from the Newcomer to Beginner level. From what I saw, Babbel didn’t give any guidance about when you are ready to move up a level at all. The lessons were structured the same. The key difference was that teachers spoke much quicker, used more advanced verb forms or domain-specific vocabulary, and expected that answers would come with reasons. The students still had a range of skill levels in these classes though. For the first few tries on the A2 level, I was the worst student.\nThe Teachers and the Students The small-group experience was enjoyable. For the most part, I liked the people who showed up. Most of them were clearly committed to learning the language. It was almost all people from the United States or European countries. Most were learning Spanish either to talk to people they knew (friends or work colleagues), because they had a Spanish-speaking family member, or because they had an upcoming trip.\nThat said, in many Newcomer classes, you would encounter either a) a person who was much more advanced than everyone else, or b) a person who was a genuine newcomer to the language and had difficulty understanding or speaking at all. I only remember one or two classes where people were not engaged or simply difficult to work with. In these cases, the teachers handled those students very well, and it didn’t interfere with the class too much.\nThe Newcomer teachers were all excellent. Each teacher was engaging, encouraging, and helpful. All would take notes and share in the chat, either through screenshots or typing. There were differences in teaching styles, but those were limited to how many mistakes they corrected for each student, usually. For the most part, after every slide, they would stop and check if anyone had questions about the material. I wish I could reach out to some of the teachers for private lessons.\nOn the User Experience Live was not well integrated with the rest of Babbel. Three small things first:\nOn my homepage, I would always see an ad asking me to sign up to Babbel live, even after I had purchased the subscription.\nSecondly, the “My Activity” progress tracker doesn’t account for any Live classes either, which made it useless for me. These might not affect my learning, but they do increase my enjoyment of being on the platform – I would have liked to see how many hours I spent in class, or how many unique people I was in class with, for example.\nLastly, after the class, there was an option to give feedback about the class in a short survey. I took most of these to compliment the teachers and say thank you. The pop-up asking me to give feedback didn’t disappear even if I had already completed the survey, which was annoying. The placement quiz panel also never disappears, even after you take the placement quiz.\nMore significantly, the self-review exercises did not incorporate what I learned at all in the Live classes. The “Practice” tab didn’t include any vocabulary that I learned in the courses! And while the Live courses linked to exercises if you viewed the “Prepare for Class” or “Recap”, I would have much preferred to have the class vocabulary automatically added to a deck of flashcards, for example. Very often the self-study lessons that the Live classes link to aren’t at all related to what you learned in the class.\nI really disliked the self-review exercises. Duolingo has a much better user interface on the desktop version that makes learning feel much smoother and more fun. The Courses on Babbel are also confusing to navigate through. You have an option for “My Level,” which was a very basic course that was onerous to get through. The “More Courses” tab didn’t really say anything about the level of the course, nor was it as tightly contained as Duolingo’s course selection is. Babbel’s self-exercises largely mimic Duolingo, but less intuitive and convenient.\nMy biggest UI/UX complaint was that I couldn’t set my time zone manually for the Babbel Live course listings. They depend on accessing the browser’s geolocation. When I traveled, or when I enabled a VPN, this completely changed the time zone of the classes. And nowhere on the site do they tell you the current time zone! Multiple times I booked courses in the wrong time zone and had to cancel. The Help chat has a specific question answering this, so I can’t be the only person to encounter this. When I reported this to the Support team, they directed me to a Babbel Wishboard. The link to this page did not work. I eventually added my feedback in after some back-and-forth, but my subscription ended before anything was ever implemented. I don\u0026rsquo;t know the status now.\nScheduling The Babbel Live course selection had a wide-enough range, but limited timings for my schedule. I generally practiced every weekday at 8am, then on the weekends, two classes in the morning. After about a week and a half, I had trouble finding new classes at the right time at the Newcomer level. It seemed that usually there were 2-3 courses scheduled for each hour. Whether these courses had available room depending on when you were scheduling the course. Sundays, I think, were the busiest and had the most fully-booked courses. I generally booked my classes for the entire upcoming week on a weekend, and didn’t have trouble finding at 8am (ET) course for the most part.\nNote that it did warn you that if you schedule and cancel with less than 24 hours notice, or miss a class, they may fine you. I never received any sort of penalty for missing a class or canceling.\nOne note is that the platform didn’t offer great filtering capabilities. I could look up by level, day of week, or time of day. I could also hide previously attended or fully booked classes. The time of day selection isn’t a specific hour, but parts of the day, e.g., 12pm to 5pm, or 9pm to 6am. This wasn’t really helpful, since it meant I still had to scroll across many irrelevant times to find the right spots. I would have also liked to filter by the class topic, or by whether it focused on a specific grammar exercise, or what conjugations or verbs were part of the class.\nSummary Overall, if you don’t have enough money to afford private classes, Babbel Live may be a good deal for you.\nThe classes can feel repetitive, and with up to 6 students, you may not get the personalized attention that you need to improve. A flexible schedule helps here, allowing you to target classes with very low participation. Using Babel Live as a supplement to private instruction may be helpful if you don’t have people to practice with.\nScheduling was not a problem, but filtering could be improved, and popular times could fill up quickly. The 55-minute instruction period was a good amount of time to fit into a workday, but partially taken up with introductions and repetitive opening exercises.\nThe Live courses were not integrated at all with the rest of Babbel and that was a very frustrating point for many users. Hopefully they have improved this in the past year.\n","permalink":"http://localhost:1313/posts/thoughts-on-babbel-live-classes/","summary":"\u003cp\u003eI took about 70 classes over a one-year unlimited class subscription with \u003ca href=\"https://www.babbel.com/live\"\u003eBabbel Live\u003c/a\u003e for Spanish from mid-2022 to 2023. My level was beginner to low intermediate over the course of the year, and I only took classes in the A1, A2, and B1 range. Prior to the classes, I was working with \u003ca href=\"https://apps.ankiweb.net/\"\u003eAnki flashcards\u003c/a\u003e and \u003ca href=\"https://www.duolingo.com/\"\u003eDuolingo\u003c/a\u003e lessons. What follows are some thoughts I had wrote down while taking the courses. \u003cstrong\u003eSome aspects of the course may have changed since I took them.\u003c/strong\u003e\u003c/p\u003e","title":"Thoughts on Babbel Live Classes"},{"content":"If you\u0026rsquo;ve got the framework installed, and just want to deploy the static pages, skip to below. Note - my first time doing this, but it works. You can always deploy directly to Observable.\nObservable Framework is not supported on Windows, according to an issue in their GitHub. (Update Mar 2024: Observable Framework is now supported on Windows). To use it, you need to use WSL.\nIf you want to use it through WSL, then the following still applies. Fortunately, it is very easy to do. Steps I had to take to do this:\nInstall WSL from Powershell as described here, or in the Windows Store, download Windows Subsystem for Linux and a preferred Linux distro. It looks like the latest offering is just named Ubuntu in the Windows store.\nOnce you get Ubuntu from the App Store, if you don\u0026rsquo;t use the command line version, you need to install the application. Just click on it from your Start Menu, and a terminal will guide you through the install process, setting up a username and password.\nNote that you may need to enable WSL in the \u0026ldquo;Turn Windows Features on or off\u0026rdquo; menu (search this from the Start menu), and ensure Windows Subsystem for Linux is checked if you don\u0026rsquo;t use the command line install.\nCheck this box in the Turn Windows Features on or off menu\nIn VSCode, you can easily open a \u0026ldquo;Remote Window\u0026rdquo; on the bottom left corner of the screen. See the green button below, with the \u0026gt;\u0026lt; signs. Clicking it will open up a menu. Note that you now have a menu at the top; just select Connect to WSL. If a error pops up saying that \u0026ldquo;no distro is found\u0026rdquo;, then you need to ensure that it is installed, rather than just downloaded on your computer. The Powershell install manages this for you.\nOpen a new terminal (View \u0026gt; Terminal). It should show up as username@computername:~$.\nFrom here, install Node. Here is the Windows Dev guide. Only one note: a Could not resolve host: raw.githubusercontent.com error may appear if you are connected to a VPN.\nOnce you can run nvm ls and see the above, you can install the Observable Framework library following the Get Started documentation.\nYou can open the WSL folders in the file explorer of VS Code, as well. If you enabled a Git repository, and want to connect it to your account, use\ngit config --global user.email \u0026#34;you@example.com\u0026#34;git config --global user.name \u0026#34;Your Name\u0026#34; Set up a remote repository (you may need to connect VSCode to git as well).\nAs instructed in the Observable documentation, just run npm run dev and a server should start, and open to a new page in your browser, likely on 127.0.0.1:3000. You\u0026rsquo;re set!\nNow, deploying the static site to GitHub pages. The steps are very similar for any static site generator process.\nFeel free to update your title, located in the observablehq.config.ts file, to update the website title in the browser.\nRun npm run build in the working directory, which will create a /dist folder. Remove the /dist folder from the .gitignore.\nFollow the instructions on GitHub here to create a new site.\nCreate a new repository in GitHub, and follow the instructions in the \u0026ldquo;…or push an existing repository from the command line\u0026rdquo; code block.\ngit remote add origin https://github.com/user_name/repo_name.gitgit branch -M maingit push -u origin main Verify that your site appears in GitHub. Go to Settings \u0026gt; Pages, and choose Build and deployment \u0026gt; GitHub Actions.\nThere is an example workflow called \u0026ldquo;Deploy static content to Pages.\u0026rdquo; Click that, and a static.yml file should be created for you. The only edit to make here is editing the path argument from ., which is the whole repository, to ./dist, which reflects you production files.\nwith: # Upload only dist directory, default is \u0026#39;.\u0026#39; path: \u0026#39;./dist\u0026#39; - name: Deploy to GitHub Pages id: deployment uses: actions/deploy-pages@v4 This will ensure the base of your site arrives at the index.html page. Navigate to https://{username}.github.io/{repositoryname}/.\nIt\u0026rsquo;s deployed! Feel free to add a custom domain based on GitHub\u0026rsquo;s instructions here.\n","permalink":"http://localhost:1313/posts/using-observable-framework-on-windows-wsl-and-quickly-deploying-to-github-pages/","summary":"\u003cp\u003eIf you\u0026rsquo;ve got \u003ca href=\"https://github.com/observablehq/framework\"\u003ethe framework\u003c/a\u003e installed, and just want to deploy the static pages, \u003ca href=\"#deploying\"\u003eskip to below\u003c/a\u003e. Note - my first time doing this, but it works. You can always deploy directly to Observable.\u003c/p\u003e\n\u003cp\u003eObservable Framework is \u003ca href=\"https://github.com/observablehq/framework/issues/90\"\u003enot supported on Windows\u003c/a\u003e, according to an issue in their GitHub. (Update Mar 2024: Observable Framework is now supported on Windows). To use it, you need to use WSL.\u003c/p\u003e\n\u003cp\u003eIf you want to use it through WSL, then the following still applies. Fortunately, it is very easy to do. Steps I had to take to do this:\u003c/p\u003e","title":"Using Observable Framework on Windows WSL and quickly deploying to GitHub Pages"},{"content":"\nThe choices to make origami sunflowers are few. I adapted the simple Lotus Blossom design from Origami-Instructions.com with an additional small square of brown paper, allowing for a very simple sunflower design that holds up against other designs that have more complicated multi-sheet folding, are hexagon-based, or require glue.\nInstructions With the Blintz base, place a sheet of brown paper within the corner folds into the center.\nIt does not need to be large, but should be centered. The yellow paper will form an envelope around the sheet of brown paper. Fold the linked Lotus Blossom design above. On unfolding all of the center folds, the brown paper will be revealed, creating a sunflower-esque design.\nFeel free to add a simple stem as described at the end of this tutorial, or glue them flat against a scrapbook.\nSunflower against the sky.\nFor the flower pot, I used a pin in the center, fitted through a tightly folded up piece of green paper. While the rest does not use any other holding mechanic apart from folds, I though using a pin here was appropriate due to the back of the flower having very little holds (the worst outcome is for the present to immediately fall apart), and it being a sunflower! The pin adds a bit to the image of a sunflower, mimicking the sunflower\u0026rsquo;s center. No point in restricting yourself to the limitations of a craft if they prevent you from getting the look that you want.\nSee a few other origami sunflowers in these articles for comparison:\nBasic Sunflower from Origami instructions (Dislike the design)\nSunflower by Karen Elaine (very similar to the adapted lotus blossom design above, but slightly more difficult. Does come out with a more circular center, which I like)\nMulti-piece sunflower on Origami Spirit (many pieces, but pops. However, depending on the angle, the petals look slightly droopy. Not sure if it is the design or the camera)\nOrigami Sunflower designed by Jo Nakashima (beautiful, but slightly more complex and may be difficult for beginners)\nI don\u0026rsquo;t include any of the interlocking sunflowers, but if you search these, many will come up. These are usually assembled from many small triangle pieces that can can be slotted together.\n","permalink":"http://localhost:1313/posts/ridiculously-easy-origami-sunflowers-adapted/","summary":"\u003cp\u003e\u003cimg alt=\"A pot with origami flowers\" loading=\"lazy\" src=\"images/20240215_102140.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003eThe choices to make origami sunflowers are few. I adapted the simple \u003ca href=\"http://www.origami-instructions.com/origami-lotus-blossom.html\"\u003eLotus Blossom\u003c/a\u003e design from Origami-Instructions.com with an additional small square of brown paper, allowing for a very simple sunflower design that holds up against other designs that have more complicated multi-sheet folding, are hexagon-based, or require glue.\u003c/p\u003e\n\u003ch3 id=\"instructions\"\u003eInstructions\u003c/h3\u003e\n\u003cp\u003eWith the Blintz base, place a sheet of brown paper within the corner folds into the center.\u003c/p\u003e","title":"Ridiculously Easy Origami Sunflowers (adapted)"},{"content":"Some people are very into keyboards. They build them, they buy many of them, they review them. They know a lot about the software and hardware, and can describe the pros and cons of each component. When they look for a keyboard, they can use their prior experience to decide what features they care about, and can identify potential issues.\nI am not one of these people. But given recent wrist and forearm pain, I decided to switch impulsively to a split keyboard. I did some not-comprehensive-at-all research - I didn\u0026rsquo;t really know what I was looking at, or how to compare different brands, or what attributes to consider that would be right for me. I ended up buying the MoErgo Glove80 Split Wireless Keyboard, largely because the curved design, tenting system, and my perception of the company as a start-up that had a large passionate community behind the product. It also looked reasonably professional, minimal, and like it would fit on my desk.\nWhen considering which keyboard to buy, I also looked at the Logitech Wave, Kinesis, Microsoft Sculpt, and others. I disqualified the Moonlander, Voyager, ErgoDox and others based on the flat design; I thought the curved looked like it would be more comfortable. If you hold your hand straight out, palm down, and watch your fingers as they bend while keeping your forearm still, then you can see the area they reach is on a curve. It is not scientific, no, but my primary guide when looking at different keyboards was identifying in what positions my arms and hands felt most comfortable in, and disqualifying keyboards which I thought would force me to move from these positions. This is also why I went straight to a split keyboard, rather than the connected keyboards that just angle the keys slightly differently, like the Microsoft and Logitech keyboards linked above.\nI am not able to solder, so that removed a few other smaller keyboard options from my list. It is exciting seeing how people modify their keyboards to meet their unique needs, but it is not the most accessible hobby, especially getting started. I wanted to buy pre-built. I was also hesitant to switch to a keyboard that made the decision to remove keys, like the Charybdis Nano, for example. I did not use function keys regularly, or program key macros, so I wanted the most familiar keyboard, but structured differently. Now, after using the Glove80 for a few months, I think this would be much less important to me. I am much more open to using and programming function keys, layers, and specific key press sequences than I was before.\nSo, I bought the Glove80. The following is what I think of it after using it for about three months. Note again that I haven\u0026rsquo;t used any other split keyboards, so I won\u0026rsquo;t compare features, or comfort, except against laptop keyboards or the Logitech MX Keys for Business, which I used for about a year prior to the switch.\nThe keyboard after a few months of use.\nBefore any criticism, I want to say that this is a fantastic product on the whole. I want to thank the people involved in making this, designing it and spending so much time in our lives to improve it. The creators really deserve a lot of credit. For my first foray into a split keyboard, I\u0026rsquo;m very happy with it. Note that if you\u0026rsquo;re considering buying a keyboard like this, you won\u0026rsquo;t heal every pain in your body, But I\u0026rsquo;ve undoubtedly noted a difference since I\u0026rsquo;ve stopped pronating my forearms so much. That said, I also type less. I\u0026rsquo;m trying to use voice access more. And in general, just rest my hands.\nThe Build But the Glove80 is all plastic, I read online. And for the most part it is. Compared to the Logitech MX Keys, which had a metal frame, the Glove80 is much lighter, and feels a bit less sturdy. But all the MX keys had to do was lie flat; the Glove 80 is tented on six feet, so I don\u0026rsquo;t mind a bit of flex. I don\u0026rsquo;t think that it feels cheap at all, and the primary frame of the keyboard is solid enough that I don\u0026rsquo;t have any complaints.\nThe palm rest is only connected by two screws to the main frame of the keyboard. This is meant to allow easy removal. I have never removed it, nor do I plan to, nor do I see many photos of it without the palm rest. So I would sacrifice the ease of unscrewing for a slightly more sturdy connection.\nWrist pad uses only 2 screws to connect to main keyboard.\nThe tenting is more limited than I was expecting, but I am reasonably happy with it. It is not a pleasant process to adjust. If you extend the screws out all the way, they can be slightly wobbly. And it\u0026rsquo;s tricky to make sure that both sides match. As seen above on the leftmost post, I used the additional supports to stabilize the rod. At very high levels of tenting, given the feet don\u0026rsquo;t angle, only an edge will connect with the ground, making it more wobbly. At that height, you\u0026rsquo;ll likely need a mounting solution that comes separately, and some example images are here. It is tricky, though, as depending on how you work (sitting, standing, etc.), if you adjust throughout the day, one mount might not be suitable for another position.\nNote that the rods are a standard size, so it is possible to mount and extend the Golve80 on whatever you\u0026rsquo;d like, given the interest, knowledge, time, and resources. For me, I took maybe two hours on a Saturday morning, and explored a few options. After a couple times adjusting, I found a comfortable and stable height, and haven\u0026rsquo;t touched it since. Overall, I was hoping for more extreme tenting and tilting options built-in, but you need to customize these yourself. The V2 nicely includes some additional rods and support pieces to help address this.\nI bought the Glove80 v2 just as it was being released, so it came with a carrying case. Just a brief note: the accessory case to carry the keyboard is fantastic, and well made. Opening the case to reveal the keyboard feels like you have just purchased a premium keyboard. Now, the keyboard is still bulky, So don\u0026rsquo;t expect to fit in to a laptop bag - unless you have a very large laptop carrying bag.\nKeyboard, case, and my laptop bag.\nIf you measure things by how many adult male cats can sit on it in the \u0026ldquo;loaf\u0026rdquo; position, the carrying case is roughly a 1. Note that cats may be uncomfortable with you using them as measurement tools, as seen here.\nThe key caps feel really smooth. I do wish I spent some time to explore the different types of key switches. I got the standard, recommended ones, and they are a bit too \u0026ldquo;clicky\u0026rdquo; for my preference. But they offer good resistance, and usually I have headphones on, so I don\u0026rsquo;t mind. I believe you can buy out test panels with all the different types of key switches, if you want to try them out before hand. The keys also wiggle a bit, side to side and back and forth, more than a laptop or the Logitech MX keys do. But when I\u0026rsquo;m actually using the keyboard, I don\u0026rsquo;t notice or mind this at all.\nI don\u0026rsquo;t like the LED lighting at all. I would say it\u0026rsquo;s the worst part of the keyboard for me. On the Logitech, the LED lights lit up the letters. Here, the LED lights are placed slightly above the letters, and the letters themselves aren\u0026rsquo;t see through (dark text on translucent white keys). For me, it means that only the top half the letter, or whatever text is on the key is half-illuminated only.\nLEDs lights are placed under the top half of the keys, which don\u0026rsquo;t highlight the keys comfortably in the dark\nPerhaps for some people who use it for gaming or for looks appreciate the programmatic control you have over the LEDS and the colored patterns they form. But not me. I want to be able to see the keyboard in the dark well. I don\u0026rsquo;t want a rainbow keyboard. Especially with the keys being in a different layout, there are times where I need to look down to see where certain key is. It is irritating, because my eyes go to the light and not toward the dark text that is lit up.\nSome people in comments online worried about the lack of homing keys. I agree with the support guide here; I don\u0026rsquo;t think you need them. The design and contours of the keyboard naturally put your fingers where they should go. Now, that said, initially I was putting my fingers incorrectly. Given that my hands feel bit small on the keyboard, I was initially starting with my index fingers on the innermost columns of each half. This allowed my thumb to reach all 6 thumb keys, without having to angle my wrist oddly or move my palm from the palm rest. After reading more of the support guide, I figured out that I had my fingers wrong.\nSize Now that I\u0026rsquo;ve mentioned this, the keyboard feels slightly too big for my hands. This might just be a situation of inaccurate expectations, but I was hoping really to not have to move my wrists or stretch my fingers out too much, especially with the columnar layout. But I still have trouble reaching the inner- and outermost columns, as well as the top two rows (number key and function key rows). I\u0026rsquo;ve also found that I would prefer a wrist pad that was slightly higher, rather than immediately sloping down. Leaving my wrists on the rest makes it a bit tricky to reach all the keys.\nI haven\u0026rsquo;t seen a keyboard company provide a great sizing chart. In the Glove80 marketing, they say it\u0026rsquo;s been tested on a range of hands. As a user with no experience in split keyboards, I took their word on it, and just hoped that my hands were within a standard deviation of the average hand size. Still, while typing or coding, I have to stretch my fingers out more laterally than I would like. In reviews for other split keyboards, I\u0026rsquo;ve seen comments that state the thumb cluster is difficult to reach; here with the Glove80, at worst I need a small wrist adjustment to reach all 6 keys.\nThis is why now after using the Glove80, I wouldn\u0026rsquo;t mind trying out a keyboard with less keys, that is a bit smaller and forced the user to use key sequences for certain keys. For me, I would prefer only moving my fingers up and down along the bottom 4 rows, and middle 4 rows, and I may adapt the keyboard layout again to accommodate that.\nI did change my keyboard layout from the Qwerty to the Workman layout. The Glove80 online layout editor worked great, so no complaints there. It was really easy to use, with the key being layouts that I could just choose from and adapt. I would not have gone through the pain of remapping every key. Even just trying to change the position of two or three keys slowed me down. Remapping does require you to restart the keyboard and install firmware, but this boils down to moving files between folders and pressing some keys. I know it isn\u0026rsquo;t perhaps the most user friendly thing. and could definitely confuse some people, but I imagine people buying this keyboard won\u0026rsquo;t have any trouble with it at all. Overall, I thought it worked fine.\nSupport The user guide is really nice. Control-F on a PDF is just easier than a million knowledge base articles that I have to hunt through. It isn\u0026rsquo;t a pain learning the Magic layers or Bluetooth set-up, but remembering which layers and lights correspond to what is a bit annoying. I think most times where I need to adjust a setting, I have to look up the user guide simply because I don\u0026rsquo;t remember what all the colors mean.\nThe Glove80 Discord is active. If you have a question, go there and ask it. I am confident someone will respond and help you out, which is a very comforting thing to see when buying a product as expensive as this one. And whenever I check in, which is perhaps once a month or so, I always see Stephen, a co-designer of the keyboard according to his profile, responding to queries and issues that people are posting about. It is reassuring to see this and to feel like you have a direct connection to somebody if something is going wrong. I haven\u0026rsquo;t interacted with him, so I can\u0026rsquo;t talk about potential troubleshooting or how well that goes. People will share their set-ups, shortcuts, layouts, and more, building a community around the product. A decent technical understanding is assumed in most cases, I think; for example, the firmware announcements or discussion of ZMK, or even understanding for non-tech people, why they talk about branches all the time. Recently, there was a Bluetooth connection issue with a firmware release, and the maintainer asked affected users to install a test fix and provide feedback. But again, I don\u0026rsquo;t expect anyone to be rude if you ask a basic question as long as it is serious and you put some thought into it prior.\nPersonally, in terms of any software bug, only rarely have I noticed some stuttering or lag or Bluetooth disconnection. This is pretty rare. It\u0026rsquo;s also happened on every other Bluetooth device anyone has ever used. So it doesn\u0026rsquo;t really bother me. There is also a cable that you can connect from your computer into the keyboard, if you prefer to use wired.\nI\u0026rsquo;m still struggling with how to handle a mouse along with the keyboard. I have limited space in the keyboard tray on this desk. and it doesn\u0026rsquo;t exactly fit on either side. It feels uncomfortable to have it in the middle. Often the mouse ends up on the main part of the desk, which also isn\u0026rsquo;t comfortable for me anyway. In the past month or so, a community member has added support for controlling the mouse within the keyboard. This doesn\u0026rsquo;t appear to be officially supported by the company, at least not yet. I\u0026rsquo;ve been looking at track balls, track pads, touch bands, eye control. and more. A keyboard like this that includes a trackball or some sort of pointing device would be nice, but I\u0026rsquo;ve also seen people online post about issues with straining their thumbs from overuse as well.\nAt the 100 day check-in email, they did provide a $20 discount code toward a second Glove80 keyboard, telling you to get your backup Glove80. I have no idea who would spend $400 more on a backup keyboard. And when I\u0026rsquo;ve told my friends about this keyboard, I think they\u0026rsquo;ve thought I was strange. None of them have asked if I could give them a discount code. What would be preferable is a discount code to use on accessories like mounting equipment. That said, the regular product emails and updates are a nice way to keep in touch, and it is helpful to see how you can improve your own workflow with the programmable nature of this keyboard.\nSummary So to summarize, if you are interested in getting your first split keyboard, I would consider the following:\nAfter having pain in your hands, take a lot of time to identify where your hands feel the most comfortable. Where\u0026rsquo;s the soreness in your fingers? On your wrist? Try to find that pose where you think your hands will be the most comfortable, and look for keyboards that would allow you to achieve that pose. This on its own rules out a lot of keyboards, and prepares you to think about how the rest of your set-up affects your comfort.\nThe size of your hands is something to consider, but companies don\u0026rsquo;t provide much reassuring about it. It might be strange for people who are in the keyboards, but that was definitely a concern of mine, since I think I have smaller hands. For others, my measurements are as follows:\nfinger lengths, measuring from the crease where my fingers first bend from my palm (right hand and left hand are equivalent (*phew*)):\npinky 6.5cm,\nindex 7.7cm,\nmiddle 8.3cm,\npointer 7.3cm.\nFrom my wrist to the top of my middle finger is 19cm.\nLaterally, palm down, fingers relaxed but straight, measuring across the back of my hand from the tip of my thumb to the edge of my pinky is about 14cm.\nIf I splay my fingers, the tip of my thumb to pinky is 21cm.\nIf your fingers are bright bigger than mine, then you should be fine with the Glove80. I\u0026rsquo;m not sure about other keyboards.\nDecide if you\u0026rsquo;re willing to deal with a few small technical steps to achieve what you want. If you\u0026rsquo;re OK with downloading a couple of files and pressing a couple buttons, then you\u0026rsquo;ll be fine with the Glove80. For now, given the maturity of the industry, you\u0026rsquo;re stuck with some personal to-do work if you want more custom set-ups in general.\nPeople make a big deal out of the key switches. If you\u0026rsquo;re really concerned, buy a key switch sample on Amazon and test it out. Otherwise, the standard is probably fine.\nNote the difference between a columnar or staggered layout. The Glove80 is columnar. Yes, there is a bit of an adjustment period, but if you are not switching from a QWERTY layout, the adjustment is not difficult.\n","permalink":"http://localhost:1313/posts/gove80-keyboard-review-3-months/","summary":"\u003cp\u003eSome people are very into keyboards. They build them, they buy many of them, they review them. They know a lot about the software and hardware, and can describe the pros and cons of each component. When they look for a keyboard, they can use their prior experience to decide what features they care about, and can identify potential issues.\u003c/p\u003e\n\u003cp\u003eI am not one of these people. But given recent wrist and forearm pain, I decided to switch impulsively to a split keyboard. I did some not-comprehensive-at-all research - I didn\u0026rsquo;t really know what I was looking at, or how to compare different brands, or what attributes to consider that would be right for me. I ended up buying the \u003ca href=\"https://www.moergo.com/\"\u003eMoErgo Glove80 Split Wireless Keyboard\u003c/a\u003e, largely because the curved design, tenting system, and my perception of the company as a start-up that had a large passionate community behind the product. It also looked reasonably professional, minimal, and like it would fit on my desk.\u003c/p\u003e","title":"Glove80 Keyboard Review (3 months)"},{"content":"- Whenever I do analyses I am nervous about being wrong, but using Excel\u0026rsquo;s autofill function to impute data would have definitely been on my \u0026ldquo;this is not correct to do,\u0026rdquo; at the very least.\n- Nice example of a personal project. Contained, clear output, and interesting to the person doing it + delightful to play with and generate maps as a person who has no use for it. It\u0026rsquo;s fun!\n- Helpful and clear description of how XSS (cross site scripting) vulnerabilities work and can be identified.\n- A nice reinforcement essay on how to study. I like these types of pieces - especially with the great comic selection - which give very practical advice, and are quick reads. They may not have any unique advice that you wouldn\u0026rsquo;t arrive to by yourself, but I imagine that by reading many of these, they reinforce the concepts in your mind over and over, hopefully making it easier for your to implement such advice.\n-Startling examples of \u0026ldquo;swatting\u0026rdquo; and how easy it is for online users to \u0026ldquo;swat\u0026rdquo; other people. Astounding that police departments don\u0026rsquo;t have more protections in place to ensure danger exists prior to creating dangerous situations. It appears they institute some \u0026ldquo;do not swat\u0026rdquo; lists, but for first time offenses, these are not helpful. Would be nice to read more about the people that answer these calls, and the decision-makers that choose whether to believe the tip or not. How do they evaluate trustworthiness, or do they always consider the potential chance of saving lives to outweigh that they may be wrong?\n","permalink":"http://localhost:1313/posts/monday-links/","summary":"\u003cp\u003e- Whenever I do analyses I am nervous about being wrong, but using Excel\u0026rsquo;s \u003ca href=\"https://retractionwatch.com/2024/02/05/no-data-no-problem-undisclosed-tinkering-in-excel-behind-economics-paper/\"\u003eautofill function to impute data\u003c/a\u003e would have definitely been on my \u0026ldquo;this is not correct to do,\u0026rdquo; at the very least.\u003c/p\u003e\n\u003cp\u003e- Nice \u003ca href=\"https://mewo2.com/notes/terrain/\"\u003eexample of a personal project\u003c/a\u003e. Contained, clear output, and interesting to the person doing it + delightful to play with and generate maps as a person who has no use for it. It\u0026rsquo;s fun!\u003c/p\u003e\n\u003cp\u003e- Helpful and clear description of how XSS (\u003ca href=\"https://journal.hexmos.com/domxss/\"\u003ecross site scripting\u003c/a\u003e) vulnerabilities work and can be identified.\u003c/p\u003e","title":"Monday links"},{"content":"227 vehicles have passed by us in the last hour. We are parked on the side of the road, in a car that is leaking oil. At least the hood has stopped smoking. Our two friends left in a taxi to Taluca, the closest town, to see a mechanic and have a grua tow us either to the town, or back all the way to Mexico City.\nWe had gone to the park to see the monarch butterflies before they begin their migration north; we arrived too late, the mariposas had left three days prior, but the trail was still open at a discount, and many bodies of the butterflies that died were still littered on the edges of the walking paths, the ticket takers told us. We had driven about 2 hours out of the city to see them; we were three days and two hours too late.\nThe path was dusty. The hundreds of boots trampled the grass into the ground many times over. Natured had ceded this narrow path and had left only loose rock and dirt that flew into the air with every step. We wore masks to avoid breathing it in, but even so, our mouths became dry and dirt had encrusted itself along where the masks had met our faces.\nPatches of dead butterflies attracted congregations of visitors. A path had been roped off due to people stealing the bodies and taking them home. The intact wings were still bright orange, dotted with black and white, but they were dirty, layered with the excrement from our boots on the path. They would be buried soon, I thought, from the crowds walking through. Children would probably pick them up and dust them off.\nThe butterflies had left too early; thousands were likely still coming to visit them through the end of February. But now they would cancel. Warmer temperatures in the north, perhaps, driven by global warming, may signal to the butterflies that it is time to leave earlier than normal.\nThe roads curved and winded down back to the city. The smell of burnt rubber persisted, and we pulled over to the side of the road. The hood smoked. A pool of oil underneath the front and a trail of drops followed us from behind. He stroked his finger along the ground; it came up dripping with the dark brown liquid, and he nodded.\nNo cell service to call for help. Cars passed, but we did not wave any down. Emergency lights on,and we decided, perhaps at 30 miles per hour, the engine would persevere. The car turned on without smoking, and drove for a few meters until the engine started clanking. We rumbled into a deep curve, along a cliff. He pressed the gas pedal, but the car did not respond, and we rolled to a halt.\nNo visibility from either side of the curve. The car smoked and soon it came through the dashboard vents. Car after car careened along the curve from behind us and deaccelerated rapidly. A line formed quickly. A policecar arrived, and a taxi man, and together we pushed the car 20 or 30 meters. Our feet slipped in the oil path. Uphill, now, but beyond the dangerous curve. The police truck, bumper to bumper, pushed the car forward to a pull off.\nThe police left. They left in the taxi, and will be back. Cars passed: 1,2,3,4,5\u0026hellip;\n","permalink":"http://localhost:1313/posts/dead-butterflies-broken-cars/","summary":"\u003cp\u003e227 vehicles have passed by us in the last hour. We are parked on the side of the road, in a car that is leaking oil. At least the hood has stopped smoking. Our two friends left in a taxi to Taluca, the closest town, to see a mechanic and have a grua tow us either to the town, or back all the way to Mexico City.\u003c/p\u003e\n\u003cp\u003eWe had gone to the park to see the monarch butterflies before they begin their migration north; we arrived too late, the mariposas had left three days prior, but the trail was still open at a discount, and many bodies of the  butterflies that died were still littered on the edges of the walking paths, the ticket takers told us. We had driven about 2 hours out of the city to see them; we were three days and two hours too late.\u003c/p\u003e","title":"Dead Butterflies, Broken Cars"},{"content":"For the first time, in my many years of eating lentils, I found a small stone in my lentils while I was eating the curry. It was slightly smaller than a single lentil.\nOn the bag of the lentils, and in every online recipe describing how to cook lentils, the following warning exists: be sure to rinse your lentils prior to cooking to remove any rocks or debris as modern cleaning equipment cannot. And I do. But I have never actually found a pebble, and so thought this was a cautionary warning that lawyers required. Now, I figured, the process of cleaning the lentils during production likely was efficient and accurate enough now (in the direct contradiction to what the warning tells me). A good self-reflection example of how my prior experience incorrectly outweighs expert knowledge.\n\u0026ldquo;A combination of gravity, screens and air flow is used to clean and sort lentils by shape and density\u0026rdquo;, is how Wikipedia describes the process. Most of the YouTube videos available focused on splitting the hull from the lentil, post-removing the plant, soil, and rock debris from the collected lentils.\nOnly a few videos, primarily from industrial companies selling lentil processing machines, showed this cleaning stage. Many of these give very little insight, instead showcasing the machines\u0026rsquo; attributes and very poor marketing materials.\nSorting by hand is a tedious process that somehow in videos only takes a few seconds, but the outcome is clear. It takes me longer to peruse the lentils for stones and small debris, though. With green lentils, I use water, but red lentils don\u0026rsquo;t float for the most part.\nA promotional video does a nice job of showing the before and after product, demonstrating what type of debris is removed from the lentils by each machine, but doesn\u0026rsquo;t demonstrate the mechanics of the cleaning process. The video description is quoted in full below:\nSensitive Cleaning Machine; screens the dust, corp, chaff, etc. from the product and finishes the pre-celaning process. Later; for sorting the high density things, product enters to the stone separator.\nStone Separator is mostly for sorting impurities like; stone, glass, dust, etc. Later the product enters to the Gravity Separator for separating light products.\nGravity Machine is used for separating the light materials from the product. This machine finalize the cleaning process. On the next step; product passes to the color sorting machine.\nAKY Technology\nA much more bountiful process was looking up each of these stages by the machine type, rather than focusing on lentil cleaning specifically, so I changed my research approach.\nThe lentils are dumped through a series of screens, shaken by an agitator, which allows the lentils to fall through the screen, while larger debris is stuck on top, and steadily shaken off to the side to be dumped on the ground.\nThe gravity sorting is the most clever aspect to this, sending the grains over a shaking panel that a) has air coming up from the bottom, and b) is slightly titled in one direction. Given the air is only powerful enough to push the lightest objects up, the heavier contaminants stay in contact with the panel and are shook in one direction. The lighter debris is pushed up and over in the opposite direction, going down the tilted panel on the other side. If I understand correctly, the settings to control the tilt, airflow, and vibration (eccentric movement), are set relative to the weight of the desired subtance.\nThe sorting \u0026ldquo;dry particles\u0026rdquo; by separating objects by their density is brilliant, and the speaker in this Oliver Manufacturing video has a great breakdown. Seeing in real time how adjusting the air and tilt settings of the machine affected the separation of contaminants was intuitive. A destoner machine appears to operate on the same principles as the gravity sorting.\n1. Honorary mentions go to a nice video on the farming and sustainability of lentils on a Canadian farm. Each lentil plant only grows about a foot tall, and the lentils are found within small pods in the plant. A pod may contain only 1 to 3 lentils each.\n2. The word \u0026ldquo;debris\u0026rdquo; belongs to that group of words that has no plural and is only plural when describing a plural noun, e.g., piles of debris.\n","permalink":"http://localhost:1313/posts/theres-a-stone-in-my-lentils/","summary":"\u003cp\u003eFor the first time, in my many years of eating lentils, I found a small stone in my lentils while I was eating the curry. It was slightly smaller than a single lentil.\u003c/p\u003e\n\u003cp\u003eOn the bag of the lentils, and in every online recipe describing how to cook lentils, the following warning exists: be sure to rinse your lentils prior to cooking to remove any rocks or debris as modern cleaning equipment cannot. And I do. But I have never actually found a pebble, and so thought this was a cautionary warning that lawyers required. Now, I figured, the process of cleaning the lentils during production likely was efficient and accurate enough now (in the direct contradiction to what the warning tells me). A good self-reflection example of how my prior experience incorrectly outweighs expert knowledge.\u003c/p\u003e","title":"There's a stone in my lentils"},{"content":"- A series of YouTube videos on how \u0026ldquo;practical effects\u0026rdquo; in movies are highlighted by directors, actors, and viewers, but actually are building blocks to extremely realistic computer generated visual effects. I didn\u0026rsquo;t even realize much of what he showed was technically possible: it makes sense that performing a stunt in real life can give VFX artists valuable information about how it should look when it is computer generated, but the fact that oftentimes the stunt itself is replaced with CGI is astounding; see, for instance, the Top Gun: Maverick replacement jets.\nWatch Part 1 here, and the creator, Movie Rabbit Hole.\n- Personal projects succeed based on momentum, to some degree. Creating accountability and relying on the adrenaline of the initial passion will get you enough of the way to where you need to release the project. Any longer, you hesitate. What small aspect could be better that is doable is an attractive fruit to pick, but very quickly we realize it is poisonous. Many of my projects fall into this trap, and I\u0026rsquo;m left with 90% of a project that I can\u0026rsquo;t release because I didn\u0026rsquo;t focus on the core added value.\n- working as the only full time data person at a nonprofit (with some excellent part-time interns), reading articles like this experience at the MTA about common obstacles encountered with meeting leadership needs for data science projects, and how haphazardly improvements happen, is comforting. Things get better when they need to get better, I\u0026rsquo;ve found, and that is a viable path as organizations develop. I also tried out Dbeaver from this article.\n- A series of comments about how to read scientific papers, which is more interesting as advice on how to write scientific articles, given you now have some anecdotal evidence that people will skip that 20 sentence series of citations masquerading as an introduction you wrote.\n- A handy reference to and learning tool to SQL queries that covers a decent amount of my regular queries.\n- To what extent do we see colors in the dark? How does our perception of colors change in low light? No link here, just curiosity.\n","permalink":"http://localhost:1313/posts/friday-links/","summary":"\u003cp\u003e- A series of YouTube videos on how \u0026ldquo;practical effects\u0026rdquo; in movies are highlighted by directors, actors, and viewers, but actually are building blocks to extremely realistic computer generated visual effects. I didn\u0026rsquo;t even realize much of what he showed was technically possible: it makes sense that performing a stunt in real life can give VFX artists valuable information about how it should look when it is computer generated, but the fact that oftentimes the stunt itself is replaced with CGI is astounding; see, for instance, the Top Gun: Maverick replacement jets.\u003c/p\u003e","title":"Friday Links"},{"content":"In the past six months I\u0026rsquo;ve started to have finger, wrist, and forearm pain. I previously was using the Logitech Mx Mouse and keyboard for business. But due to the pronation of my wrists I wasn\u0026rsquo;t able to type at all without experience severe pain that would continue through the evening. so recently I\u0026rsquo;ve been using the Windows voice axis. To try and perform as much typing and as many actions on the computer as I can. This post Is entirely written using my voice. And as you can I sit I\u0026rsquo;m still having trouble making this a usable tool.\n1. A good quality microphone helps but isn\u0026rsquo;t enough. Iterating through the available microphones, I have the built in one on my laptop, Logitech camera, Bose NC700, and the blue Yeti. By far, having a microphone right next to your mouth that is of reasonable quality will Undoubtedly improve the voice recognition available in windows. But it still will often misinterpret words, and it is necessary to speak more slowly and clearly than feels natural.\n2. Actions interfere with typing and vice versa. I can\u0026rsquo;t type \u0026ldquo;open up\u0026rdquo; Because if I do say it. It will open up the start menu. Any of the keyword action for years often will confuse. often will confuse. the computer. into actually performing the action rather than typing the word\u0026rsquo;s out. This happens for keyword phrases like open focus, left, press, etc. It\u0026rsquo;s especially an issue when you\u0026rsquo;re trying to speak naturally, and you pause. In mid thought.\n3. For some reason, the voice access compatibility with certain apps is limited. If I have Firefox Open, for example, and I say, focus on Firefox, I get an error that says Firefox doesn\u0026rsquo;t exist. Sometimes when I\u0026rsquo;m typing emails. the voice access will recognize what I say, but either it will come back with an error that says working on it for a long period of time, until I restart the voice access. Or it\u0026rsquo;ll tell me that the text was inserted when it really wasn\u0026rsquo;t. To fix this, sometimes I have to double press enter. It happens sporadically, and I\u0026rsquo;m not sure how to create a reproducible example.\nFord. 4 4. Sometimes it can take a bit as evidence here when misinterpreting words and having to repeat. Voice typing doesn\u0026rsquo;t work exactly like just speaking, because the computer will misinterpret pauses. The best results come from planning ahead and saying what you need to say as straightforwardly as possible. But of course, I don\u0026rsquo;t think many people speak like this. You can see above that many sentences might be cut up by a period. And this is just moments where I wasn\u0026rsquo;t sure what to say next.\n5. The text setting editing tools are limited. And this makes it difficult to actually edit and work. updating one word in a sentence for example, forces me to reconnect my hands to a keyboard. adding a comma somewhere in the sentence can be irritating. here for example, I\u0026rsquo;m not sure why it\u0026rsquo;s decided to stop capitalizing the first word after a period. in the voice access toolbar, which appears on the top of your screen. It offers two settings. 1 is filter profanity and the other is turn on automatic punctuation. When you need to type many symbols, it\u0026rsquo;s very difficult. especially in the context of coding,\n6. I still feel self conscious about speaking out loud. My office is on the wall next to a hallway, and I\u0026rsquo;m sure people can hear me. Especially when I have to repeat the same instruction over and over again.\n7. It\u0026rsquo;s much better than what Windows previously had with voice typing. This is easily the best voice recognition tool that I\u0026rsquo;ve used. And you can see that for many sentences, it performs excellently. That said, I haven\u0026rsquo;t used many alternative tools, although I\u0026rsquo;ve been looking for some. I saw that serenade AI, which is a voice recognition tool specifically for coding, is available. but development recently has been slow. and it requires an Internet connection, which I don\u0026rsquo;t care for. especially for work. I\u0026rsquo;m not going to be able to use a tool that sends data back and forth.\n8. when it works, voice typing feels infinitely faster than typing. That said, I\u0026rsquo;m not often typing like this natural naturally. on my daily workflow, which might involve working in Excel sheets, writing code or creating data visualizations, We\u0026rsquo;re working in common product software, It\u0026rsquo;s primarily mouse usage and short sentences that need to be replaced.\n9. Gesture controls don\u0026rsquo;t seem to be widely available yet, and the tools that are are primarily repurposed tools. Toby eye tracker, for example, seems to be pivoting away from accessibility usage. The tap tools don\u0026rsquo;t necessarily exist. better. It just removes the keyboard, but I\u0026rsquo;m still going to have to move my wrists and fingers. Restructuring a mouse to make it more vertical, or use a trackpad. I think I\u0026rsquo;d prefer to just be able to use a camera to recognize gestures. But this technology is apparently very difficult and might require the use of multiple cameras. I haven\u0026rsquo;t seen many examples of it, but I\u0026rsquo;m trying to do more research. But the point here is that different mice don\u0026rsquo;t necessarily help me. The question is, how could I possibly replace a mouse? Dragon balls don\u0026rsquo;t necessarily seem to be recommended because they put a lot of stress on your thumbs and track pads that lay directly on the desk, force my wrist to bend at odd angles. Replace the word dragon with track. This is why I don\u0026rsquo;t use voice access to type out emails. without reviewing them and editing them.\n10. It feels like there needs to be a second step in voice access. That reviews what you\u0026rsquo;ve said and then reorients it in the context of what is previously written. For example, combining sentences together when it makes sense. We\u0026rsquo;re updating the punctuation. or updating the punctuation. For example, if I repeat the sentence like that with just one word different, the software might infer that I want to replace that sentence with that 1 word difference rather than add it again afterwards. There are commands like delete that sentence. But having to intersperse the common language with commands like this can get frustrated. In natural language, when I\u0026rsquo;m in a conversation with somebody, I would just say the word over again. Microsoft does offer selection and correction tools for text, But they only seem to work in limited applications. For example, many don\u0026rsquo;t work while typing this post, and it takes a bit of practice to get used to what the commands are. Plus to remember them. For example, saying correct previous word here either goes to the next paragraph and highlights the first word and that 1. Or tells me to select a number, but doesn\u0026rsquo;t actually point out any numbers anywhere on the page. For example, trying to use the select previous word will also go to the next paragraph.\nAs you can tell. It feels like the majority of the work is done. But its ironing out these difficult situations. and creating a better compatibility with the actual software that you\u0026rsquo;re working in that seems to be the next major step. working in programs like Excel or VS code become very difficult. I just saw that Github copilot is going to be releasing a voice copilot that\u0026rsquo;s currently in preview. and I signed up. I\u0026rsquo;ve heard the dragon voice software is also a possibility. but many of these accessibility tools can become very expensive. Custom keyboards are easily within the hundreds of dollars buying specific Chester recognition cameras that are precise and that work with the software that you work with can also be expensive and rare to find. And of course, it needs to better recognize your accents.\nAs I test more software out, we\u0026rsquo;ll continue adding to this. to note the title is my microphone picking up what somebody was saying outside in the hallway.\n","permalink":"http://localhost:1313/posts/ill-be-back-babe-no-baby/","summary":"\u003cp\u003eIn the past six months I\u0026rsquo;ve started to have finger, wrist, and forearm pain. I previously was using the Logitech Mx Mouse and keyboard for business. But due to the pronation of my wrists I wasn\u0026rsquo;t able to type at all without experience severe pain that would continue through the evening. so recently I\u0026rsquo;ve been using the Windows voice axis. To try and perform as much typing and as many actions on the computer as I can. This post Is entirely written using my voice. And as you can I sit I\u0026rsquo;m still having trouble making this a usable tool.\u003c/p\u003e","title":"I'll be back babe no baby"}]